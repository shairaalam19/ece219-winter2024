{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Regression Analysis and Define Your Own Task!\n",
    "\n",
    "## Group Members\n",
    "- Shaira Alam\n",
    "\n",
    "- Vani Agrawal \n",
    "\n",
    "- Dhakshina Ilango"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/vaniagrawal/anaconda3/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/vaniagrawal/anaconda3/lib/python3.10/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/vaniagrawal/anaconda3/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/vaniagrawal/anaconda3/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/vaniagrawal/anaconda3/lib/python3.10/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 color clarity  carat        cut   symmetry     polish  \\\n",
      "0           0     E    VVS2   0.09  Excellent  Very Good  Very Good   \n",
      "1           1     E    VVS2   0.09  Very Good  Very Good  Very Good   \n",
      "2           2     E    VVS2   0.09  Excellent  Very Good  Very Good   \n",
      "3           3     E    VVS2   0.09  Excellent  Very Good  Very Good   \n",
      "4           4     E    VVS2   0.09  Very Good  Very Good  Excellent   \n",
      "\n",
      "   depth_percent  table_percent  length  width  depth girdle_min girdle_max  \\\n",
      "0           62.7           59.0    2.85   2.87   1.79          M          M   \n",
      "1           61.9           59.0    2.84   2.89   1.78        STK        STK   \n",
      "2           61.1           59.0    2.88   2.90   1.77         TN          M   \n",
      "3           62.0           59.0    2.86   2.88   1.78          M        STK   \n",
      "4           64.9           58.5    2.79   2.83   1.82        STK        STK   \n",
      "\n",
      "   price  \n",
      "0    200  \n",
      "1    200  \n",
      "2    200  \n",
      "3    200  \n",
      "4    200  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "diamonds_data = pd.read_csv(\"diamonds_ece219.csv\").dropna(subset=['price'])\n",
    "diamonds_data_numbers = diamonds_data.select_dtypes(include=['number'])\n",
    "diamonds_data_objects = diamonds_data.select_dtypes(include=['object'])\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify data is loaded correctly\n",
    "print(diamonds_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "### Plot a heatmap of the Pearson correlation matrix of the dataset columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the Pearson correlation matrix\n",
    "corr_matrix = diamonds_data_numbers.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report which features have the highest absolute correlation with the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with highest absolute correlation with the target variable (price):\n",
      " carat            0.913479\n",
      "length           0.869521\n",
      "width            0.841887\n",
      "Unnamed: 0       0.753482\n",
      "depth            0.299696\n",
      "table_percent    0.042453\n",
      "depth_percent    0.025469\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find features with highest absolute correlation with the target variable\n",
    "target_corr = corr_matrix['price'].abs().sort_values(ascending=False)\n",
    "highest_corr_features = target_corr[1:]  # Excluding the target variable itself\n",
    "\n",
    "print(\"Features with highest absolute correlation with the target variable (price):\\n\", highest_corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the context of either dataset, describe what the correlation patterns suggest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Strong Positive Correlation:\n",
    "\n",
    "Features such as carat, length, width, and Unnamed: 0 have a strong positive correlations with the target variable (price). Specifically, carat has the highest correlation coefficient (0.913479), indicating that as the carat weight of a diamond increases, its price tends to increase significantly. This relationship is similar with length and width as well. \"Unnamed: 0\" also shows a relatively strong positive correlation.\n",
    "\n",
    "2. Weak Positive Correlation:\n",
    "\n",
    "Features like depth exhibit weaker positive correlations with the target variable. Although these correlations are positive, they are lower than those of carat, length, and width. This suggests that these features may have an influence on the price, but their impact is not as significant as the features that have a strong correlation.\n",
    "\n",
    "3. Weak Correlation:\n",
    "\n",
    "Features such as depth_percent and table_percent show very weak positive correlations with the target variable. The correlation coefficient is close to zero, which means that it has a non-impactful linear relationship between these features and the price. These features may not have much impact on the price of a diamond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the histogram of numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of numerical features:\n",
      "Unnamed: 0        0.263138\n",
      "carat             2.331773\n",
      "depth_percent   -13.559608\n",
      "table_percent   -11.046563\n",
      "length            1.283604\n",
      "width             4.115348\n",
      "depth            27.493299\n",
      "price             3.071737\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Plot histograms of numerical features\n",
    "plt.figure(figsize=(12, 10))\n",
    "diamonds_data_numbers.hist(bins=20, color='skyblue', edgecolor='black', linewidth=1.0, xlabelsize=8, ylabelsize=8, grid=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check skewness of numerical features\n",
    "skewness = diamonds_data_numbers.skew()\n",
    "print(\"Skewness of numerical features:\")\n",
    "print(skewness)\n",
    "\n",
    "# Handle high skewness using preprocessing techniques (e.g., log transformation)\n",
    "skewed_features = skewness[abs(skewness) > 1].index\n",
    "for feature in skewed_features:\n",
    "    diamonds_data_numbers[feature] = np.log1p(diamonds_data_numbers[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What preprocessing can be done if the distribution of a feature has high skewness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Log Transformation: \n",
    "\n",
    "Logarithmic transformation is usually effective for reducing right skewness (positive skewness). It compresses large values and stretches small values, making the distribution more symmetric. This transformation is especially useful when dealing with features such as depth that exhibit high positive skewness.\n",
    "\n",
    "2. Square Root Transformation: \n",
    "\n",
    "Square root transformation is another effective method for reducing right skewness in feature distributions. It's similar to the logarithmic transformation but milder in its effect. This transformation is suitable for features with high positive skewness, such as carat, width, and price, where a less aggressive transformation is desired compared to the logarithmic transformation.\n",
    "\n",
    "3. Inverse Transformation: \n",
    "\n",
    "Applying an inverse transformation, such as taking the reciprocal or the inverse square root, can help reduce left skewness in the distribution. This transformation stretches large values and compresses small values, making the distribution more symmetric. It can be useful for features like depth_percent and table_percent, which exhibit high negative skewness.\n",
    "\n",
    "4. Square Transformation:\n",
    "\n",
    "Similar to the inverse transformation, the square transformation can also help reduce left skewness by stretching small values and compressing large values. Similar to the square root transformation, this transformation is less aggressive than the inverse transformation and may be more suitable for features with moderate negative skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct and inspect the box plot of categorical features vs target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize box plots of categorical features vs. target variable (price)\n",
    "num_plots = len(diamonds_data_objects.columns)\n",
    "num_rows = (num_plots - 1) // 3 + 1  # Calculate the number of rows needed for subplots\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, col in enumerate(diamonds_data_objects.columns, start=1):\n",
    "    plt.subplot(num_rows, 3, i)\n",
    "    sns.boxplot(x=col, y='price', data=diamonds_data)\n",
    "    plt.title(f'{col} vs. price')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Color \n",
    "\n",
    "Color were relatively same distribution except for \"M\" \n",
    "\n",
    "2. Clarity\n",
    "\n",
    "There were some variations, especially regarding I2 and I3 \n",
    "\n",
    "3. Cut \n",
    "\n",
    "Both had similar distribution.\n",
    "\n",
    "4. Symmetry\n",
    "\n",
    "Distribution was relatively the same with regard to price. \n",
    "\n",
    "5. Polish\n",
    "\n",
    "Similar to Cut and Symmetry, they were relatively similarly distributed, however, having an \"Excellent\" polish did have a slightly wider range in the higher price range. \n",
    "\n",
    "6. girdle_min\n",
    "\n",
    "The disbtribution was the same except for XTN, VTK, STN, and XTK. \n",
    "\n",
    "6. girdle_max \n",
    "\n",
    "The distribution was similar except for VTK, VTN, XTN, STN, XTK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "For the Diamonds dataset, plot the counts by color, cut and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot counts by color\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.countplot(x='color', data=diamonds_data, palette='viridis')\n",
    "plt.title('Counts by Color')\n",
    "\n",
    "# Plot counts by cut\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.countplot(x='cut', data=diamonds_data, palette='viridis')\n",
    "plt.title('Counts by Cut')\n",
    "\n",
    "# Plot counts by clarity\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(x='clarity', data=diamonds_data, palette='viridis')\n",
    "plt.title('Counts by Clarity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "Standardize feature columns and prepare them for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing X\n",
      "   Unnamed: 0 color clarity  carat        cut   symmetry     polish  \\\n",
      "0           0     E    VVS2   0.09  Excellent  Very Good  Very Good   \n",
      "1           1     E    VVS2   0.09  Very Good  Very Good  Very Good   \n",
      "2           2     E    VVS2   0.09  Excellent  Very Good  Very Good   \n",
      "3           3     E    VVS2   0.09  Excellent  Very Good  Very Good   \n",
      "4           4     E    VVS2   0.09  Very Good  Very Good  Excellent   \n",
      "\n",
      "   depth_percent  table_percent  length  width  depth girdle_min girdle_max  \n",
      "0           62.7           59.0    2.85   2.87   1.79          M          M  \n",
      "1           61.9           59.0    2.84   2.89   1.78        STK        STK  \n",
      "2           61.1           59.0    2.88   2.90   1.77         TN          M  \n",
      "3           62.0           59.0    2.86   2.88   1.78          M        STK  \n",
      "4           64.9           58.5    2.79   2.83   1.82        STK        STK  \n",
      "Printing y\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "Name: price, dtype: int64\n",
      "['Unnamed: 0' 'carat' 'depth_percent' 'table_percent' 'length' 'width'\n",
      " 'depth']\n",
      "['color' 'clarity' 'cut' 'symmetry' 'polish' 'girdle_min' 'girdle_max']\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing X\")\n",
    "X = diamonds_data.drop(columns=['price']).dropna()  # Features (all columns except 'price')\n",
    "print(X.head())\n",
    "\n",
    "print(\"Printing y\")\n",
    "y = diamonds_data['price'].dropna()  # Target variable\n",
    "print(y.head())\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['number']).columns.values\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.values\n",
    "\n",
    "print(numerical_features)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  carat  depth_percent  table_percent  length  width  depth  \\\n",
      "0                0   0.09           62.7           59.0    2.85   2.87   1.79   \n",
      "1                1   0.09           61.9           59.0    2.84   2.89   1.78   \n",
      "2                2   0.09           61.1           59.0    2.88   2.90   1.77   \n",
      "3                3   0.09           62.0           59.0    2.86   2.88   1.78   \n",
      "4                4   0.09           64.9           58.5    2.79   2.83   1.82   \n",
      "...            ...    ...            ...            ...     ...    ...    ...   \n",
      "149866      212615   2.01           63.0           59.0    7.98   8.03   5.05   \n",
      "149867      212616   1.90           62.7           57.0    7.82   7.87   4.92   \n",
      "149868      212617   2.45           61.2           60.0    8.58   8.65   5.28   \n",
      "149869      212619   2.50           59.1           62.0    8.80   8.85   5.22   \n",
      "149870      212620   1.50           62.9           56.0    7.25   7.30   4.58   \n",
      "\n",
      "        color_E  color_F  color_G  ...  girdle_min_unknown  girdle_max_STK  \\\n",
      "0             1        0        0  ...                   0               0   \n",
      "1             1        0        0  ...                   0               1   \n",
      "2             1        0        0  ...                   0               0   \n",
      "3             1        0        0  ...                   0               1   \n",
      "4             1        0        0  ...                   0               1   \n",
      "...         ...      ...      ...  ...                 ...             ...   \n",
      "149866        0        0        1  ...                   0               1   \n",
      "149867        0        1        0  ...                   1               0   \n",
      "149868        0        0        0  ...                   1               0   \n",
      "149869        0        0        0  ...                   0               1   \n",
      "149870        0        0        0  ...                   0               1   \n",
      "\n",
      "        girdle_max_STN  girdle_max_TK  girdle_max_TN  girdle_max_VTK  \\\n",
      "0                    0              0              0               0   \n",
      "1                    0              0              0               0   \n",
      "2                    0              0              0               0   \n",
      "3                    0              0              0               0   \n",
      "4                    0              0              0               0   \n",
      "...                ...            ...            ...             ...   \n",
      "149866               0              0              0               0   \n",
      "149867               0              0              0               0   \n",
      "149868               0              0              0               0   \n",
      "149869               0              0              0               0   \n",
      "149870               0              0              0               0   \n",
      "\n",
      "        girdle_max_VTN  girdle_max_XTK  girdle_max_XTN  girdle_max_unknown  \n",
      "0                    0               0               0                   0  \n",
      "1                    0               0               0                   0  \n",
      "2                    0               0               0                   0  \n",
      "3                    0               0               0                   0  \n",
      "4                    0               0               0                   0  \n",
      "...                ...             ...             ...                 ...  \n",
      "149866               0               0               0                   0  \n",
      "149867               0               0               0                   1  \n",
      "149868               0               0               0                   1  \n",
      "149869               0               0               0                   0  \n",
      "149870               0               0               0                   0  \n",
      "\n",
      "[149871 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical features\n",
    "categorical_encoded = pd.get_dummies(X[categorical_features], drop_first=True).astype(int)\n",
    "\n",
    "# Concatenate numerical and one-hot encoded categorical features\n",
    "X_encoded = pd.concat([X[numerical_features], categorical_encoded], axis=1)\n",
    "\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0     carat  depth_percent  table_percent    length  \\\n",
      "0        -1.602442 -1.157106       0.215866       0.345119 -2.146391   \n",
      "1        -1.602425 -1.157106       0.014689       0.345119 -2.156289   \n",
      "2        -1.602408 -1.157106      -0.186488       0.345119 -2.116697   \n",
      "3        -1.602391 -1.157106       0.039836       0.345119 -2.136493   \n",
      "4        -1.602374 -1.157106       0.769101       0.218693 -2.205778   \n",
      "...            ...       ...            ...            ...       ...   \n",
      "149866    1.996218  3.631605       0.291307       0.345119  2.931233   \n",
      "149867    1.996235  3.357252       0.215866      -0.160588  2.772867   \n",
      "149868    1.996252  4.729018      -0.161341       0.597973  3.525108   \n",
      "149869    1.996286  4.853724      -0.689429       1.103680  3.742861   \n",
      "149870    1.996303  2.359604       0.266160      -0.413441  2.208686   \n",
      "\n",
      "           width     depth  color_E  color_F  color_G  ...  \\\n",
      "0      -2.078247 -0.730430        1        0        0  ...   \n",
      "1      -2.059209 -0.735681        1        0        0  ...   \n",
      "2      -2.049690 -0.740932        1        0        0  ...   \n",
      "3      -2.068728 -0.735681        1        0        0  ...   \n",
      "4      -2.116324 -0.714676        1        0        0  ...   \n",
      "...          ...       ...      ...      ...      ...  ...   \n",
      "149866  2.833676  0.981472        0        0        1  ...   \n",
      "149867  2.681369  0.913206        0        1        0  ...   \n",
      "149868  3.423869  1.102251        0        0        0  ...   \n",
      "149869  3.614253  1.070743        0        0        0  ...   \n",
      "149870  2.138772  0.734664        0        0        0  ...   \n",
      "\n",
      "        girdle_min_unknown  girdle_max_STK  girdle_max_STN  girdle_max_TK  \\\n",
      "0                        0               0               0              0   \n",
      "1                        0               1               0              0   \n",
      "2                        0               0               0              0   \n",
      "3                        0               1               0              0   \n",
      "4                        0               1               0              0   \n",
      "...                    ...             ...             ...            ...   \n",
      "149866                   0               1               0              0   \n",
      "149867                   1               0               0              0   \n",
      "149868                   1               0               0              0   \n",
      "149869                   0               1               0              0   \n",
      "149870                   0               1               0              0   \n",
      "\n",
      "        girdle_max_TN  girdle_max_VTK  girdle_max_VTN  girdle_max_XTK  \\\n",
      "0                   0               0               0               0   \n",
      "1                   0               0               0               0   \n",
      "2                   0               0               0               0   \n",
      "3                   0               0               0               0   \n",
      "4                   0               0               0               0   \n",
      "...               ...             ...             ...             ...   \n",
      "149866              0               0               0               0   \n",
      "149867              0               0               0               0   \n",
      "149868              0               0               0               0   \n",
      "149869              0               0               0               0   \n",
      "149870              0               0               0               0   \n",
      "\n",
      "        girdle_max_XTN  girdle_max_unknown  \n",
      "0                    0                   0  \n",
      "1                    0                   0  \n",
      "2                    0                   0  \n",
      "3                    0                   0  \n",
      "4                    0                   0  \n",
      "...                ...                 ...  \n",
      "149866               0                   0  \n",
      "149867               0                   1  \n",
      "149868               0                   1  \n",
      "149869               0                   0  \n",
      "149870               0                   0  \n",
      "\n",
      "[149871 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "X_scaled = preprocessing.scale(X_encoded[numerical_features])\n",
    "X_preprocessed = pd.concat([pd.DataFrame(X_scaled, columns=numerical_features), categorical_encoded], axis=1)\n",
    "print(X_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes and sample data before preprocessing:\n",
      "X_train shape: (119896, 46)\n",
      "X_train head:\n",
      "        Unnamed: 0     carat  depth_percent  table_percent    length     width  \\\n",
      "80033   -0.004553 -0.009811       0.190719       0.345119  0.169718  0.158772   \n",
      "82831    0.061423 -0.134517      -0.060752       1.103680  0.041046  0.044541   \n",
      "31549   -0.959298 -0.608400      -0.312223       0.092266 -0.651808 -0.640843   \n",
      "94480    0.350785  0.114895       0.215866      -0.666295  0.377574  0.358676   \n",
      "78520   -0.039572 -0.458753      -0.010458       0.345119 -0.424156 -0.421901   \n",
      "\n",
      "          depth  color_E  color_F  color_G  ...  girdle_min_unknown  \\\n",
      "80033  0.041502        0        0        0  ...                   0   \n",
      "82831 -0.026764        0        1        0  ...                   1   \n",
      "31549 -0.278824        0        0        1  ...                   1   \n",
      "94480  0.099265        0        0        0  ...                   0   \n",
      "78520 -0.179050        0        0        0  ...                   0   \n",
      "\n",
      "       girdle_max_STK  girdle_max_STN  girdle_max_TK  girdle_max_TN  \\\n",
      "80033               1               0              0              0   \n",
      "82831               0               0              0              0   \n",
      "31549               0               0              0              0   \n",
      "94480               1               0              0              0   \n",
      "78520               1               0              0              0   \n",
      "\n",
      "       girdle_max_VTK  girdle_max_VTN  girdle_max_XTK  girdle_max_XTN  \\\n",
      "80033               0               0               0               0   \n",
      "82831               0               0               0               0   \n",
      "31549               0               0               0               0   \n",
      "94480               0               0               0               0   \n",
      "78520               0               0               0               0   \n",
      "\n",
      "       girdle_max_unknown  \n",
      "80033                   0  \n",
      "82831                   1  \n",
      "31549                   1  \n",
      "94480                   0  \n",
      "78520                   0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "y_train shape: (119896,)\n",
      "y_train head:\n",
      " 80033    1464\n",
      "82831    1520\n",
      "31549     850\n",
      "94480    2248\n",
      "78520    1408\n",
      "Name: price, dtype: int64\n",
      "X_test shape: (29975, 46)\n",
      "X_test head:\n",
      "         Unnamed: 0     carat  depth_percent  table_percent    length  \\\n",
      "97395     0.430082 -0.134517       0.266160      -0.160588  0.021250   \n",
      "145917    1.852993  3.606664      -0.815165       0.977253  3.168783   \n",
      "46909    -0.664673 -0.633341       0.241013      -0.413441 -0.760685   \n",
      "53870    -0.532060 -0.433811      -0.287076      -0.413441 -0.305381   \n",
      "93746     0.329814 -0.134517      -0.890606       0.850826  0.169718   \n",
      "\n",
      "           width     depth  color_E  color_F  color_G  ...  \\\n",
      "97395   0.015984 -0.000508        0        0        1  ...   \n",
      "145917  3.043099  0.865945        0        0        0  ...   \n",
      "46909  -0.726516 -0.263070        0        0        0  ...   \n",
      "53870  -0.307670 -0.163296        0        0        0  ...   \n",
      "93746   0.168291 -0.074025        0        0        0  ...   \n",
      "\n",
      "        girdle_min_unknown  girdle_max_STK  girdle_max_STN  girdle_max_TK  \\\n",
      "97395                    1               0               0              0   \n",
      "145917                   0               0               0              0   \n",
      "46909                    0               1               0              0   \n",
      "53870                    0               1               0              0   \n",
      "93746                    0               1               0              0   \n",
      "\n",
      "        girdle_max_TN  girdle_max_VTK  girdle_max_VTN  girdle_max_XTK  \\\n",
      "97395               0               0               0               0   \n",
      "145917              0               0               0               0   \n",
      "46909               0               0               0               0   \n",
      "53870               0               0               0               0   \n",
      "93746               0               0               0               0   \n",
      "\n",
      "        girdle_max_XTN  girdle_max_unknown  \n",
      "97395                0                   1  \n",
      "145917               0                   0  \n",
      "46909                0                   0  \n",
      "53870                0                   0  \n",
      "93746                0                   0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "y_test shape: (29975,)\n",
      "y_test head:\n",
      " 97395      2418\n",
      "145917    18058\n",
      "46909       966\n",
      "53870      1022\n",
      "93746      2190\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes and sample data before preprocessing\n",
    "print(\"Shapes and sample data before preprocessing:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_train head:\\n\", X_train.head())\n",
    "print(\"y_train shape:\", Y_train.shape)\n",
    "print(\"y_train head:\\n\", Y_train.head())\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"X_test head:\\n\", X_test.head())\n",
    "print(\"y_test shape:\", Y_test.shape)\n",
    "print(\"y_test head:\\n\", Y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe how this step qualitatively affects the performance of your models in terms of test RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first standardize the numerical features using StandardScaler. This preprocessing transforms the numerical features so that they have a mean of 0 and a standard deviation of 1. It helps to bring all features to a similar scale and prevents features with larger magnitudes from having significantly larger impact on the training than other features.\n",
    "\n",
    "The benefits are as follows:\n",
    "\n",
    "1. Model Convergence: \n",
    "\n",
    "Standardizing helps algorithms converge faster during training. Algorithms such as gradient descent-based methods often converge more quickly when features are on a similar scale, leading to potentially faster training times and more stable optimization.\n",
    "\n",
    "2. Improved Interpretability: \n",
    "\n",
    "Standardization allows for the relationships between features to be understood -- and allows the importance of the values to be on the same scale. \n",
    "\n",
    "3. Reduced Sensitivity to Outliers: \n",
    "\n",
    "Standardizing allows for the presesnce of outliers to have less of an impact. By centering around the mean and scaling by the standard deviation, outliers cannot heavily impact the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it true for all model types? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear Models (i.e. Linear Regression, Logistic Regression):\n",
    "\n",
    "Standardization is important for linear models because these models assume that the input features have a linear relationship with the target variable. Standardizing features ensures that the coefficients obtained during training are directly comparable, leading to more stable models.\n",
    "\n",
    "2. Tree-Based Models (i.e. Decision Trees, Random Forests):\n",
    "\n",
    "Tree-based models are generally not sensitive to the scale of features because they make decisions based on feature thresholds rather than the absolute values of features. Therefore, standardization may not be as significant on the performance of tree-based models compared to linear models. However, standardization can still help in scenarios where there are interactions between features or when using algorithms that incorporate feature importance measures.\n",
    "\n",
    "3. Distance-Based Models (i.e. K-Nearest Neighbors):\n",
    "\n",
    "Distance-based models calculate distances between data points, making them sensitive to the scale of features. Standardizing features ensures that they equally contribute to the distance calculations.\n",
    "\n",
    "4. Neural Networks:\n",
    "\n",
    "Standardizing features helps ensure that optimization is efficient and that the gradients are well-scaled, leading to faster convergence and better performance.\n",
    "\n",
    "4. Support Vector Machines (SVMs):\n",
    "\n",
    "SVMs are sensitive to the scale of features because they rely on the distance between data points to define decision boundaries. Standardizing features helps SVMs perform better by making sure that features contribute equally to the decision-making process and preventing bias towards features with larger scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also list two features for either dataset that has the lowest MI w.r.t to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transformed shape: (119896, 46)\n",
      "X_train_transformed samples:\n",
      "        Unnamed: 0     carat  depth_percent  table_percent    length     width  \\\n",
      "80033   -0.004553 -0.009811       0.190719       0.345119  0.169718  0.158772   \n",
      "82831    0.061423 -0.134517      -0.060752       1.103680  0.041046  0.044541   \n",
      "31549   -0.959298 -0.608400      -0.312223       0.092266 -0.651808 -0.640843   \n",
      "94480    0.350785  0.114895       0.215866      -0.666295  0.377574  0.358676   \n",
      "78520   -0.039572 -0.458753      -0.010458       0.345119 -0.424156 -0.421901   \n",
      "\n",
      "          depth  color_E  color_F  color_G  ...  girdle_min_unknown  \\\n",
      "80033  0.041502        0        0        0  ...                   0   \n",
      "82831 -0.026764        0        1        0  ...                   1   \n",
      "31549 -0.278824        0        0        1  ...                   1   \n",
      "94480  0.099265        0        0        0  ...                   0   \n",
      "78520 -0.179050        0        0        0  ...                   0   \n",
      "\n",
      "       girdle_max_STK  girdle_max_STN  girdle_max_TK  girdle_max_TN  \\\n",
      "80033               1               0              0              0   \n",
      "82831               0               0              0              0   \n",
      "31549               0               0              0              0   \n",
      "94480               1               0              0              0   \n",
      "78520               1               0              0              0   \n",
      "\n",
      "       girdle_max_VTK  girdle_max_VTN  girdle_max_XTK  girdle_max_XTN  \\\n",
      "80033               0               0               0               0   \n",
      "82831               0               0               0               0   \n",
      "31549               0               0               0               0   \n",
      "94480               0               0               0               0   \n",
      "78520               0               0               0               0   \n",
      "\n",
      "       girdle_max_unknown  \n",
      "80033                   0  \n",
      "82831                   1  \n",
      "31549                   1  \n",
      "94480                   0  \n",
      "78520                   0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "Y_train shape: (119896,)\n",
      "Y_train samples:\n",
      " 80033    1464\n",
      "82831    1520\n",
      "31549     850\n",
      "94480    2248\n",
      "78520    1408\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_transformed shape:\", X_train.shape)\n",
    "print(\"X_train_transformed samples:\\n\", X_train[:5])\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_train samples:\\n\", Y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi_scores = mutual_info_regression(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with the lowest Mutual Information scores:\n",
      "      Feature  MI Score\n",
      "0  Unnamed: 0  7.602010\n",
      "1       carat  1.356386\n"
     ]
    }
   ],
   "source": [
    "mi_df = pd.DataFrame({\"Feature\": X_train.columns, \"MI Score\": mi_scores})\n",
    "\n",
    "# Sort the DataFrame by MI scores in descending order\n",
    "mi_df_sorted = mi_df.sort_values(by='MI Score', ascending=False)\n",
    "\n",
    "# Display the features with the lowest MI scores\n",
    "lowest_mi_features = mi_df_sorted.head(2)\n",
    "print(\"Features with the lowest Mutual Information scores:\")\n",
    "print(lowest_mi_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 \n",
    "Training: train multiple algorithms and compare their performance using average RMSE from 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: Average RMSE (Training) = 1475.46\n",
      "Decision Tree: Average RMSE (Training) = 17.00\n",
      "Random Forest: Average RMSE (Training) = 20.12\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Perform 10-fold cross-validation and calculate average RMSE for training for each algorithm\n",
    "num_folds = 10\n",
    "results_training = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train, Y_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        Y_train_fold, Y_test_fold = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "\n",
    "        # Fit the model on training data\n",
    "        model.fit(X_train_fold, Y_train_fold)\n",
    "\n",
    "        # Predict on validation data\n",
    "        Y_pred_fold = model.predict(X_test_fold)\n",
    "\n",
    "        # Calculate RMSE for validation set\n",
    "        rmse = np.sqrt(mean_squared_error(Y_test_fold, Y_pred_fold))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    # Calculate average RMSE across all folds\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    results_training[model_name] = avg_rmse\n",
    "\n",
    "# Print average RMSE for each algorithm\n",
    "for model_name, avg_rmse in results_training.items():\n",
    "    print(f'{model_name}: Average RMSE (Training) = {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 \n",
    "Evaluation: Perform 10-fold cross-validation and measure average RMSE errors for training and validation sets. For random forest model, measure Out-of-Bag Error (OOB) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop through models\n",
    "for model_name, model in models.items():\n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train, Y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Calculate RMSE for training set\n",
    "    rmse_train_scores = np.sqrt(cv_scores)\n",
    "    avg_rmse_train = np.mean(rmse_train_scores)\n",
    "\n",
    "    # Store training set scores\n",
    "    results[model_name] = {'Training RMSE': rmse_train_scores}\n",
    "    \n",
    "    # Perform cross-validation for validation set\n",
    "    rmse_val_scores = np.sqrt(cv_scores)\n",
    "    avg_rmse_val = np.mean(rmse_val_scores)\n",
    "\n",
    "    # Store validation set scores\n",
    "    results[model_name]['Validation RMSE'] = rmse_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[\"Random Forest\"]\n",
    "\n",
    "oob_predictions = np.zeros(len(Y_train))\n",
    "oob_counts = np.zeros(len(Y_train))\n",
    "for tree, samples in zip(model.estimators_, model.estimators_samples_):\n",
    "    oob_indices = np.delete(np.arange(len(Y_train)), samples)\n",
    "    oob_predictions[oob_indices] += tree.predict(X_train.iloc[oob_indices])\n",
    "    oob_counts[oob_indices] += 1\n",
    "\n",
    "oob_predictions /= np.maximum(1, oob_counts)\n",
    "oob_rmse = np.sqrt(mean_squared_error(Y_train, oob_predictions))\n",
    "\n",
    "results[\"Random Forest\"]['OOB RMSE'] = oob_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Linear Regression', {'Training RMSE': array([1432.24950485, 1468.83419038, 1484.47810014, 1498.23246743,\n",
      "       1544.81214529, 1436.0743509 , 1492.18666083, 1442.1216482 ,\n",
      "       1480.92658636, 1478.62227049]), 'Validation RMSE': array([1432.24950485, 1468.83419038, 1484.47810014, 1498.23246743,\n",
      "       1544.81214529, 1436.0743509 , 1492.18666083, 1442.1216482 ,\n",
      "       1480.92658636, 1478.62227049])}), ('Decision Tree', {'Training RMSE': array([ 5.25691094, 19.13097824,  6.07151569, 26.71636147,  8.28436936,\n",
      "        6.2146213 , 35.45437695,  6.71085185,  7.77003919, 63.72854777]), 'Validation RMSE': array([ 5.25691094, 19.13097824,  6.07151569, 26.71636147,  8.28436936,\n",
      "        6.2146213 , 35.45437695,  6.71085185,  7.77003919, 63.72854777])}), ('Random Forest', {'Training RMSE': array([15.51102745, 24.06180064, 20.03655935, 18.89405138,  8.33273828,\n",
      "       15.74761469, 35.07166829, 13.39411528,  6.61187193, 61.85871962]), 'Validation RMSE': array([15.51102745, 24.06180064, 20.03655935, 18.89405138,  8.33273828,\n",
      "       15.74761469, 35.07166829, 13.39411528,  6.61187193, 61.85871962]), 'OOB RMSE': 11.078639119660636})])\n",
      "Linear Regression:\n",
      "   Average RMSE (Training): 1475.85\n",
      "   Average RMSE (Validation): 1475.85\n",
      "Decision Tree:\n",
      "   Average RMSE (Training): 18.53\n",
      "   Average RMSE (Validation): 18.53\n",
      "Random Forest:\n",
      "   Average RMSE (Training): 21.95\n",
      "   Average RMSE (Validation): 21.95\n",
      "   Average RMSE (OOB): 11.08\n"
     ]
    }
   ],
   "source": [
    "# Print RMSE for training and validation sets\n",
    "\n",
    "print(results.items())\n",
    "for model_name, scores in results.items():\n",
    "    print(f'{model_name}:')\n",
    "    print(f'   Average RMSE (Training): {np.mean(scores[\"Training RMSE\"]):.2f}')\n",
    "    print(f'   Average RMSE (Validation): {np.mean(scores[\"Validation RMSE\"]):.2f}')\n",
    "    # If Random Forest, calculate OOB error\n",
    "    if model_name == 'Random Forest':\n",
    "        print(f'   Average RMSE (OOB): {np.mean(scores[\"OOB RMSE\"]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least squares (linear regression without regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-15 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-15 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-15 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-15 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-15 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-15 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, Y_train) # Remove this line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-17 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-17 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-17 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-17 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-17 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lasso<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_model = Lasso(alpha=1.0) # need to tune\n",
    "lasso_model.fit(X_train, Y_train) # Remove this line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-16 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-16 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-16 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-16 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-16 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge(alpha=1.0) # need to tune\n",
    "ridge_model.fit(X_train, Y_train) # Remove this line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the objective function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function is the function that an ML model aims to maximize/minimize during training and therefore find the corresponding parameter set in the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Explain how each regularization scheme affects the learned parameter set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization schemes such as Lasso and Ridge Regression add penalty terms to prevent the model from overfitting to the data and improve generalization on unseen data. <br>\n",
    "\n",
    "- OLS(Ordinary Least Squares): OLS does not include any regularization term. It aims to minimize the sum of squared difference between the predicted and actual target value. As a result it might result in overfitting of train data. \n",
    "\n",
    "- Lasso Regression: The penalty term is equal to the absolute value of the coefficients multiplied by alpha(regularization parameter). This shrinks some coefficients to zero, effectively performing feature selection by eleminating less important features of the model. \n",
    "\n",
    "- Ridge Regression: The penalty term is equal to the squared value of the coefficients multiplied by alpha (regularization parameter). It penalizes large coefficients and thus some coefficients tend to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Report your choice of the best regularization scheme along with the optimal penalty parameter and explain how you computed it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best regularization scheme is the Ridge Regression with (alpha = 1) since the MSE of Ridge Regression is lesser than that of Lasso Regression. \n",
    "\n",
    "Parameter grids are used for both Lasso and Ridge regression, specifying a range of alpha values to search for the optimal penalty parameter.\n",
    "GridSearchCV is used to perform grid search with cross-validation (cv=5 indicates 5-fold cross-validation) to evaluate the models' performance using negative mean squared error as the scoring metric. After fitting the models, we extract the best parameters and best scores for both Lasso and Ridge.<br><br>\n",
    "Finally, the regularization scheme with the optimal alpha values along with their MSE values are reported.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Lasso and Ridge Regression \n",
    "param_grid_lasso = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid_ridge = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-18 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-18 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-18 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-18 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-18 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Ridge</label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lasso = GridSearchCV(lasso_model, param_grid_lasso, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search_ridge = GridSearchCV(ridge_model, param_grid_ridge, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_lasso.fit(X_train, Y_train)\n",
    "grid_search_ridge.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Lasso: {'alpha': 0.1}\n",
      "Best MSE for Lasso: 2179098.1313627465\n",
      "Best parameters for Ridge: {'alpha': 1}\n",
      "Best MSE for Ridge: 2179159.6774081877\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters and scores\n",
    "print(\"Best parameters for Lasso:\", grid_search_lasso.best_params_)\n",
    "print(\"Best MSE for Lasso:\", -grid_search_lasso.best_score_)\n",
    "\n",
    "print(\"Best parameters for Ridge:\", grid_search_ridge.best_params_)\n",
    "print(\"Best MSE for Ridge:\", -grid_search_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Does feature standardization play a role in improving the model performance (in the cases with ridge regularization)? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge regularization is sensitive to the scale of the features. Scaling the features ensures that all features contribute uniformly to the regularization process. Ridge regularization is also often optimized using gradient descent which allows for smoother progress towards the optimal solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Some linear regression packages return p-values for different features. What is the meaning of these p-values and how can you infer the most significant features? A qualitative reasoning is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-values represent the probability that there is no relationship between the target and dependent variables. Features with lower p-values are considered statistically significant and more likely to contribute to the prediction of target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform polynomial regression by crafting products of features you selected in part 3.1.4 up to a certain degree (max degree 6) and applying ridge regression on the compound features. You can use scikit-learn library to build such features. Avoid overfitting by proper regularization. Answer the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Mutual Information: Index(['Unnamed: 0', 'color', 'cut', 'symmetry', 'polish'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using mutual information\n",
    "mi_selector = SelectKBest(mutual_info_regression, k=5)\n",
    "X_train_mi = mi_selector.fit_transform(X_train, Y_train)\n",
    "selected_features_mi_indices = mi_selector.get_support(indices=True)\n",
    "selected_features_mi = X.columns[selected_features_mi_indices]\n",
    "\n",
    "print(\"Selected features using Mutual Information:\", selected_features_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using F-scores: Index(['Unnamed: 0', 'color', 'cut', 'symmetry', 'polish'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using F-scores\n",
    "f_selector = SelectKBest(f_regression, k=5)\n",
    "X_train_f = f_selector.fit_transform(X_train, Y_train)\n",
    "selected_features_f_indices = f_selector.get_support(indices=True)\n",
    "selected_features_f = X.columns[selected_features_f_indices]\n",
    "\n",
    "print(\"Selected features using F-scores:\", selected_features_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_indices = list(set(selected_features_mi_indices) | set(selected_features_f_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00455306, -0.00981083,  0.19071851, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.06142336, -0.13451686, -0.06075226, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.95929846, -0.60839976, -0.31222303, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.414363  ,  1.28713185,  0.14042435, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.88858752,  1.73607355,  0.01468897, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.06674278,  0.36430725,  0.7439542 , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array = X_train.to_numpy()\n",
    "X_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_scores = []\n",
    "mean_train_scores = []\n",
    "\n",
    "for degree in degrees:\n",
    "  poly_transform = PolynomialFeatures(degree=degree)\n",
    "  X_poly = poly_transform.fit_transform(X_train_array[:, selected_features_indices])\n",
    "\n",
    "  # Standardization of features\n",
    "  scaler = StandardScaler()\n",
    "  X_poly_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "  # Ridge Regression\n",
    "  r_model = Ridge(alpha=1, random_state=42)\n",
    "\n",
    "  # 10 fold CV\n",
    "  grid_search = GridSearchCV(r_model, param_grid={}, cv=10, scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "  \n",
    "  grid_search.fit(X_poly_scaled, Y_train)\n",
    "\n",
    "  mean_test_scores.append(grid_search.cv_results_['mean_test_score'])\n",
    "  mean_train_scores.append(grid_search.cv_results_['mean_train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_scores = np.array(mean_test_scores)\n",
    "mean_train_scores = np.array(mean_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_test_score  mean_train_score  param_poly_transform__degree\n",
      "0     -1822.669644      -1821.699859                             1\n",
      "1     -1292.226781       -974.399664                             2\n",
      "2     -2062.737749       -631.944789                             3\n",
      "3     -1356.735857       -479.220262                             4\n",
      "4     -1054.456174       -426.467604                             5\n",
      "5     -1167.782082       -408.617347                             6\n"
     ]
    }
   ],
   "source": [
    "poly_result = pd.DataFrame({'mean_test_score': mean_test_scores.mean(axis=1),\n",
    "                            'mean_train_score': mean_train_scores.mean(axis=1),\n",
    "                            'param_poly_transform__degree': degrees})\n",
    "print(poly_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2062.73774857]\n",
      "[-1821.69985923]\n"
     ]
    }
   ],
   "source": [
    "# Polynomial degree = 3\n",
    "print(min(mean_test_scores))\n",
    "print(min(mean_train_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 What are the most salient features? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most salient features are 'color', 'clarity', 'symmetry', 'polish' and 'depth_percent'. These features are determinant of the diamonds quallity and consequently their price. Color of the diamond affects its value. Clarity refers to internal flaws therefore higher the clarity the more valuable the diamond. Symmetry is an important aspect of the diamond's cit quality and diamonds with excellent symmetry are more desirable. Polish  refers to the smoothness of the diamond the more polished the diamond is the greater is the value. Depth Percentage is a measure of the depth of the diamond relative to its width. THis affects the value of the diamond as well. Therefore the most salient features are those with greatest absolute coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 What degree of polynomial is best? How did you find the optimal degree? What does a very high-order polynomial imply about the fit on the training data? What about its performance on testing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial degree of 3 is the best as it has lowest test error and the train error is relatively low as well. Therefore the model is able to learn and generalize well on test data. A high order polynomial overfits on the train data since its train error is significantly lower than the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "You will train a multi-layer perceptron (fully connected neural network). You can simply use the sklearn implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "hidden_layers = [(50,), (100,), (50, 50), (100, 50)]\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1]  # Regularization strength\n",
    "best_mse = float('inf')\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search with for loop\n",
    "for layer in hidden_layers:\n",
    "    for a in alphas:\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=layer,\n",
    "                           alpha=a,\n",
    "                           activation='relu',\n",
    "                           solver='adam',\n",
    "                           random_state=42)\n",
    "\n",
    "        mlp.fit(X_train, Y_train)\n",
    "\n",
    "        y_pred = mlp.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(Y_test, y_pred)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = {\n",
    "                'hidden_layer_sizes': layer,\n",
    "                'alpha': a\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MSE: 110032.51057070299\n",
      "Best Parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MSE:\", best_mse)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Adjust your network size (number of hidden neurons and depth), and weight decay as regularization. Find a good hyper-parameter set systematically (no more than 20 experiments in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters for the network is (100,50) for hidden_layer_sizes and 0.1 for alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 How does the performance generally compare with linear regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 What activation function did you use for the output and why? You may use none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No activation function was used since this is a regression task. The output needs to be a real number within the range of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 What is the risk of increasing the depth of the network too far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The risk of increasing the depth of the network too far is overfitting to the training data. The training could also have an impact on the memory as it could take longer. Increasing the depth of the network could also cause vanishing or exploding gradients which is a problem because it could lead to unstable training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a random forest regression model on datasets, and answer the following:\n",
    "- Random forests have the following hyper-parameters:\n",
    "    - Maximum number of features;\n",
    "    - Number of trees;\n",
    "    - Depth of each tree;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 314.99716792487345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "num_trees = 100\n",
    "max_num_features = 'sqrt'\n",
    "max_depth_tree = None\n",
    "\n",
    "random_forest_model = RandomForestRegressor(\n",
    "    n_estimators= num_trees,\n",
    "    max_features= max_num_features,\n",
    "    max_depth= max_depth_tree,\n",
    "    random_state= 42,\n",
    "    oob_score=True\n",
    "\n",
    ")\n",
    "\n",
    "random_forest_model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, y_pred))\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1\n",
    "Explain how these hyper-parameters affect the overall performance. Describe if\n",
    "and how each hyper-parameter results in a regularization effect during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How each hyperparameter affects the overall performance:\n",
    "1. Maximum number of features\n",
    "    - The maximum number of features is used to measure the number of features each tree is allowed to considered when making a split. A large number of features increases the model complexity, while a small number of features decreases the model complexity, which helps prevent overfitting and improves the generalization to new data.\n",
    "2. Number of trees\n",
    "    - Increasing the number of trees improves the performance, but only up to a certain point. A larger number of trees helps provide better generalization which reduces the risk of overfitting.\n",
    "3. Depth of each tree\n",
    "    - A deeper tree will capture more complex relationships in the training data, but has a high chance of overfitting to the training data if the depth of the tree is not controlled.\n",
    "\n",
    "How each hyperparameter results in a regularization effect during training:\n",
    "1. Maximum number of features\n",
    "    - Reducing the maximum number of features results in a regularization effect during training. This is because this reduces the amount of information each tree can use for decision-making.\n",
    "2. Number of trees\n",
    "    - Multiple trees helps smooth out invidual tree biases and overall helps reduce overfitting to the training data.\n",
    "3. Depth of each tree\n",
    "    - Limiting the depth of each tree helps prevent the tree from growing too deep and overfitting to the noise in the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2\n",
    "How do random forests create a highly non-linear decision boundary despite the fact that all we do at each layer is apply a threshold on a feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests create a highly non-linear decision boundary by combining multiple decision trees, where each tree is trained on different parts of the data and features. Each tree is trained on a random portion of the initial training data by bootstrap sampling, which adds diversity to the trees and allows for various interpretations of the data. Furthermore, random feature selection at each node makes sure that every tree examines many facets of the data, avoiding the over-specialization of individual trees to certain features. Random Forests mimic extremely non-linear functions by combining estimates from various different trees, thereby capturing intricate links and interactions in the data. When compared to a single decision tree, this ensemble technique reduces the danger of overfitting while improving the robustness and generalization of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3\n",
    "Randomly pick a tree in your random forest model (with maximum depth of 4) and plot its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "random_forest_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    random_state=42, \n",
    "    oob_score= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACMYAAARNCAYAAACzYN4QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd3gU5d7G8e+ThBJAQrEXbBRFRUTFAiK9V0VFECmCvXvs56ivvbdjOR6lCIooilgRsPfeexdpKi30BJLn/WMwyAEVFBiyfD/X5SXZzO7cWUiyO3PP7wkxRiRJkiRJkiRJkiRJkqRMk5V2AEmSJEmSJEmSJEmSJGltsBgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZIkSZIkSZIkZSSLMZIkSZIkSZIkSZIkScpIFmMkSZIkSZIkSZIkSZKUkSzGSJIkSZIkSZIkSZIkKSNZjJEkSZIkSZIkSZIkSVJGshgjSZIkSZIkSZIkSZKkjGQxRpIkSZIkSZIkSZIkSRkpJ+0AkiRJkiQpc1WsWPHMcuXK9isuKq6cdhatf0IISyLxw/z8OUfFGH9JO48kSZIkSco8IcaYdgZJkiRJkpSBKlaocNFmm2165qDbb6mwycbVCSGkHUnrmUUFBQy7977Fg+++Z+K8+fP3ijHOTjuTJEmSJEnKLBZjJEmSJEnSGhdCCGXKlFn49cfvltt6q63SjqP1WIyRlh26zH/+xZePjjGOSDuPJEmSJEnKLFlpB5AkSZIkSRmpUoBsSzH6MyEEdq27cxlgi7SzSJIkSZKkzGMxRpIkSZIkrRUhhFI9pvb5F1/mtLPOTWXfn3/xJQ32a0KF6lswe3b+Cp9//sWXqVF7F5q37UTztp2YN28eALXr7Vly24MPPwLA7XcO5sBW7dm/WSvOveD/1unXsaqysrJcZ0uSJEmSJK0VOWkHkCRJkiRJKu1ijITw+92ORYsWUbZsWbKyVu0apW223ornnnqcbof1+t1tDu7amRuuvmK52ypVrMizTz223G1H9TmC4wb2B6B52058/8NEttu2xirlkCRJkiRJKu2cGCNJkiRJkjYoMUZOPfMcmrRqR8v2XZj44ySmTJ1K607daNamI/2PPYHi4uLl7jNq9Bj2a9qS/Zu1YvQjSfGk3zEncPwpZ9C2y8FMmjx5pft66513Of6UM2jXpTsFBQWrnLFixYrk5VX+w20eefxJDmzVniuuub7ktoWLFtG8bScOPaIv0376CYCyZcsCsGTJEirnVWbj6tVWOYckSZIkSVJp58QYSZIkSZK0QXl87DgKCxfz4oSxABQXF3PaWedx8vHH0rFdG846/wIeefxJqlapAkBRURGXXnkNr7/wNACNmreha6cOAOy2S11uu+m65R5/7ty5DLp7OE+MHc+uu+zMwP592GP3egDMnDmL7j2PXCHTLTdcQ92dd1rlr2GvBvX5/P23yMrKole/gTz93PO0bNaUl59+iurVq/HoE2M587wLGD7oDgAuueJqhgy/l5bNm1KxYsXVer4kSZIkSZJKMyfGSJIkSZKkDcrnX3xJk8b7l3yclZXFV998w94N9gCg4V578tXX35R8fvr0GWy11Zbk5uaSm5vLVlttyS+/TAdgn4Z7rfD4U6ZOY/Dd91B/99045qh+JaUYgGrVqvLsU4+t8N/qlGIAKlWqRNmyZcnJyeHgrp15/4MPAai+dBpM5w7t+OLLr0q2/9e5Z/Hlh+8w7aefeeW1N1ZrX5IkSZIkSaWZxRhJkiRJkrRBqVO7Fi+98lrJx8XFxdTcYQfefOddAN58+x1q1dyx5PMbb1ydSZMms3DhQhYuXMikSZPZZJONgaRUs7LH//CtV+nSsQPX3vRvWnfsxu13DqaoqIiZM2fRvG2nFf779LPPV+tryM+fU/LnF19+lR132IGCgoKS5ZreeuddttxyC4CS23JycqhUsSIVKuSu1r4kSZIkSZJKM5dSkiRJkiRJG5RO7dsy/ulnOaBlW8qVLcfgO27l7DNOoe/A47nuxn+z3Xbb0qVje158+VUAsrOzOf/sf9CsbSdCgPPP/sdKCzH/q/H++9J4/32ZN28eox5+hMLCwpKJMX/mp59+pvdRx/DBxx9zUI8jOOXE4+jSsT0DTziZO2+9mZEPjmbw3cMpW7YM9Xbdla6dOjB12jQ6dz+cShUrkpOTU7LE04WXXsGbb73D4iWLadK4EQ3q7/73nkBJkiRJkqRSJMQY084gSZIkSZIyTAhho3Jly85YMHNambSzaP132lnnLr75tjvOjTFel3YWSZIkSZKUWVxKSZIkSZIkSZIkSZIkSRnJYowkSZIkSZIkSZIkSZIyksUYSZIkSZK0QWjethOzZ+enHeN39Rl4HAe0bEuj5q0Z/8yzADzw0MPs17QlTVq149QzzynZdsrUqRzUozct23fhH+f+E4D/u+xK6u29P83bdmLgCSeXbPvyq6/TumM3WrTrzPD77gfgrPMvYOuadTntrHOXe8zWnbrRrE1H/u+yK0tuv+2Ou2jcog1tOh/Ezz//skLuTz/7nPbdDqFFu85ce+PNv/u1LFmyhMP7HEXT1h1o2roD3373/Rp65iRJkiRJkn5fTtoBJEmSJEmS/q7i4mKystbO9T//+9h/tq+/muVf55xJzR13YNas2bTu1I3WLZrTcK89efmZcWRnZ9Oz7wBef/Mt9m24N2eedwE3XnMFNbbZernHuPiC8+naqUPJx4sWLeKq62/ksYdGUq5cuZLbTzvpeNq1bsWjTzxZctuV197IGaecSJuWLejVbyCffvY5m226KSMffIgXJ4zliafGc/UNN3HtFZcut89zLvg/Rgy5iypV8v7wa3n19TepVKkiz49/grHjJ3DrHXdy3ZWXrfbzJEmSJEmStDqcGCNJkiRJkta6jz/5lP2btaJFu84ce9JpADz3wkvsuf+BHNSjN83adOT9Dz/i+RdfLpli8v0PE+nW4wgArr3xZlq278JejZry6BNjgWRCSt+jj6dT9x68+fY7XHntDTRr05EDWrbljbfeBmDEAw+yd+Nm9DiyP7Nmz/7dfCu7b/19GnPaWedyWO9+K+zrnH9dRJNW7WjWpiOff/HlCtv/FTV33AGA8uWXFVi227YG2dnZAJQrV46srCyWLFnCt999x7kX/B/N23bi6eeeL9n+kiuupmnrDjw+dhwAr73xFrnly9OtxxF06t6D73+YCMAWm29OCGG5/X/97bfU3203ABrUr8eLr7zGm++8Q9MDGpOVlUW71i1Lnptffff9DxQUFNDv2BNo3bEb73/40R9+LYsXLwFg9uw5VK9W7S89T5IkSZIkSavDiTGSJEmSJGmtG//Mswzo14f+Rx5BcXExAOdfdDHjHh1NXl5l6u/T+A/vf/zRA/jHqScze3Y+bbscTOcO7QDYbNNNGPrf2/j4k0/5+NPPeG7c40yfPoOe/QYwdsyDXHP9Tbz2/AQKCwvZYZf6K33sld13/GMPM3fePAb260PdnXfi/y67smRf777/Ad98+x0vThjLx598yjkX/B9j7r93ue1/a8QDD3LX4LuXu22bbbbm7jtvX2me8y+6hBOPO3q52956512mTptGw732ZOq0aXzw0SeMGDqIKnl5tGjfmbdfeZ4Tjz2aC88/hxkzZtK6Uzca77cv0376ma++/obXnp/Aex98yFnnX8AD9wxd6X53rbszz7zwIj26H8SzL7zEAfvvR+XKG5GXVxmAnJwcCgsXL3efaT/9xEcff8on77zO7Px8+g48jhcmLJtC89uvZfPNNmXOnLnsuue+LFy0iNeem7DSHJIkSZIkSWuSxRhJkiRJkrTW9T2iF5dedQ29+g2kTasWHNmzBwUFhWy8cXUAdq+XTCr57RSTGGPJn++9fxTDR4wkOyubHydNLrl9n733AuDTz7/gzbffoXnbTgAsWLiQX6ZPZ4stNqd8+fKUL1+eOrVqrjTbyu4LsFGlSsuVXH7d11dff8PeezYAYNdd6jJ16rSVbv+rnod2p+eh3VfpefrPXUMoLFxMn16Hl9z2/Q8TOe2scxl93z0AVMnLY4fttmX77bYFYKuttmT69BlsuukmAFSvXo19G+7NV998Q5Uqldlvn4aUL1+e/fZpyKlnnvu7+z7njNM4/tQzGDr8XrbZeis233wzqlbJ4/PPvwCgqKiIsmXLLHefKnl51N99N6pWrULVqlVYVFDwu1/L0HtGsMvOOzF65HCeff5FzrvoYu667d+r9LxIkiRJkiT9VRZjJEmSJEnSWpebW57rr7qcGCO7NNiXnod2p2zZMsyYMZO8vMp8+NHHAFStWoVJk6cA8N4HH5bc/4abb+ODN19m3rz51GvYqOT2rKxkleid6tSm0X77MuSOWwEoLCwkOzubqVOnUVBQQGFhIV9+/c1Ks63svr997P/dV80dd2DU6DFAMm1miy02X+n2v1rViTGPjx3H2PETGH3f8JLbZs2aTa9+A7jrtn+XFF9yc3PZdJNNmDlzFhUrVmDKlKlUr16N/Pw55OVVprCwkHfff58LzzubHbffnutuvIUYI199/Q2bbbbpSjMCVKtWlZHDBlNcXMyRA46lXauWZGdnc9W1NxJjZPwzz5aUg35Vq+aO5OfnU1BQwPz5C8jJyf7dr6WoqJiNN06WT9p44+rk58/53SySJEmSJElrisUYSZIkSZK01o144EGG3zuSGCNtW7cgJyeHSy/8F206H0SNbbZhyy22AGC3XeqyeMkSWnfsRv3ddyu5/4EHNOLA1u1pUL8+VZYu7fNb9Xbdhbo71aFZm45kZWWx7z57c9lF/+KMU0+icYu21K5Vk2232Wal2X7vvr9nzz3qs/1223JAy7ZkhSxuv/n6P/zaV3VizMDjT6bGNlvTqkNXypQtw7hHR3PV9TcyafIUTjj1HwD885wzad60CVdcciHdDutF4eJCzjztZLKzs/nHef/ks8+/oKioiAH9+pQUaQ45uBtNW3cgErn1husAuPbGm7n/wYf5Zfp0fpw0mQdHDOOpCU9zzfU3E0LguKOPKinRdO/WhSat2lGhQgWG3fkfAK667kYO7tqZmjvuwNlnnEarjl1ZsmQJl110we9+LUf0OIQefY7ikceepHBxITdfd/WfPieSJEmSJEl/V/jtWGJJkiRJkqQ1IYSwUbmyZWcsmDmtzJ9vDf2OOYFTTjiW+vV2+/ONlXFOO+vcxTffdse5Mcbr0s4iSZIkSZIyixNjJEmSJEnSBuOLL7/iuJNPX+6222++njq1a6WUSJIkSZIkSWuTxRhJkiRJkpS6IXfcuk72U6d2LZ596rF1si9JkiRJkiSlLyvtAJIkSZIkSZIkSZIkSdLaYDFGkiRJkiTpL2qwX5O1+vgfffwpzdt2onnbTtTfpzEHH34kAP2OOYGGBzSnedtO/Ov/LgNg+H33l2y73U678e/b7ih5nLlz57JpjZqMeewJAH7++RfadjmYxi3acNsdd63Vr0GSJEmSJClNLqUkSZIkSZK0ntpt17olSz9ddOkV7LjjDiWf+++tN1G/3m4lH/c+/DB6H34YAM3bdqJLpw4ln7vh37ex1557lHx89Q03ccIxA+nQtjVN23TgsO4HUb16tbX95UiSJEmSJK1zToyRJEmSJEkZ6+NPPmX/Zq1o0a4zx550GgDX3ngzLdt3Ya9GTXn0ibEA/N9lV9Kr30A6HHQorTp0ZdDdw2nVoSttOh9EUVERz7/4Mq07daPLoT3Zu3Ez3nz7neX2M336DLr1OIKW7btw6BF9WbRo0Ur3/Xc8+sRYunRoB0AIcPwpp9OqQ1def/Ot5babMnUqS4qWUGObrQGYOXMWX3z1NfvstWfJNq+98SZtW7UgKyuL5gc24a133/3b+SRJkiRJktZHToyRJEmSJEkZa/wzzzKgXx/6H3kExcXFABx/9AD+cerJzJ6dT9suB9N5admkds0dufD8czj6xFOYPHkKE54Yw9EnnsKrr78JwLx583jqkYeY+OMkjjr2RJ4Z+2jJfq66/kaOG9if1i2ac9sdd3HPyAeYM2fOCvv+rT4Dj+PHHyctd9uA/n3oeWj3Fbb94KOP2W7bbalcuTIA11x2CdWrV+OHiT/S9dCevPvai4QQAHhw9CN079ql5L7X3Hgzp510PE+MHVdyW0FBIWXKlAGgSpU8Zs6avdrPrSRJkiRJUmlgMUaSJEmSJGWsvkf04tKrrqFXv4G0adWCI3v24N77RzF8xEiys7L5cdLkkm3r7bYrAFttsQW77bpLyZ9nzppFXuXK1K9Xj6ysLLbbtgaz8/OX28+nn3/BG2+9zZXX3MCigkV0at+OY47qt8K+f+vuO29f5a/jgYce5tCDu5Z8/OuyR9vW2IYtt9yC6dNnsMkmGwPw4JhHGDlsMADTfvqJ73+YyF4N9liuGFOuXFmWLFlCTk4O+flz2KlO7VXOIkmSJEmSVJpYjJEkSZIkSRkrN7c81191OTFGdmmwLz0P7c4NN9/GB2++zLx586nXsFHJtr9OXPnfP8cYAfjw44+JMTLxx0lUyctbbj871a5Fx3ZtaXbgAQAUFhZSVFS0wr5zcpYdilmdiTFPjB3HeWeeXvJxfv4c8vIqk58/hx9/nFRSlJn44yRysnPYcostAPj408/4cdIk2nXtzjfffsdjTz5FvV13Yd+GezPh2edo26olz7/4Micee/TqPbGSJEmSJEmlhMUYSZIkSZKUsUY88CDD7x1JjJG2rVuQk5PDgQc04sDW7WlQvz5V8iqv8mNVqVKFLof2ZOrUafz7+quX+9x5Z57BMSedymVXXQvAv849i6+//XaFff/Wqk6Mefvd96hdqyYVK1Ysua1nvwHMnTuXJUuWcPnFF5KVlQXAqNEP073bsmWUWjZrSstmTQH4v8uuZPd6u7HD9ttx1mmncOTAY7nsqmvp0f3gkmKNJEmSJElSpgm/XvUkSZIkSZK0poQQNipXtuyMBTOnlUk7y5rw/Isv88jjT3DD1VekHSUjnXbWuYtvvu2Oc2OM16WdRZIkSZIkZZastANIkiRJkiRJkiRJkiRJa4NLKUmSJEmSJP2Jpk0a07RJ47RjSJIkSZIkaTU5MUaSJEmSJG3wGuzXZK3v48dJk2jcog3N23aiZfsuTJk6FYCjTzyFZm06sk+TFowaPQaARx5/kiat2tGkVTv6Hn08RUVFAFx7483s17Ql+zVtyZPjJiz3+L/8Mp0W7TpzYKv2tGzfhR8m/gjAJ59+RtPWHWjaugN3DrkbgBdeeoX9m7WiaesO9Ow7gMWLF6/1r1+SJEmSJCkNIcaYdgZJkiRJkpRhQggblStbdsaCmdPKpJ1lVTTYrwnvvvbiWt1HUVERIQSysrIYes8IfvhhIheefw6FhYWULVuWuXPn0rhFWz5485WS2wD6HXMCfXodzgGN9qP+Po354M1XmDt3Hu26Hsyrzy0rx8ybN4/58xew2WabMu7pZxjz6BPcfvP1dD7kcK657GJq16pJm04HMXLYYBYuWkj1atUoX7485114MfV23YUehxy8Vr/+P3LaWecuvvm2O86NMV6XWghJkiRJkpSRnBgjSZIkSZIy0slnnM3Lr74OwNvvvsfRJ57CTz/9TKsOXWnaugOdDzmcgoKC5e7T75gTeP/DjwD4v8uuZMxjTwBw5bU30KxNRw5o2ZY33nr7L+XJzs4mKys5FDNv7jx2qbszQEkBZsGChexUp/Zyt8UYiTGy/Xbbkp2dTY0a21BQUMCcuXOoUqXKco9fqVIlNttsUwDKlS1Xsq8pU6ZSp3YtQgjUqV2LN995h6223JLy5csv3bZsybaSJEmSJEmZxqMekiRJkiQpI/U45CDuf3A0ACNHPcThh3SnatUqjH3kQZ4f/wS77VKXx5586k8f5+NPPuXjTz/juXGP8/DIe/nXxZetsE2bzgfRvG2n5f579vkVJ9C8+fY77Ne0JbfccSd77lG/5PaDDz+S3fdpTNvWLUtu++/goezSYF9mzJzJZptuAsCBjRtRt8E+7NOkJf845aSV5i0oKODiy6/ipOOOBmCH7bfj1dffYNGiRbzy2uvMmpVfsu133//A+GeepWunDn/6PEiSJEmSJJVGOWkHkCRJkiRJWhv233cfzjjnfBYvXswrr73O1ZddzM+//MJxp5zBrJmz+PmX6Wy2ySbL3SeEZX/+dfnpTz//gjfffofmbTsBsGDhwhX2Ne7R0auUqeFee/La809z/4Ojufya67jz1psBeOi+YcycOYt9DmxB78MPIycnh6P792Vgvz6ceNqZPDjmURru2YBxE57hq4/eZdas2XTq3oPXX3h6ucePMXLUcSdx7MD+JdNnrr7sYk464yyKioqoXasmW2y+GQCzZs3myAHHMPg/t5ZMqJEkSZIkSco0FmMkSZIkSVLGanZgEy6+/Gr233cfsrKyGHH/KFo3b8ZxRx/F+RddQiQut33VKlWYNHkK9evtxnsffkT93euxU53aNNpvX4bccSsAhYWFK+ynTeeDWFy4eLnb/nnOmTRv2qTk44KCAsqVKwdAlSp5VMitsNztFStWYKNKlcjOzi65LYRAXl5lKuTmUlRUROW8yuTk5FC58kYsXElB59wL/o9d6+7MoQd3K7ltu21r8NiDIykoKKBHn6PYt+FeFBQUcNiR/bj0wn9Rp3atv/jsSpIkSZIkrf8sxkiSJEmSpIx1+CHd2bPRgbz63HgAmjc9kD4DjuWpp59ho0qV2HSTjZfbvs8RPekz4FiGDLuXckunqNTbdRfq7lSHZm06kpWVxb777M1lF/1rufutysSY1998mwsvuZzs7GzKlivLXbcl02K6HNqTwoJCChcXcu6ZpxNC4PY7B/Ho42MpLi6mZs0d6NKxPdnZ2eyw3bYc0LIthYWLOePUZCmlofeMoOYOO1C9WlVu+PdtNNp3H8Y//Sx779WAqy79P4beM4Lh944kKyuLC847m/Lly3P7nYP54MOP+b/LrgRgQP8+9Dy0+997siVJkiRJktZD4dexwJIkSZIkSWtKCGGjcmXLzlgwc1qZtLNo/XfaWecuvvm2O86NMV6XdhZJkiRJkpRZstIOIEmSJEmSMtKSouKirOLi4rRzqBRYsHBhEbD4TzeUJEmSJElaTRZjJEmSJEnSGhdjXFi2bLkZYx57Iu0oWs/NmDGTp8Y/XQR8nnYWSZIkSZKUeVxKSZIkSZIkrRUhhL0q5OY+e3C3Ljlbbr55uZAVVrrd0mMTgRhDTO4XgRjCyrfX+umv/D0uWLCgaMxjTxROnzHzzgULFpwePVAlSZIkSZLWMIsxkiRJkiRprQkh1AJaAVVX8unNgL2A3YGpwNvAp0DROguotWVzlv3dTib5u/2MFf9uC0n+zp+0FCNJkiRJktYGizGSJEmSJGmdCSFUBnoAA4AtgcHAkBjjd6kG01oRQsgFDiL5+94FuAcYFGP8JNVgkiRJkiRpg2ExRpIkSZIkrVUhWUtnf5JyRDfgGWAQMC7G6HSYDUQIoSbQH+gLfA/cBTwQY5yXYixJkiRJkpThLMZIkiRJkqS1IoSwKdCbpBCTRVKEGBZj/CnVYEpVCCEHaA8cBTQBHiT5t/GmyylJkiRJkqQ1zWKMJEmSJElaY0II2UArkjJMS2AMSenhFUsP+l8hhC2BPiQlmYUk/1buiTHOSDWYJEmSJEnKGBZjJEmSJEnS3xZC2BboR7JUzk8kSyXdF2PMTzWYSoUQQhbJ9JgBQEfgKZKSzLMxxuI0s0mSJEmSpNLNYowkSZIkSfpLQgjlgM4kZYa9gBHAoBjj+2nmUukWQqgK9CL5d5UHDAaGxBgnpRpMkiRJkiSVShZjJEmSJEnSagkh7EKy9M0RwMckkz0ejjEuTDWYMkoIIQANSAoyhwGvkfxbezzGuDjNbJIkSZIkqfSwGCNJkiRJkv5UCKEScChJSWE7YCgwOMb4dYqxtIEIIVQAupP8+6sNDCOZTvRFqsEkSZIkSdJ6z2KMJEmSJElaqaUTOxqSlBG6Ay+STOwYG2NckmY2bbhCCHVIJhYdCXwJDAJGxRgXpBpMkiRJkiStlyzGSJIkSZKk5YQQNiZZJukoIJekDHN3jHFqqsGk3wghlAE6khS39gPuJ/m3+m70gJckSZIkSVrKYowkSZIkSSKEkAU0JykZtAUeJykZvBhjLE4zm/RnQghbA31Jylz5JP92740xzkozlyRJkiRJSp/FGEmSJEmSNmBLCwX9gP4khYI7gREWClQa/U7BaxDwggUvSZIkSZI2TBZjJEmSJEnawCxdgqYTyXSN/YCRJOUBl6BRxgghVCdZEmwAyZJgg0iWBJuSajBJkiRJkrROWYyRJEmSJGkDEUKoQ1KGORL4kmS5mQdjjAtSDSatRSGEADQk+bd/CPASyb/9J2OMS9LMJkmSJEmS1j6LMZIkSZIkZbAQQkWgO8nUjFrA3cDgGOMXqQaTUhBCqAQcSvL9sB0wlOT74esUY0mSJEmSpLXIYowkSZIkSRlm6YSMPUkmZBwGvEqyjMzjMcbFaWaT1hchhLok3yO9gU9IpsiMjjEuTDWYJEmSJElaoyzGSJIkSZKUIUIIVYFeJNMw8kjKMENjjJNSDSatx0II5YDOJCWZvYH7gLtijO+nmUuSJEmSJK0ZFmMkSZIkSSrFQghZwIEkZZgOwFiSyRfPxRiL08wmlTYhhG2BfkB/4GeS76X7Yoz5qQaTJEmSJEl/mcUYSZIkSZJKoRDClkAfkikXC0lO4N8TY5yRajApA4QQsoFWJN9frYBHSL7HXo4eTJMkSZIkqVSxGCNJkiRJUikRQsgB2pNMhzkAGEWyXNKbnqyX1o4QwqZAb5LvuyyS77m7Y4w/pRpMkiRJkiStEosxkiRJkiSt50IINUkmV/QBvieZXPFAjHFemrmkDUkIIQD7kRRkDgKeJfleHBdjLEozmyRJkiRJ+n0WYyRJkiRJWg+FEHJJTr4PAHYBhgODYoyfphpMEiGEykAPksLaVsAQYHCM8btUg0mSJEmSpBVYjJEkSZIkaT0SQqhPUoY5HHiLZNmWR2OMBWnmkrRyIYR6JAWZXsB7JN+zY2KMi1INJkmSJEmSAIsxkiRJkiSlLoSQB/QkObm+KTAYGBJj/CHVYJJWWQihPNCVpNi2O3AvyZSnj9LMJUmSJEnShs5ijCRJkiRJKQghBKAxyUn0LsAE4C7g6RhjUZrZJP09IYQdgP5AX2Ayyff2yBjj3DRzSZIkSZK0IbIYI0mSJEnSOhRC2AzoQzIdpohk2ZXhMcafUw0maY0LIeQAbUgKcM2Ah0hKMq9HD8pJkiRJkrROWIyRJEmSJGktCyFks+zkeHNgNMnJ8dc8OS5tGEIImwNHkvwcWMyyUtwvqQaTJEmSJCnDWYyRJEmSJGktCSFsT7KcSj+WLadyf4xxTqrBJKVm6TJqB5AUZDoD41m2jFpxmtkkSZIkScpEFmMkSZIkSVqDQgjlga4kSyXtAdwLDIoxfphmLknrnxBCFeBwkpLMxsBgYEiMcWKauSRJkiRJyiQWYyRJkiRJWgNCCLuRlGF6AR+QTIAYE2NclGowSaVCCGEPkp8hhwNvkiy19GiMsTDVYJIkSZIklXIWYyRJkiRJ+otCCBsBPUimPWwFDCGZ9vBtqsEklVohhFzgYJKfKzsDw0mmTn2WajBJkiRJkkopizGSJEmSJK2GEEIA9iOZ7HAQ8DzJdJhxMcYlKUaTlGFCCLWA/kBf4FuSnzUPxBjnp5lLkiRJkqTSxGKMJEmSJEmrIISwCdCbZIpDDskJ6mExxmmpBpOU8UIIZYD2JIW8xsAokqWW3ooe3JMkSZIk6Q9ZjJEkSZIk6XeEELKBliRlmFbAIyQno1/yZLSkNIQQtgL6kJRk5pOU9O6JMc5MNZgkSZIkSespizGSJEmSJP2PEEINoB/JEibTSU483xdjnJ1mLkn6VQghCziQpLjXARhL8rPquRhjcZrZJEmSJElan1iMkSRJkiQJCCGUBTqTnGTeG7gPGBRjfC/VYJL0J0II1YBeJD+/NiKZbDU0xjg51WCSJEmSJK0HLMZIkiRJkjZoIYS6JEuS9AY+ITmh/FCMcWGqwSRpNYUQArAnSUHmUOBVkikyT8QYF6eZTZIkSZKktFiMkSRJkiRtcEIIlYBDSE4e7wAMBQbHGL9KM5ckrSkhhIpAd5KfczWBYSRTsL5MNZgkSZIkSeuYxRhJkiRJ0gZh6SSFvUlOEh8CvEQySWGskxQkZbIQwk4kk7GOBD4n+dn3UIxxQarBJEmSJElaByzGSJIkSZIyWgihOnAEyUnhiiRLJd0dY5ycajBJWsdCCGWBjiQFwX2BkcBdMcZ3Uw0mSZIkSdJaZDFGkiRJkpRxQghZQDOSk7/tgCdIJiS8EGMsTjObJK0PQgjbAP2A/sBMktLgiBjjrFSDSZIkSZK0hlmMkSRJkiRljBDC1kBfkhO9c0nKMPfGGGemmUuS1ldLi4QtSIqEbYDHSH52vhg9cChJkiRJygAWYyRJkiRJpVoIoQzJ0iBHAfsDD5Cc1H3Hk7qStOpCCBsDvUlKMmVZtvTc1FSDSZIkSZL0N1iMkSRJkiSVSiGE2iRlmD7AVyRlmAdjjPNTDSZJpVwIIQD7kBRkDgZeICnJjI0xLkkzmyRJkiRJq8tijCRJkiSp1AghVAC6k5ysrQMMAwbFGD9PNZgkZagQwkbAoSQ/d2sAQ4HBMcZv0swlSZIkSdKqshgjSZIkSVrvhRAakJyU7QG8TjId5vEYY2GqwSRpAxJC2JVkUtcRwEckP4tHxxgXpRpMkiRJkqQ/YDFGkiRJkrReCiFUBXqSFGKqkizjMTTG+GOqwSRpAxdCKAd0Ifn53AAYQTK964NUg0mSJEmStBIWYyRJkiRJ640QQgCakJxs7QSMI5lI8EyMsTjNbJKkFYUQtgP6Af2BaSQ/s++LMc5JM5ckSZIkSb+yGCNJkiRJSl0IYQugD8kSHQUkJ1bviTFOTzWYJGmVhBCygdYkxcYWwMMkP8tfjR6AlCRJkiSlyGKMJEmSJCkVIYQcoB1JGeZA4EGS5ZLe8CSqJJVeIYTNgN4kJRlICjLDYow/p5dKkiRJkrShshgjSZIkSVqnQgg7kiy50ReYSHLC9IEY49w0c0mS1qyly+M1IilAdgOeJilAjo8xFqWZTZIkSZK04bAYI0mSJEla60II5YGDSKYH7AYMBwbFGD9JNZgkaZ0IIeQBPUh+D2wODAaGxBi/TzOXJEmSJCnzWYyRJEmSJK01IYTdSSYF9ATeIZkU8EiMsSDVYJKk1PzP74Z3SSaH+btBkiRJkrRWWIyRJEmSJK1RIYTKwOE4FUCS9AdCCLkkSywdRTJN7B6cJiZJkiRJWsMsxkiSJEmS/rYQQgAakZRhugJPk0wAmBBjLEoxmiSpFAgh7Aj0B/oBP5D8Drk/xjgv1WCSJEmSpFLPYowkSZIk6S8LIWwKHElSiIkkSyUNizH+nGowSVKpFELIAdqS/F45EHiIpCTzRvRApiRJkiTpL7AYI0mSJElaLSGEbKA1yUnLFsDDJCctX/WkpSRpTQkhbAH0IVlqqYDkd809McbpqQaTJEmSJJUqFmMkSZIkSaskhLAdy5a5mEpygnJkjHFOmrkkSZlt6XJ9TUgKmZ2AcSS/g56JMRanmU2SJEmStP6zGCNJkiRJ+l0hhHJAF5KTkQ2AEcCgGOMHqQaTJG2QQghVgJ7AQKAqMBgYEmP8Mc1ckiRJkqT1l8UYSZIkSdIKQgi7kixdcQTwIcmV+Q/HGBelGkySpKVCCA1Iips9gNdJflc9HmMsTDWYJEmSJGm9YjFGkiRJkgRACGEj4DCSQkwNYAjJVfjfpBpMkqQ/EEKoABxMUpLZCRhGMt3s81SDSZIkSZLWCxZjJEmSJGkDFkIIwD4kJxMPBl4gueL+qRjjkjSzSZK0ukIItYH+QF/gK2AQMCrGOD/NXJIkSZKk9FiMkSRJkqQNUAhhY6A3SSGmLEkZZliMcWqqwSRJWgNCCGWADiS/5/YHHiD5XfdO9ICoJEmSJG1QLMZIkiRJ0gYihJAFtCRZKqkN8BjJScIXPUkoScpUIYStSSbI9AfmkvzuuzfGODPNXJIkSZKkdcNijCRJkiRluBDCNkA/khOCs4A7gRExxtlp5pIkaV1aWhBtRjJFph3wBMlSS8/HGIvTzCZJkiRJWnssxkiSJElSBgohlAU6kZz82wcYCdwVY3w31WCSJK0HQgjVgV7AQKACSUFmaIxxSqrBJEmSJElrnMUYSZIkScogIYSdSJZKOhL4nGS5iIdijAtSDSZJ0noohBCAvUmKpIcAL5P87nwyxrg4zWySJEmSpDXDYowkSZIklXIhhIokJ/MGADWBocDgGOOXaeaSJKk0CSFUYtnv0x1Y9vv0qzRzSZIkSZL+HosxkiRJklQKLb3CfS+WXeH+KskV7k94hbskSX9PCGFnlk1g+5RlE9gWphpMkiRJkrTaLMZIkiRJUikSQqgG9CIpxGwEDAKGxhgnpxpMkqQMFEIoC3Qm+b27N3AfMCjG+F6qwSRJkiRJq8xijCRJkiSt50IIWUBTkivXOwBPkhRinosxFqcYTZKkDUYIoQbQD+gPTCeZInNfjHF2mrkkSZIkSX/MYowkSZIkradCCFsCfUkKMfNJTsDdG2OckWYuSZI2ZCGEbKAlye/n1sCjJL+jX4oebJUkSZKk9Y7FGEmSJElaj4QQygDtSZZsaAw8QHKy7W1PtkmStH4JIWwC9Cb5vZ0NDAbujjFOSzWYJEmSJKmExRhJkiRJWg+EEGqRLM3QF/iWpAwzKsY4L81ckiTpz4UQArAvSUHmYOA5kt/l42KMS9LMJkmSJEkbOosxkiRJkpSSEEIuycmzAUBdYBgwKMb4WarBJEnSXxZCqAwcRrLU0tbAUGBwjPHbNHNJkiRJ0obKYowkSZIkrWMhhD1IyjA9gDdJrih/LMZYmGowSZK0RoUQdiMpyBwBvE/yO39MjHFRmrkkSZIkaUNiMUaSJEmS1oEQQhXgcJJCzMbAYGBIjHFimrkkSdLaF0IoD3QheR2wB3AvcFeM8aNUg0mSJEnSBsBijCRJkiStJSGEABxAchKsMzCe5ErxZ2KMRWlmkyRJ6QghbA/0B/oBk4FBwMgY45xUg0mSJElShrIYI0mSJElrWAhhc6APydIJi0nKMPfEGH9JNZgkSVpvhBCygTYkBdrmwGiS1wyvRQ/aSpIkSdIaYzFGkiRJktaAEEIOy05uNWXZya3XPbklSZL+SAhhM+BIktcRxSSvIYZZqpUkSZKkv89ijCRJkiT9DSGEHVi2HMKPJCey7o8xzk01mCRJKnWWLsPYmKQg0wWYQLLU0gSXYZQkSZKkv8ZijCRJkiStphBCeaAbyVJJuwP3AINijB+nGkySJGWMEEIecDhJSWZTYDAwJMb4Q6rBJEmSJKmUsRgjSZIkSasohFCPpAzTC3iPZDrMmBhjQarBJElSRgsh1Cd5DdITeJvkNcijvgaRJEmSpD9nMUaSJEmS/kAIoTLQg+Rq7S1ZdrX2d6kGkyRJG5wQQi5wEMnrkl2A4SRT6z5NNZgkSZIkrccsxkiSJEnS/wghBGB/kiuzDwKeAQYB42KMRWlmkyRJAggh1AT6A32B70mmyDwQY5yXYixJkiRJWu9YjJEkSZKkpUIImwBHklyFnUVygmlYjPGnVINJkiT9jhBCDtCepNDbBHiQ5DXMm9GDv5IkSZJkMUaSJEnShi2EkA20IjmZ1Ap4hORk0sueTJIkSaVJCGFLoA/J65qFJK9p7okxzkg1mCRJkiSlyGKMJEmSpA1SCGFboB/JEgQ/k5w4ui/GmJ9qMEmSpL8phJBFMj1mANAReIrktc6zMcbiNLNJkiRJ0rpmMUaSJEnSBiOEUA7oTHKSaC9gBDAoxvh+mrkkSZLWlhBCVaAXyeufPGAQMDTGOCnVYJIkSZK0jliMkSRJkpTxQgh1SZYU6A18QnLF9OgY48JUg0mSJK0jIYQANCApyBwGvEbymujxGOPiNLNJkiRJ0tpkMUaSJElSRgohVAIOJTn5sx0wFBgcY/w6xViSJEmpCyFUALqTvE6qDdxNMkXvy1SDSZIkSdJaYDFGkiRJUsZYeiV0Q5KTPN2BF0mWC3gyxrgkzWySJEnroxDCTkB/oA/wBckUmQdjjAtSDSZJkiRJa4jFGEmSJEmlXgihOnAESSEml6QMc3eMcUqqwSRJkkqJEEIZoCPJ66n9gPtJSjLvRg8iS5IkSSrFLMZIkiRJKpVCCFlAc5KTN22Bx0lO3rwYYyxOM5skSVJpFkLYBuhLMklmNslrrBExxlkpxpIkSZKkv8RijCRJkqRSJYSwNdCP5ERNPsmJmns9USNJkrRm/UER+QWnyEiSJEkqLSzGSJIkSVrvOdpfkiQpXb9ZunIgUA4YDAyNMU5NNZgkSZIk/QmLMZIkSZLWWyGEOsBRwJHAlyRlmAdjjAtSDSZJkrSBCiEEoCFJYbk78CLJa7SxMcYlaWaTJEmSpJWxGCNJkiRpvRJCqAAcQlKIqQ0MAwbFGL9INZgkSZKWE0KoBBxKUpLZDhgKDI4xfp1iLEmSJElajsUYSZIkSalbeuVxA5KTKocBr5Fcefx4jHFxmtkkSZL050IIdUmKzb2Bj4FBwOgY48JUg0mSJEna4FmMkSRJkpSaEEJVoBdJISaP5ATK0BjjpFSDSZIk6S8JIZQDOpO8vtsLGAHcFWP8INVgkiRJkjZYFmMkSZIkrVNLp8McSHKypCPwFMl0mGdjjMVpZpMkSdKaE0LYFugH9Ad+JnnNd1+MMT/VYJIkSZI2KBZjJEmSJK0TIYQtgL4kJ0YWkZwYuSfGOCPNXJIkSVq7QgjZQCuSpZZaAWNIJgW+HD1ALUmSJGktsxgjSZIkaa0JIeQA7UimwzQBRpGcBHnTkyCSJEkbnhDCpkBvkteHWSRl6WExxp9SDSZJkiQpY1mMkSRJkrTGhRBqkkyG6Qt8T3LC44EY47wUY0mSJGk9sXR5zf1ICjIHAc+SvGYcF2MsSjObJEmSpMxiMUaSJEnSGhFCyCU5qXEUsCswHBgUY/w01WCSJElar4UQKgM9SF5HbgkMAYbEGL9LNZgkSZKkjGAxRpIkSdLfEkLYneRK357AWyRLJT0aYyxINZgkSZJKnRBCPZKCTC/gPZIpMmN8bSlJkiTpr7IYI0mSJGm1hRDygMNJCjGbAoNJrur9IdVgkiRJygghhPJAV5LXm7sD95BMI/w4zVySJEmSSh+LMZIkSZJWSQghAI1JruDtCkwguYL36RhjUYrRJEmSlMFCCDsA/YG+wCSS16D3xxjnpplLkiRJUulgMUaSJEnSHwohbAYcSXK1bhHJUknDY4w/pxpMkiRJG5QQQg7QhuR1aVPgIZLXpq9HD3RLkiRJ+h0WYyRJkiStIISQzbKTDs2Ah0muzH3Nkw6SJElKWwhhc5aVtxeTvFYdHmOcnmowSZIkSesdizGSJEmSSoQQtgf6Lf1vCsvG1M9JNZgkSZK0EkuX+zyApCDTGRjPsuU+i9PMJkmSJGn9YDFGkiRJ2sCFEMoBXUlOJuwB3AsMijF+mGYuSZIkaXWEEKoAh5O8rq0ODAaGxBh/TDOXJEmSpHRZjJEkSZI2UCGEXUlOGvQCPiC5snZMjHFRqsEkSZKkvymEsAdwFElR5k2S17qPxRgLUw0mSZIkaZ2zGCNJkiRtQEIIGwGHkRRitgaGAoNjjN+mmUuSJElaG0IIucDBJK9/dwaGk0xH/CzVYJIkSZLWGYsxkiRJUoYLIQRgX5KTAQcBz5NcMTsuxrgkxWiSJEnSOhNCqAX0B/oC35C8Jh4VY5yfZi5JkiRJa5fFGEmSJClDhRA2BnqTFGLKkBz4HxZjnJZqMEmSJClFIYQyQHuSpZYaA6NIXiu/HT1gLkmSJGUcizGSJElSBgkhZAEtScowrYFHSQ7yv+RBfkmSJGl5IYStgD4kJZl5wCDgnhjjzFSDSZIkSVpjLMZIkiRJGSCEsA3Qj2Q0/AySMsx9McbZaeaSJEmSSoOlBfMDSQrmHYAnSV5TPx9jLE4zmyRJkqS/x2KMJEmSVEqFEMoCnUgO3jcE7gMGxRjfSzWYJEmSVIqFEKoBvUheZ29EMkVmaIxxcqrBJEmSJP0lFmMkSZKkUiaEsDPJqPfewGckV7I+FGNcmGowSZIkKYOEEAKwJ0lB5lDgFZKSzBMxxsVpZpMkSZK06izGSJIkSaVACKEicAjJQfkdgaHA4BjjV2nmkiRJkjYES1+Pdyd5PV4TuJtkWqOvxyVJkqT1nMUYSZIkaT219ArVvUgOvh8CvExyheqTXqEqSZIkpSOEsBPJBMcjgc9ZNsFxQarBJEmSJK2UxRhJkiRpPRNCqAYcQXKwvRJJGebuGOPkVINJkiRJKhFCKAt0JCmy7wOMJJki826qwSRJkiQtx2KMJEmStB4IIWQBTUkOqrcHniC58vSFGGNxitEkSZIk/YkQwjZAP6A/MJPktfyIGOPsNHNJkiRJshgjSZIkpSqEsBXQl2Q6zFySA+j3xhhnpplLkiRJ0upbWnhvQVJ4bwM8SjIB8sXowXhJkiQpFRZjJEmSpHUshFAG6EBShmkEPEBSiHnHg+WSJElSZgghbAz0JinJlGHZEqnTUg0mSZIkbWAsxkiSJEnrSAihFkkZpg/wNUkZ5sEY4/xUg0mSJElaa0IIAdiHpCBzMPACyXuBp2KMS9LMJkmSJG0ILMZIkiRJa1EIoQLJwe8BwE7AMGBQjPHzVINJkiRJWudCCBsBh5K8P6gBDAEGxxi/TTWYJEmSlMEsxkiSJElrQQihAcl0mB7AGyRXhD4eYyxMNZgkSZKk9UIIYVeS9wxHAB+SvGd4OMa4KNVgkiRJUoaxGCNJkiStISGEKkBPkqs/qwGDgKExxh/TzCVJkiRp/RVCKAd0IXkf0QAYAdwVY/ww1WCSJElShrAYI0mSJP0NIYQANCG50rMzMI7kSs9nYozFaWaTJEmSVLqEELYD+gH9gakk7y1GxhjnpJlLkiRJKs0sxkiSJEl/QQhhc6APSSGmkOSA9T0xxumpBpMkSZJU6oUQsoHWJFNkWgAPk7zneDV6UF+SJElaLRZjJEmSpFUUQsgB2pIcnD4QeJBkuaQ3PDgtSZIkaW0IIWwG9CZ5HxJJ3oMMizH+nGowSZIkqZSwGCNJkiT9iRDCDiSjzPsBE0mu1Hwgxjg31WCSJEmSNhhLl3FtRDK1shvwNMl7kwkxxqI0s0mSJEnrM4sxkiRJ0kqEEMqTHGweANQDhgODYoyfpBpMkiRJ0gYvhJAH9CB5v7IZMAQYEmP8Ps1ckiRJ0vrIYowkSZL0GyGEeiQHl3sC75JcgflIjLEg1WCSJEmStBIhhN1Jpsj0BN4hWWrJ9zCSJEnSUhZjJEmStMELIVRm2dWWWwCD8WpLSZIkSaVICCGXZOrlUcBuwD049VKSJEmyGCNJkqQNUwghAPuTlGG6Ac+QTIcZH2MsSjObJEmSJP0dIYQdgf5AP+AHkvc698cY56UaTJIkSUqBxRhJkiRtUEIImwJHklxFGUgOEA+PMf6UajBJkiRJWsNCCDlAW5ILAg4EHiRZaumN6MkBSZIkbSAsxkiSJCnjhRCygVYkB4NbAg+THAx+xYPBkiRJkjYEIYQtgD4kFwkUkFwkcE+McXqqwSRJkqS1zGKMJEmSMlYIYTuS0eH9gJ9IDvyOjDHmp5lLkiRJktKydFnZJiQXDnQCxpG8V3omxlicZjZJkiRpbbAYI0mSpIwSQigHdCG5CnJPYAQwKMb4QarBJEmSJGk9E0KoAvQEBgJVgMHAkBjjpBRjSZIkSWuUxRhJkiRlhBDCLiRlmCOAj0iWSno4xrgw1WCSJEmSVAqEEBqQTJE5DHid5D3VYzHGxakGkyRJkv4mizGSJEkqtUIIlUgO2g4AtgWGAINjjN+kGkySJEmSSqkQQgXgYJL3WXWAYSRTOL9INZgkSZL0F1mMkSRJUqkSQgjAPiTTYboDLwB3AU/FGJekmU2SJEmSMkkIoTbQH+gDfE3y3uvBGOP8VINJkiRJq8FijCRJkkqFEMLGJMskDQDKkYz1vjvGODXVYJIkSZKU4UIIZYAOJO/H9gfuJ3lP9k70JIMkSZLWcxZjJEmStN4KIWQBzUkOvrYFHiO5QvFFD75KkiRJ0roXQtgK6EsyxXMOyXu0e2OMs9LMJUmSJP0eizGSJEla74QQtgb6kYzsng3cCYyIMc5OMZYkSZIkaamlFzI0IynItAeeICnJvBBjLE4zmyRJkvRbFmMkSZK0Xlg6mrsTyUHVfUlGc98VY3w31WCSJEmSpD8UQqgO9CKZ9lmBZUvfTkk1mCRJkoTFGEmSJKUshFCHpAxzJPAFyRWGD8UYF6QaTJIkSZK0WkIIAdiLpCBzCPAyyXu8J2OMS9LMJkmSpA2XxRhJkiStcyGEikB3koOlNYG7gcExxi9TDSZJkiRJWiNCCJVIyjFHATuQvO8bFGP8OtVgkiRJ2uBYjJEkSdI6sfTKwT1JDooeBrxKcuXgEzHGxWlmkyRJkiStPSGEnVk2KfQTkveCo2OMC1MNJkmSpA2CxRhJkiStVSGEqixba74yyVrzQ2OMk1MNJkmSJElap0IIZYFOJO8PGwL3AXfFGN9PM5ckSZIym8UYSZIkrXEhhCzgQJKDnR2AJ0kKMc/FGIvTzCZJkiRJSl8IoQbQD+gP/ELynnFEjDE/1WCSJEnKOBZjJEmStMaEELYE+pCMyF5AMh773hjjjFSDSZIkSZLWSyGEbKAFyYUVrYFHSN5Lvhw9gSFJkqQ1wGKMJEmS/pYQQg7QnuQgZmNgFMlBzLc9iClJkiRJWlUhhE2AI0jeX+aQTJG5O8b4U6rBJEmSVKpZjJEkSdJfEkKoSTIZpg/wLckBy1ExxnmpBpMkSZIklWohhADsS1KQOQh4juQ957gY45I0s0mSJKn0sRgjSZKkVRZCyCU5KDkA2AUYBgyKMX6WajBJkiRJUkYKIWwEHEbyPnRrYAgwOMb4XarBJEmSVGpYjJEkSdKfCiHUJzkIeTjwJslSSY/FGAvTzCVJkiRJ2nCEEHYjmVzaC3ifZIrMmBjjojRzSZIkaf1mMUaSJEkrFULIA3qSHHTcBBgMDIkxTkw1mCRJkiRpgxZCKA90IbmAoz5wL8k004/SzCVJkqT1k8UYSZIklVi6jntjkoOLXYDxJNNhnokxFqWZTZIkSZKk/xVC2B7oD/QDJpO8hx0ZY5ybajBJkiStNyzGSJIkiRDCZkAfkukwRSQHEofHGH9JNZgkSZIkSasghJANtCG50KMZMJpkqaXXoidCJEmSNmgWYyRJkjZQv3PQ8C7gdQ8aSpIkSZJKq6UXfxxJ8n7Xiz8kSZI2cBZjJEmSNjD/M2Z6EskVdPfHGOekGkySJEmSpDVoJcsFTyApyTztcsGSJEkbDosxkiRJG4AQQnmgK8lSSfWBe4FBMcaPUowlSZIkSdI6EULIAw4nKclsAgwGhsQYJ6YaTJIkSWudxRhJkqQMFkLYjaQM0wt4n+TKuEdijIvSzCVJkiRJUlpCCPVJ3iv3BN4iea/8aIyxMM1ckiRJWjssxkiSJGWAEMJJwKIY450hhI2AHiRXwW0FDAEGxxi/SzOjJEmSJEnrkxBCLnAQyfvnusA9JNNVPw0hbEyy9PARMca5KcaUJEnS32QxRpIkqZQLIRwJXAKcDHQmOaj3HMkVb+NcN12SJEmSpD8WQqgJ9Af6At+RvKduDGwLdIgxFqSXTpIkSX+HxRhJkqRSLITQA7gT+AkoIjlwNyzG+FOqwSRJkiRJKoVCCDlAe5KllpoAs4GvgLYxxuIUo0mSJOkvyko7gCRJkv6W/wIVgHLAL0BZSzGSJEmSJP01McYlwBQgF5gKbAq0AnqnmUuSJEl/nRNjJEkq5UII9YH6JMUIbZjKAxsBhcDzMcY3U84jSZIkSVKpE0KoAzQENga2A+Ys/W8e4LQYFQPfA8+6bLUkSaVLTtoBJEnSX1emTJn+eZUr/7tVyxbFFStVchLcBqyoqIgPPvig+PsfJnYJIbSKMS5IO5MkSZIkSaVFCKFNhfJlRzfbc+eiKpUqZKedR+ufxUVF8c1Pvo3TZ88dG0I43HKMJEmlhxNjJEkqpUIIdTfaaKO333rtldzatWulHUfrgaKiIg49vNeiCROeHjx33rwT0s4jSZIkSVJpEEKoWq5MzuTHrzs9d59dd0w7jtZjCxYV0uH06xa++/n35xTHeHPaeSRJ0qrxynJJkkqvXRs32n+xpRj9Kjs7m6MHHFW+XLlyDdPOIkmSJElSKVJrm82rF1qK0Z+pUL4svds1yt2oYu6+aWeRJEmrzmKMJEmlV7kKFSqUut/lz7/wIqee8Y9U9l1UVMTAY4/ngKbNGXjs8RQVLT/xdsmSJRzeqzcHNm/Jgc1b8u233wHw2uuv06hJUxo1acprr78OwJw5c2jXsTPNWramTfuOzJo1a51/PStToUIuQLm0c0iSJEmSVIqUyy1bJu0Mf8tL73/B2bfcn8q+v5w4jUYDL2GTNicwe96KKzsvKSqi7yV30vaUa2h7yjV8N+UXAObMX8iAywfR8fTrOeqyQcvd59p7n6TRwEvWSf7VlVuuLNlZWblp55AkSauu1J1MkyRJG44/W/Jx0aJFFBcXr/LjPTn2KSpX3oiXnn+WypU34smxTy33+Vdfe52KlSrxwrNPc85ZZ3LL7bcDcPa55/Pwgw/w8IMPcPa55wMw5pHHaLT//jz39Hi6dunM8HtHrOZXJ0mSJEmStO796fGWwsWrdbxlq02q8uQN/2Dvujus9PNvfPwNlXLL8dRNZ3J6z3b8d8xzAFw+9DGOO6gFj19/OoPOP6pk+9nzFvDZ91NXef+SJEl/xmKMJElaI2KMnHL6GRzQtDktWrdl4sSJTJkyhdbtOtC0RSv6Dzh6hYMqox58iH0bHcB+jZsw+uExAPQ7aiDHnXgybTt0YtKkSSvd11tvv12yTUFBwSpnfPmVV2nfti0AHdu355VXX1vu89ttW4MlixcDMHv2bKpXq87ChQsB2HTTTdl0003Jyspi0aJF1K5dk3nz5i3dNp/q1aqtcg5JkiRJkqRVEWPkrFvup/XJV9Px9Ov58aeZTJ0+my5n3ki7U6/luKuGrnC85eHn36HZ8VfQ/IQrefTFdwE49qqhnHbDvXQ96yYm/7LyqbfvfP49p91wL93OuomCxUtWOWPF3HLkVfr9ASo1Nt+YxUuSqb358xZQrXIlAN794nvuGfsK7U69lvuffqNk+5vvH89xBzVf5f1LkiT9mZy0A0iSpMzw+BNPUli4mJeefxaA4uJiTj3jH5x84gl07NCeM885l0cefYyqVasCybJGl1x2BW+8+hIA+x/QlK5dOgOw2667cPstNy/3+HPnzuWuwUN44smx7LrrLhx9VH/22KM+ADNnzuTgQ3uskOnWm2+ibt2dSz6eNXs2eXmVAaiSl8fM/1n+aPPNN2fOnDnsUm8PFi5ayOsvv8isWbPIy8sr2aZKXhVmzpzJTnXq8Mqr57Jb/T3Jzs7m9Vde/DtPnyRJkiRJ0gqeeu1DFi9ewvibzwKS4y1n3/oAxx7UnHb71eOf/3mQJ175gCobVQCgqKiYq4Y/znO3nQtAyxOvomPj+gDU3WErbjit13KPP3fBIu5+4mXGvf4hdbffir4dD2D3WjUAmDlnPkdc+J8VMl1/yuHstN2Wq/w1bFatMnPnL2LvfhexqKCQZ289B4B3v/iBS44+mN1r16D9adfRcu9diDHy3ZTp7LXz9qv3REmSJP0BizGSJGmN+OzzzznwgMYlH2dlZfH1199w/jlnA7DP3nvz5VdfsU/DhgBMnz6drbfeitzc5Iqirbfeil9+SdaY3nefhis8/pQpUxk85G7atGnFgH792GmnOiWfq1atGs89Pf5PM1atUoX8/DkA5M+ZQ7WlJZ1fDR02nLp16zL6wQd49rnnOfefF3DLTTeQn59fsk3+nHyqVavGxZdeTp8jezOgfz8GD72ba667gX+df+4qPVeSJEmSJEmr4ouJ02i0e+2Sj7Oysvhm8s+c2as9AHvtvD1fT/qppEgyI38eW25SldxyZQHYcpOqTJ+dTLzde+cVlzqaNn02w8e+Qsu9d6FPh8bUrrF5yeeqVa7Ikzec8be/hnvHvcpO223BiEuO44V3P+eiu8Zw65lHsnm1PPbZdUcA9qi9Ld9N+YXRz7/NyYe1+tv7lCRJ+i2LMZIkaY3YqU4dnho/gR6HHQokVzDtuOMOvPnW23Tq2IE33nqL/ffdt2T7jTfemB9/nFSyVNGPP05ik002ASArrLjaY506tfno/Xd4+ZVXuOb6G5g4cSIHdevK0QOOIj8/f5UmxjTafz/GT3iaFs2bMfapcTRutP9y2xcVFbHxxtWTfNWrMyc/v6S4M3369JJtypcvn2xbfdm2n3722V974iRJkiRJkn5H7W02Z8Jbn9C9+d5Acrxlhy034Z3Pv6Pd/rvz9mffsc8uO5ZsXz2vEpN/nsXCgkIAJv88i42rJEsXZWWFFR6/Vo3NeWPwhbz20dfcdP94fvxpBp0PaEC/jgeQP3/hGpkYU1QUqZ5XqSTfnPnJsaAGdbblq4nTqLnNZnz2/RS22awa30+ZzsWDxgDw/dTpXDnscc45suMq70uSJGllLMZIkqQ1olPHDoyb8DSND2xGuXLlGHLXfznnzH/Qp/8Arr3+Brbfbju6dO7Eiy+9DEB2djb/PO8cmrZoRQiBf553DllZKxZi/lfjRo1o3KgR8+bNY9RDoyksLFzliTEd2rfjkccep0mzFtSqVYv27doCMOCY47jrjts5oufh9OjVm0cefYzCwkL+fdMNAFxx2SV0Oag7AFdfeTkAJx5/LH36D+Cmf99CjJG7B9/1l543SZIkSZKk39Nu/3o8/fYntDrpasqVyeH2s/ty+uFtOebKIdx0/3i23WJjOjTanVc+/AqA7OwszurdnnanXkcIcFbv9qt0vGW/3Wqy3241mbdwEWOef4fCJUtWeWLMzzPnMODyQXz8zSR6/ut2Tujegg6N6nPitcO45R9Hclirfeh78Z088coHFC5ewrUnHw7AhQO7ccp197CwsJBuB+7JZtXyGHHJcSWP22jgJZZiJEnSGhFijGlnkCRJf0EIoffBB3W7bdTIEZXSzqL1x0svv8xB3Q/7aPqMGfXSziJJkiRJUmkQQjhgtx23fuyVO/+Vl3YWrf/uG/8659z6wJiZc+Z1SzuLJElaNX9eE5YkSZIkSZIkSZIkSZJKIYsxkiRJkiRJkiRJkiRJykgWYyRJkiRJkiRJkiRJkpSRctIOIEmSMkezlq15+MEHqFKlStpRVuqCiy7mxZdeYsGCBfQ+ohcnnXA8z7/wIr379qPmjjsC8NiY0SxcuJBDD+8FwIIFC1iypIh33nyNkfc/wEUXX0pubi7vvf1GyeOecvoZvP32O8QYuemG69h7r7044si+TJ4yBYA33nyLyT98S9WqVXlo9MPc9p87iDFy7tln0apli5LHWVmWSpUq0bnrwcyZO4dFixZx1RWXc2CTA/jkk085/qSTATiiV08GHtV/nTyHkiRJkiRp7Wt/2nWMuOQ4qlSqkHaUlbp0yKO88sGXLCgo5PBW+3LsQc0BeOTFd7lzzPNEImf0bEe9mtvQ5+L/sqSomDLZ2dx2Vh9qbF6d824fxftfTgTgg68mMu6mM9l1x60BeOPjb2h18tVMfPQGqlSqQKczrqeoOFJcXMyn309h4iM3MGf+Qvpc/F8KCpdQJieboRcMpOpGFXnspfe48f5xlMnO5t//OJJa22y2XO6RE17n9tHPEggc1bkJvds1+t3HWtm2kiSpdLIYI0mSVklxcTFZWWtn2Nz/Pvaf7euvZvnneedQtuwFLFmyhHp77MWxRw8E4OCDunHjddeWbFepUiWee3o8AEPuHsakSZMBaNmiOQd168o++x9Qsu3EiRP59NPPeOXF5/nss8/55wUX8tCo+7ln2FAAvvvue44+7niqVq3KtGnTGPXgQ0x46snfzf+/WQAefOA+ypYty/ff/0C/AQN57unxnHv+v/jv7bdRu3YtWrfrwMHdulKtWrXVfk4kSZIkSdK6lQnHWM46oj1l+3VmSVER+x51MUd1PpCZc+bx8PNv8+i1p5Y85ryFixjyz4FsWq0yT7/1Cdff9xQ3ntaLy487BID5CwtoedJVJaUYgNseeoY96mxb8vFj150OwIvvfcH9TycXKj3+yvvst2tNzurdgbseeYGRE95gYJcDufbeJ3nqpjP5dvIvXDxoDMMvOma53P9+YAJP33I2OdnZHHDMpfRu12ilj3XcQc1Xuq0kSSqdLMZIkpQhPv74EwYeexy5ubnUqlWLO267heeef4Ezzjyb7batwcxZs7jxumuZnZ/PmEcf5cbrruX773/gtDP+wcMPjeKa667nqXHjmT07nwv/dT6dO3Xkoosv5fvvv2fGzJmcf+7ZPPf8i4wbP54lS5Zw3TVXsU/Dhoy4byTX33gzNXfcgVmzZv9uviuuumaF++7eYG+aNTuQyZMms8suuyy3r4fHPMqrr71GdnY2/7n1Fnbaqc5y24+6/77Vfo7Kli0LQEFBAdtvvx1lypQB4JFHH+Pdd9+jbZs2nHfOWcvd54FRD3LT9dcBsPHGG6/wmNWrV6dihYoUFRUxO3821apXX+7z948axSHdDwZg7Ljx5Obm0rZDJ6pVrcptt9y8QpllZVl+zT1nzhx22aUuAJOnTKFOndoA1KlTmzffepu2bVqv9nMiSZIkSZKW9+l3kznx2uHklitDza0346bTj+DF977gvNtHUWOz6syaO5+rTjyM/HkLePzl97nqxMP4Ydp0zrn1Ae675HhuGjmOCW9+Qv68BZzbpxPtG+3O5UMf44dp05k5Zz5nHtGel97/gqff/IQlRcVcfvwh7L3z9jzwzJvc8sAEdthqE2bPXfC7+a4bMXaF++434GKa1K/DlOmz2Xm7LZfb1+Mvv8frH39DdlYWN51+BLVrbL7c9v9bHlkVZcskp5cKCpew7eYbUyYnmwlvfEz5cmXpdvbNVN2oAtef2otqlStSKbc8AOXK5BBCWO5xxr72IW333a3k4+fe+YwGdbbll9lzV9jn6Off5qCmewFQc+vN+OL7qQDkz1/A1ptW45tJP1O7xhbklivLLjtsxY8/zVzhMWpuvRnzFxZQtkxOSa6VPdbvbStJkkonizGSJGWIcRMmMHDAUfTv24fi4mIAzvvnvxg/9nHy8vLYvcHef3j/E447ljPPOJ3Zs2fTpn1HOnfqCMCmm27K0MF38fHHn/DJJ5/w/DMTmD59Oj1792Hs449y9bXX8/orL1JYWMj2tXZa6WOv7L7jxz7B3HlzOfqoo6hbd2cuuvjSkn29+957fPvtt7z0/LN8/PEnnHPePxkzetRy2//WiPtGcuegwcvdVmObbbh7yKAVshx/0imMeeRRjjvmaAD22rMBX3zyEVlZWfTq3Yenn3mWli2S8b8zZsxg5syZ1K5d63eftwoVKrD1Nlux8267M3/+fCaMfXK5z49+eAxPPvYIANOm/cRPP//MU088xv0PjOKKq6/hmiuvKNn297IUFhbSqm17vvjyK4YOuhOAHXfYnldfe40Ge+zBK6+8RqP99vvdjJIkSZIkadU989an9Ot4AL3bNSo5xnLRXQ/zyDWnUrliLvsNuPgP7z+wazNO6dGG2fMW0PXMm2jfaHcANq1amTvO6cen303m0++mMPbGfzAjfx79L72L0VeezI33jePZ286hcPESdu153kofe2X3feSaU5m3YBH9Oh7ATtttyeVDHyvZ1/tfTuS7KdMZf/NZfPrdZC7472hGXnr8ctv/1gPPvMnQx19a7ratN63Gf8/tt0KW024cweMvv8eALk0B+GnWHH6eNYeHrzqZh557m+tHjOXSY7sDUFC4mCvufpwbT+u13GOMfu5tzu3bseTj/4x+liH/Gsi4Nz5ebrslRUW88uFXXHtyDwBq19icf378Nfv0/z+ys7J49rZz+ODLiVSumFtyn0hcIXP7RrvT+OhLKY6R/xt40O8+1u9tK0mSSieLMZIkZYh+fY7kksuvoFfvPrRp3Zoje/eioKCwZMpJ/d3rASx3ZU6Myw4Q3HvfSIYNv4fs7Gx+XLp0EMC++zQE4NPPPuONt96iWctkKsmCBQv45Zdf2HLLLShfvjzly5enzu8USFZ2X4CNKm20XMnl13199dXX7LXXngDsuusuTJk6ZaXb/6rn4T3oeXiPVXqebvv3TVx39ZUc0LQFfY88gm222abkcwcf1I333n+/pBjz0MNj6Na1yx8+3oSnn2FO/hy++OQjvv76G0485VTGPfk4AF9++RXVq1cv+TuoUiWPA5scQFZWFq1atuCeEctPvalUqdJKs5QtW5YXnn2a77//gc7dDqZtm9ZcfeUVnHTqaRQVFVGndi222GKLVfr6JUmSJEnSH+vVdn+uHv4E/S+9i5YNd6Fn6/0oXLyE6nnJ+/bddkyOJSx/jGXZ/R94+g1GjH+N7KwsJv+ybGrJ3jtvD8DnP0zl7c++o/1pyYTaBYsKmZ4/l803zqN82TKUL1uGWttsttJsK7svQKUK5Zcrufy6r28m/0SDpcsS1d1+K6bOmL3S7X91aIuGHNqi4So9Tzec2pPLj+tOm5OvoVeb/cirWIEDdq9NVlYWzfeqy8gJbyx9biLHXzOMAV0OpHaNzUvuP2f+Qn6YNr3k+XzylQ84oH5tKpQvu8K+Xnj3CxrVq0VOdjYAN40cR682+9OnQ2OGj32Fm+4fT9cmDZgzf2HJfbL+ZzrN3AWLuHHkON4ddgkA7U+7ji5NGqz0sY4/uMVKt11ZNkmStP6zGCNJUobIzc3lhmuvIcZI3d3q0/PwwyhbtgwzZswgLy+PDz78CICqVaoweWnx5b333y+5//U33MSH773NvHnz2G2PPUtu/3VN6J3q1KHx/vszZOnEksLCQrKzs5kyZSoFBQUUFhby5VdfrzTbyu7728f+333VrLkjox58CEimzWy5xZYr3f5XqzoxpqCggHLlylG+fHkqVMglNzeX/Px88vLyAHjhpZdp2bxZyfajHnyIO267daX7/FVRURHVqlcjhEC1alWZO3fZqN/7Rz3IoYd0L/m4SePGXHbFlQC8+977bL/9dss91sqyFBUVEWMkJyeHypU3olKligBst922PDZmNAUFBfToeURJqUiSJEmSJP09ueXKcOUJhxJjZK++F3Joi4aUyclmRv488irl8vG3kwCoUqkCU6bPBuDDryaW3P/foybw+qALmbdwEfv2XzZd5tfjGrW32Zz9dqvJf87uC0Dh4iVkZ2UxbXo+BYWLKVxSxNeTfl5ptpXdF1Ysgfy6rx222pSHn38HSKbNbFG9ykq3/9WqTowpKFxMuaUlntzyZcktV5ZG9Wpx9T3JJN33v5zIdlskFwpdeOdo6m6/ZckySL964pUPSqbpAHzy3WRefO9znnn7Uz7+dhLHXjmUkZceDyTLKB3Wcp+SbYuKi0uKStUrV+Lz76ey49ab8uWP01hUuJjvp/zCVptUXf45CYGyOdnklkuW1o5ElhQVrfSxfm9bSZJUOlmMkSQpQ4wYeT/Dht9DjJG2bVuTk5PDZZdcTOt2Hdm2xjZsuWUyUWS33XZl8eIltGrbnvr1lx18OPDAJjRp1oIGDRpQJa/KCo9fr95u7LzzTjRt0YqsrCz23WcfLr/0Yv5x+mk0atKMOrVrsW2NGivN9nv3/T17NmjAdttvR+MDm5GVlcV/br3lD7/2VZ0Yc8xxJ/DDxIkUFhZyeI/D2HjjjbnjzrsYNHgIZcuWpV69enTt0hmAn376ifnz57PDDtuX3H/8hKe55rrr+ebbb2nVtj13/ud2WrdqyT33juDA5i1ZtGgRF190Ycn2Yx55lGfGjy35eJdd6lKrVi2atmhFTk5OybJIA445jrvuuJ2RD4xaIUt+fj5dDz6ErKwslixZwhWXXQrA0GHDGTb8HrKysrjwX+dTvrxrXUuSJEmStCaMeuZNRox7jQi0argrOdnZXDigK13PvJFtNqvOFtWTi1p22WErFi8povM/bqBezWUTaQ+oX4c2p1xD/do1yKuUu8Lj77rj1uy07Ra0O/VasrICDevuwIUDunHyYa1oddLV1NxmM2psWm2l2X7vvr9nj9rbsu3mG9PqpKvJygrc9D9LGf2vVZ0Yc/L19/DjTzMpXLyEQ1o0pHpeJarnVaLmNpvS7tRrycnO4j/n9OOLH6Zyy6in2XfXmjzz1qfsudN2XHLMwUBSdrn4N0sUnXlEe848oj2QTGj5zzl9AVi8pIg3P/2Wf59xRMm2R3dtxjFXDuG2h54hxsgd5/QjJzub0w9vS4fTr6NMdjb/PqM3APc+9So7bLUp++1Wk+7NG9LixKuIMdK1SQMqV8xd6WNVzC230m0lSVLpFH67hIIkSSo9Qgi9Dz6o222jRo6o9OdbQ7+jBnLKSScuV4ZR5nnp5Zc5qPthH02fMaNe2lkkSZIkSSoNQggH7Lbj1o+9cue/8lZl+2OvGsrxB7dYrgyjDcd941/nnFsfGDNzzrzfbyRJkqT1ihNjJEnSGvXFF19y7AknLnfbf269hTp1aqeUSJIkSZIkqfT5auI0Trnh3uVuu+m0XtSqsXlKiSRJkkonizGSJG0ghixdtmdtq1OnNs89PX6d7EuSJEmSJGld+8/ZfdfJfmrV2JwnbzhjnexLkiQpk1mMkSRJ65099tqH995+Y63u49NPP+MfZ5/DokWLaNe2DWeecTrvv/8Bx590Mjk5OdStW5f/3PpvioqK6D/gaCb++CNbbL45g+68g9zcXJq1bM2SJUvIycnh4IO6ceLxxzF02HAuu+JKtt5qKypVqsRjY0av1a9BkiRJkiRpdTUaeAmv3PmvtbqPz7+fwnn/eZCCwsW0brgrp/Row1GXDWLq9NkAvP3Zd3wx6io2qlCeAZcPZtrS228/uy/bb7kJ7U+7jiVFReRkZ9OlSQOO6dZsreaVJEmZzWKMJEnaIJ1z3j8ZMfxuqlSpUnLbzbfextVXXk7jRo3o0fMIPvzwI776+mu23HJL7h4yiP/eNYghdw/j+GOPAeCxMaOXuz/ACccdy6knn7QOvxJJkiRJkqT1ywX/Hc3gfw6gSqUKJbcNOv8oAL6fOp2TrxtO1Y0q8soHX1IptxxP3XQm49/4mP+OeY4rjj8UgAcuP3G5+0uSJP1VFmMkSdJq+/jjTxh47HHk5uZSq1Yt7rjtFq657nqeGjee2bPzufBf59O5U0cuuvhSvvrqK2bn51NQUMDhPQ7jvpH3k52dzZOPPcJLL7/C5VdeRW75XCZPmcJtt9xEw733LtnP9OnTGXjMccyZO5fq1aoxbOhgvv76mxX2vbq+++57CgoL6HfUQObNn881V15B/fq7s/NOdcjPn0OMkfkLFlClSh5ff/MN9XevB0CDPepz3fU3cvyxxxBCoMtB3dloo4247uqrqFOnNgD/vXMQox8eQ98+R9K/b58184RLkiRJkqQNxqffTebEa4eTW64MNbfejJtOP4KbRo5jwpufkD9vAef26UT7Rrtz+dDH+HrST+TPW0jh4sUc0qIho555k6ysLEZfeTKvfvQV1947lvJlyzB1+myuP7Une+28fcl+ZuTP48RrhzF3/iKqVa7If8/rz7eTf15h36vr+6nTKVi8hOOuGsr8hQVcemx36tXcpuTzo597m25N9wSgxuYbs3hJEQD58xZQrXIlAEKAHuffSqUK5bniuEOoVWPzv/OUSpKkDZzFGEmStNrGTZjAwAFH0b9vH4qLi4FkUsqZZ5zO7NmzadO+I507dQSgVq1aXHTBPxl47PFMmjSZp8eNZeCxx/Pqa68BMHfuXJ564jEmTvyR/gOP5tkJ40r2c+U113LcscfQulVLbr39P9wz4j7y8/NX2Pdv9el3FBN//HG52wYe1Z+eh/co+XjaT9P48KOP+fTD95g9O58+/Y/ixeeeoW3r1nQ5uDun/+MsDjigMTVq1GDXXXbhkcce57BDD2HC088ya/ZsAEaNHEH16tV55913Oe7Ek3h2wji6du7EkUf0YtGiRbTv1IVG++1XUpiRJEmSJElaFc+89Sn9Oh5A73aNSo59DOzajFN6tGH2vAV0PfMm2jfaHYCaW2/GeX07cdK1w5n8yyweu+50Trp2OG988g0Acxcs4uGrTubHn2dy/NV388T1Z5Ts5/oRTzGgc1Na7F2X/455jvsnvMGc+QtX2PdvHX3FECb9PHO52/p2PIBDWzQs+finmfl88u1k3hp6EfnzFnLMlUMYd9OZJZ9/5KV3GX3lyQBsVq0yc+cvYu9+F7GooJBnbz0HgGEXHkP1vEq89+UPnHrjvcvlliRJWl0WYyRJ0mrr1+dILrn8Cnr17kOb1q05sncv7r1vJMOG30N2djY/Tppcsu3u9XYDYKstt6TebruW/HnmzFnk5eVRv359srKy2G67bZk9O3+5/Xz22ee88cabXHHV1SxatIhOHTty7NEDVtj3b909ZNCf5q+SV4U96u9O1apVqVq1KosWLQLg+JNO5qnHH6NWrZr0O2ogL738Mu3bteXFl16meas27LlnA7bYPLlCqXr16gDs2aABc+fOSx536bJKFSpUoH27tnz40UcWYyRJkiRJ0mrp1XZ/rh7+BP0vvYuWDXehZ+v9eODpNxgx/jWys7KY/MuyYspuO24NwBYbV2HXHZb9edbc+VSumMvuNbchKyuLbTffmPx5C5fbz+c/TOWtz77luhFjWVS4mPb716N/pwNX2Pdv/ffcfn+av0qlCtSrtQ1VN6pI1Y0qsqhwccnnvvrxJ6pVrkj1vGQyzL3jXmWn7bZgxCXH8cK7n3PRXWO49cwjSz6/R+1tmbdg0V94FiVJkpaxGCNJklZbbm4uN1x7DTFG6u5Wn56HH8b1N9zEh++9zbx589htjz1Ltg0hrPTPMUYAPvzwQ2KMTJw4kSpV8pbbT506tenUoQPNmh4IQGFhIUVFRSvsOydn2UuaVZkYU6tWTWbPnk1BQQHz588vuX+MkWrVqhJCoFr1auTnzyGEwFVXXAbAjTf/m8b77w/AnDlzqFy5Mj/88AM5OdkA5Ofnk5eXR3FxMS+//CotWzT/i8+wJEmSJEnaUOWWK8OVJxxKjJG9+l7IoS0a8u9RE3h90IXMW7iIfftfXLLt7x93Sf7/0TeTiDHy408zyauUu9x+atfYjHb77U6TPeoAULh4CUXFxSvsOyc7u+Q+qzIxZsetNyV/3gIKChczf1EhOdlZJZ8b/fzbHNx0r5KPi4piSQmmel4l5sxPyjtz5i+kcsVcJk6bQfZv9i9JkvRXWIyRJEmrbcTI+xk2/B5ijLRt25qcnBwOPLAJTZq1oEGDBlTJq7LKj1W1alW6dOvOlKlTueXmG5b73PnnnM0xx53ApZdfAcAF/zyfr7/5ZoV9/9aqTIzJycnhnLPOpGWbdixZsoTLL70EgP+78AI6dT2IsmXLssXmm9OmdSumTZvG4UccSU5ODvs0bMgpJ51IcXExzVu1pUKFXIqLi7nhumsAuO6Gm5jw9NMAtG/XjgZ77LHKz4MkSZIkSRLAqGfeZMS414hAq4a7kpOdzQH169DmlGuoX7vGCgWXP1Jlowocdv6tTJuR///s3Xe81uPjx/HXdc5pnPYwGlQqlRQpKu1dUlaIbC2bsmWEMkryjfjZe5MKqWwKkZ0d7aS9xzmdrt8fh8NRKKr7jNfz8fg+vp3P/Rnv+/76dj7e9/W5Lm45//hsr110QmfOv/Uxhjz6MgCXndKFn+Yt3Ozaf7Q1M8akJCdz4fGH0PWi4WzM2MTAXkdmvfbSu5/y4q39s37u3r4Rp153Ly9P/py09I3cct7xbNq0iS79byW1cEE2bYrcdPaxW/1+JUmStiT89rS2JEnKXUIIJ3U76sg7n33qiWKJzvJvvfX2O4weO5bbht2S6Ch5xruTJnHU0d2/XLxkyX6JziJJkiRJUm4QQmhet9oeL06+96qS/7x37vHuZ9/x0qTPuPmc7omOkqc8OfEDLhv5zOilK1cf+c97S5KknCDpn3eRJEmSJEmSJEmSJEmSch+XUpIkSQnTqmULWrVskegYkiRJkiRJeU7zejVpXq9momNIkiQlnDPGSJKkHeaAAxvt8Gu8/c67HNysBS3btKPHiSeTnp4OwPsffEDTFq1o2qIV73/wAQBDh91K63YdaN2uA7tXrMTYF18C4JLLrqBlm3Z0PeIoFi9evNk1Rt71fzRt0YqOnbuwcOHCbK917NyFCy68CIBHH3si6/yVq+3NiDtG7si3LkmSJEmS8qGmva/f4ddYunINrc68kfKdz+OL6XOytq9cs45eN9xPl/630nPw/UDmkk0NTxtIlSP6Z+331U/z6NxvGJ37DePgXtdxwtV3ATDowbEccsEttDzzBv5v1BubXXdLrz858YOsc9U+7jLu2sJxkiRJf8cZYyRJUq5WvVpV3nxtIoULF+byAVfx/KgXOK77sVx6+QBeeO4ZAI7ufjzvvPk6F1/Yn4svzCxp6tZrQPt2bfn4k0+YO3cub7/xGhNffY0ht9zKkJtuyDr/kiVLeOrpZ3j3rTd4edwr3HzLMIYNuRnIHJSTkvL77dRJJ/bgpBN7ANC6XQeOOKzrzvoYJEmSJEmStpviRQrz/E3nMuD/nsu2/YaHXuTMo9rSoFaVrG11q+/JW3ddQftzb87atm/ViowbfiEAgx8aS9UKuwFwyYmdKXjaYWzMyKBxz+voeVhLCqQkZx23pdeP79CY4zs0BqBzv2F0aVpvB71rSZKUVzljjCRJ2ibnXtCPSZMnAzD144/pfcZZ/PLLL7TreAgt27TjsCO6sWHDhmzHnNazN5999jkAA68bxOgxYwG48eahtGrbnmYtWzPlww//VZ6KFStSuHBhAAoVKkRSUhLr1q0DYLfddmO33XYjKSmJ9evXZx3zwZQp7Fe3DqmpqUyf/iP7778fAPUPqMe7kyZlO/+HH02lVcuWJCUlcUinjkyZ8nvOEbffwVln9N0s0/z589m4cSOVKlX6V+9JkiRJkiTlLxeNeJL3v5wOwCffzeTcWx5l4dKVdL3wVjqdP5Rjr7iDDWnp2Y454+aHsmZzueGhF3lp0mcADHviFQ654BbanzuEj76Z8a/yFEhJpmzJYptt/+S7mTz2ymQOueAWnn5tCgClihWhSOGCf3mucZM/59Cm+wNQsEDmA0Yb0jZSudwu2QbF/NPrPy9ezsaMDPbcvcy/ek+SJCn/cmCMJEnaJsd3P5annnkWgCeffoYex3WndOnSjH/5Rd5+4zXq1NmXF196+R/PM23aV3z11Ve89fqrjH7+Wa665trN9unYuUvW0kS//eeNN9/a4vlmzJjJxFdf5YjDD2PZsmWULFky67VSJUuxdOnSrJ+ffvY5jj3maAD2rV2bt995l02bNvHqa6+zbNnybOfNPFcJAFJSUkhLSwPglfETOPjgxhQtWnSzLM8+P4qjux31j5+BJEmSJEkSwDFtGvLcGx8B8NwbH3FM24aUKl6EF4acz/j/Xcy+VSvyyvtf/ON5vp4xj69nzOeV2y7iqUFnMeiBMZvtc/jFt2UtTfTbf97+5NutyvnJd7M4rn1jXhhyPne/8CZLVqz+2/2//HEOlcvtQomiqVnb+t32BPVOupKG+1bd4jF/9foLb3/MES0bbFVOSZKkP3IpJUmStE2aHHww/S+6hPT0dCZPfo+hN93IwoULOfPsc1m6bBkLFy5i9913y3ZMCCHrzzFGAL7+5humfPQRrdt1AGDt2rWbXWvCuJe2KtOyZcs46dTTePC+eylYsCClS5dmxYoVWa+vWLmCMmXKZF3/1Vdf56bBgwCoU2df2rVtQ9sOnWjUsCGVK2ef5aV06dJ88+13AGRkZFCwYOYTUCPv+j+eefJxPvxo6mZ5nnt+FE8/8dhWZZckSZIkSWpUpxqX3fkM6RszeP/L6Qzq241Fy1dxwfDHWbZyDYuWr2LX0iWyHRP+8OdIZt/y7ayfmfrNDDr3GwbA2vVpm11rzNAL/nXOcmVK0qhONQAOqFGZGfMXbXFmmd+MenMqR7U+MNu24Rf04IYzj6bjeUM5oePB7LFbma16ffTbH/Pw1X3+dXZJkpR/OTBGkiRts9atWnHt9YNp0uRgkpKSePzJp2jfvh1nndGXK668Omvwy29KlS7F3HnzqFdvfz777HMOqLc/tWrWpFmTJjx4/70AWTOx/FHHzl02237VgCto07pV1s8bNmyge48TGXz9ddSsWQOA1NTMp5AWL14MZA5o+W25pUmTJ3Ngg/oUKlQo6xz9Lzif/hecz+gxYylfvly26x10YANuGjKUGCMTX32NRo0asmrVKubP/5luxx7H0qVLWbhoEa1atOCIww9j9uzZpKSkUKFChX/xyUqSJEmSpPyq5QG1uPHhF2lcpxpJSUk889qHtDmwNr0Pb8W1972wed9SvAjzFi1jv+p78sUPc9i/eiVq7FmOg+tW5/8uPRWAtPSNm13n8ItvI31jRrZtl550KC3r1/rHjPVrVuaH2QuovufufDNz/j8uazT+gy+56ITOWT9vSEunUMECFC5YgNTCBUktlH0Jpr96fc4vS0lJTqb8LqX+MaMkSdKfOTBGkiRtsx7Hdad+w8a8P+ltANq2bs3Jp/VkwoRXKV68GLvttmu2/U896SROPq0nDz70MIV+LTT2268u++xTi1Zt25OUlETjRo24YdB12Y7bmhljHnjoYT77/AsGXnc9AL17nk6P44/jxsHXc/hRmcslDbnphqz9n372OY45ulu2c7Ru14Hk5GRq1KjBbcOGAnDTkKEcfdRRVK9ejaO7HUXzVm0oWrQojzx4P8WLF+eTjz4A4K2332H02LEccfhhADzz3PMuoyRJkiRJkrbZMW0b0qzPIF4feSkALevXos+ND/Dah19RrEhhdilVPNv+J3RsQp8bH+SxVyZTqEDm1z11qu1BrcrlOeSCW0hKCjSsXZVreh2Z7bitnTHmsIuG8+2sn/l+9gJOOqQJp3VpwTW9j+T8YY+xLi2NI1s2YPcyJfnyxzkMuOs5ZsxfxGEXDeeqnkdw0D578cl3M9l7j90pmvr7w0nn3foYc35ZSlr6Ro5p25CyJYvxxfQ5vP/ldPoe2XqLrwO88NZUjmhZ/99+tJIkKZ8Lfx5hLEmScocQwkndjjryzmefeuKv56tVvvPupEkcdXT3LxcvWbJforNIkiRJkpQbhBCa1622x4uT772qZKKzKOd7cuIHXDbymdFLV64+8p/3liRJOUFSogNIkqR/zwGu+rMYwX8qJEmSJEnaNlYs2lqRiO2LJEm5iwNjJEnKvRbOmDFjk4Nj9EczZ84CWJDoHJIkSZIk5SILFyxdnpKRsSnROZQLzF6whHUb0mcnOockSdp6LqUkSVIuFUIoXqxYsU969Tyt8vnnnF2gaNGiiY6kBMrIyODzL77kmON6rFu1alW3GOMric4kSZIkSVJuEEJILlak8DvtDqpd/9reRxUuUTQ10ZGUA23MyODdz77n7KGPrFm3Ia1FjPGTRGeSJElbx4ExkiTlYiGEXUqWLPlsenp6vU2bNhVIdB4gAIV+/e/15O15ZQv8+p8NQEaCsxAgFipUaNHyFSsuiDGOTXQeSZIkSZJykxBCasmiqY9t3LSpZUbGpsKJzvMn+apviVAg5JC+5U82FSqQMm/FmnWnxxjfT3QYSZK09RwYI0mStosQwoHAc8AzwBUxxo0JjrTDhRBaAk8CI4EbY4zOuSxJkiRJkrYb+xb7FkmS9N85MEaSJP1nIYRewI3AGTHG5xOdZ2cKIVQks5xaApwcY1ye2ESSJEmSJCkvsG+xb5EkSdtHUqIDSJKk3CuEkBpCuB/oBzTLbyUNQIxxHtAamAFMDSHsn+BIkiRJkiQpF7NvsW+RJEnblwNjJEnSvxJC2AuYDBQFGsUYv0twpISJMabFGM8HrgJeCyGclOhMkiRJkiQp97Fv+Z19iyRJ2l5cSkmSJG2zEMIhwEPADcCI6A1FlhBCHWAU8BrQL8a4IcGRJEmSJElSLmDf8tfsWyRJ0n/hwBhJkrTVQghJZD6l0xs4LsY4KcGRcqQQQkkyi6zywNExxrmJTSRJkiRJknIq+5atY98iSZL+LZdSkiRJWyWEUAZ4CWgLHGRJ89dijCuAo4AXgI9CCG0SHEmSJEmSJOVA9i1bz75FkiT9Ww6MkSRJ/yiEcAAwFfgGaBtj/DnBkXK8mOlm4ATg8RDCpSGEkOhckiRJkiQpZ7Bv2Xb2LZIk6d9wKSVJkvS3QginAUOAs2OMzyQ6T24UQtgDeA74GTj11yecJEmSJElSPmXf8t/Zt0iSpK3ljDGSJGmLQgiFQwj3AJcALSxp/r1f17xuCcwnc6rfOgmOJEmSJEmSEsC+Zfuxb5EkSVvLgTGSJGkzIYTKwLtAaaBhjPGbBEfK9WKMG2KMZwPXA2+GEHokOpMkSZIkSdp57Fu2P/sWSZK0NRwYI0mSsgkhdACmAE8Cx8YYVyU4Up4SY3wUaAtcF0IYEUIomOhMkiRJkiRpx7Jv2bHsWyRJ0t8JMcZEZ5AkSTlACCEJuAI4E+gRY3w7wZHytBBCKeARoCyZhdi8xCaSJEmSJEnbm33LzmXfIkmStsQZYyRJ0m+lwRjgEOAgS5odL8a4HDgCeJnMdbBbJTCOJEmSJEnazuxbdj77FkmStCUOjJEkKZ8LIewPTAV+AlrHGOcnOFK+EWPcFGO8ATgVeCqEcFEIISQ4liRJkiRJ+o/sWxLHvkWSJP2ZSylJkpSPhRBOBoYB58UYn0x0nvwshFAZeA6YBZzmWuOSJEmSJOVO9i05h32LJEkCZ4yRJClfCiEUCiHcCVxJ5lNLljQJFmOcBTQHlpA51W/tBEeSJEmSJEnbwL4l57FvkSRJ4MAYSZLynRDCnsA7QDky17eeluBI+lWMcX2MsS9wM/B2COHYRGeSJEmSJEn/zL4l57JvkSRJDoyRJCkfCSG0BT4Enge6xRhXJDiStiDG+CDQAbgphDA8hFAg0ZkkSZIkSdKW2bfkDvYtkiTlXyHGmOgMkiRpBwshBOBS4HzghBjjGwmOpK0QQigDPAqUAI6NMf6c4EiSJEmSJOlX9i25k32LJEn5jzPGSJKUx4UQSgIvAEeQOZWvJU0uEWNcCnQFXgWmhhCaJziSJEmSJEnCviU3s2+RJCn/cWCMJEl5WAihLvARMA9oGWOcm+BI2kYxxk0xxuuAnsBzIYQLfn0iTZIkSZIkJYB9S+5n3yJJUv7iUkqSJOVRIYQewP+A/jHGRxOdR/9dCGEv4DngB6BXjHF1giNJkiRJkpSv2LfkPfYtkiTlfc4YI0lSHhNCKBhCGAFcB7S1pMk7YowzgKbAamBKCKFWgiNJkiRJkpQv2LfkXfYtkiTlfQ6MkSQpDwkhVATeAqoAB8YYv0hoIG13Mcb1McZewHDg3RBCt0RnkiRJkiQpL7NvyfvsWyRJytscGCNJUh4RQmhF5vrWLwFHxBiXJzKPdqwY433AIcCwEMLQEEJKojNJkiRJkpTX2LfkL/YtkiTlTSHGmOgMkiTpPwghBOBC4CLgpBjjqwmOpJ0ohFAWeBwoBBwXY/wlwZEkSZIkScr17FvyN/sWSZLyFmeMkSQpFwshlACeBY4FGlrS5D8xxiXAocC7wNQQQpMER5IkSZIkKVezb5F9iyRJeYsDYyRJyqVCCLWBD4HFQPMY4+wER1KCxBgzYoxXA2cCo0MI5/z6ZJskSZIkSdoG9i36jX2LJEl5h0spSZKUC4UQugN3ABfHGB9KcBzlICGEqsAo4CugT4xxTYIjSZIkSZKUK9i36K/Yt0iSlLs5Y4wkSblICKFACGE4cAPQ3pJGfxZj/AloAqQDH4QQ9k5wJEmSJEmScjT7Fv0T+xZJknI3B8ZIkpRLhBDKA28ANYADY4yfJTaRcqoY41rgNDKfcpscQjgisYkkSZIkScqZ7Fu0texbJEnKvRwYI0lSLhBCaA5MBSYCXWOMyxIcSTlczHQ30AX4XwjhxhBCSqJzSZIkSZKUU9i3aFvZt0iSlDuFGGOiM0iSpL8QQgjABcClwKkxxvGJTaTcKISwK/AEmYOij48xLkxwJEmSJEmSEsa+RduDfYskSbmHM8ZIkpRDhRCKAU8BJwKNLWn0b8UYFwGdgA+AqSGERgmOJEmSJElSQti3aHuxb5EkKfdwYIwkSTlQCKEW8CGwCmgaY5yZ2ETK7WKMGTHGAcC5wIshhDN/fUJOkiRJkqR8wb5F25t9iyRJuYNLKUmSlMOEELoB/wdcHmO8L9F5lPeEEPYGngc+Bc6MMa5NcCRJkiRJknYo+xbtaPYtkiTlXM4YI0lSDhFCSAkhDAVuATpZ0mhHiTH+ABwMJAPvhxCqJTiSJEmSJEk7hH2Ldhb7FkmSci4HxkiSlAOEEHYHXgPqAgfGGD9OcCTlcTHGNcBJwD1kljVdExxJkiRJkqTtyr5FO5t9iyRJOZMDYyRJSrAQQhNgKvA2cGiMcUmCIymfiJlGAocDd4YQBoUQkhOdS5IkSZKk/8q+RYli3yJJUs4TYoyJziBJUr4UQgjAOcCVwOkxxpcTHEn52K9P0T0FpAM9YoyLExxJkiRJkqRtZt+inMS+RZKknMEZYyRJSoAQQlHgcaAncLAljRItxvgL0B74FJgaQjgowZEkSZIkSdom9i3KaexbJEnKGRwYI0nSThZCqAF8AKSRWdL8lOBIEgAxxo0xxkuB/sDLIYTevz5pJ0mSJElSjmbfopzKvkWSpMRzKSVJknaiEMKRwN3AVcA90V/EyqFCCDWBUcAU4OwY47oER5IkSZIkaYvsW5Rb2LdIkpQYzhgjSdJOEEJICSHcBNwGdIkx3m1Jo5wsxvgd0AhIBSaHEPZKcCRJkiRJkrKxb1FuY98iSVJiODBGkqQdLISwGzABaAA0iDF+mOBI0laJMa4GegAPAR+EEDonNpEkSZIkSZnsW5Rb2bdIkrTzOTBGkqQdKITQGJhK5hrXnWKMixMcSdomMdMIoBtwTwhhYAjBe0hJkiRJUsLYtyi3s2+RJGnnCs4qKEnS9hdCCMAZwLVArxjj2ARHkv6zEEI54GlgDXBijHFpgiNJkiRJkvIR+xblRfYtkiTteI4+lSRpOwshFAEeBs4EmljSKK+IMS4A2gHfAFNDCPUTHEmSJEmSlE/Ytyivsm+RJGnHc2CMJEnbUQihGvA+EIDGMcbpCY4kbVcxxvQY44XApcCEEMJpic4kSZIkScrb7FuU19m3SJK0Y7mUkiRJ20kIoStwP5nT+d4Z/SWrPC6EsA8wCngXOC/GuD7BkSRJkiRJeYx9i/Ib+xZJkrY/B8ZIkvQfhRCSySxnTgGOiTF+kOBI0k4TQigOPADsBXSLMc5KcCRJkiRJUh5g36L8zL5FkqTty6WUJEn6D0IIuwCvAE2ABpY0ym9ijKuAY4EngCkhhA4JjiRJkiRJyuXsW5Tf2bdIkrR9OTBGkqR/KYRwEPAx8AnQIca4MMGRpISImW4ls7B5KIRwZQjB+0xJkiRJ0jazb5Ey2bdIkrT9uJSSJEnbKIQQgN7AIKBvjPGFBEeScowQQgXgGWAZcHKMcVmCI0mSJEmScgH7Fumv2bdIkvTfOLJUkqRtEEJIBe4HzgOaWdJI2cUY5wOtgR+BqSGE/RMcSZIkSZKUw9m3SH/PvkWSpP/GgTGSJG2lEEJVYDJQGGgcY/w+wZGkHCnGmB5jvAC4EngthHBygiNJkiRJknIo+xZp69i3SJL077mUkiRJWyGE0Bl4EBgM3B79BSptlRDCvsAo4HWgX4xxQ4IjSZIkSZJyCPsW6d+xb5Ekads4MEaSpL8RQkgGrgZ6At1jjJMTHEnKdUIIJYCHgIrA0THGOYlNJEmSJElKJPsW6b+zb5Ekaeu5lJIkSX8hhFAGeAloBRxoSSP9OzHGlUA34DngwxBC2wRHkiRJkiQliH2LtH3Yt0iStPUcGCNJ0haEEOoDHwNfAe1ijAsSHEnK1WKmocAJwGMhhMtDCN6LSpIkSVI+Yt8ibV/2LZIkbR2XUpIk6U9CCKcDNwNnxRifTXQeKa8JIewBPAv8ApwSY1yR4EiSJEmSpB3MvkXasexbJEn6a44alSTpVyGEwiGEe4GLgRaWNNKOEWOcC7QE5gJTQwh1ExxJkiRJkrSD2LdIO4d9iyRJf82BMZIkASGEysAkoCTQMMb4TYIjSXlajDEtxngOcC3wRgjhhERnkiRJkiRtX/Yt0s5l3yJJ0pY5MEaSlO+FEDoCU4AngO4xxlUJjiTlGzHGx4C2wLUhhNtDCAUTnUmSJEmS9N/Zt0iJY98iSVJ2IcaY6AySJCVECCEJGACcARwfY3wnwZGkfCuEUAp4GNgVOCbGOC+xiSRJkiRJ/4Z9i5Rz2LdIkpTJGWMkSflSCKE0MBboCBxkSSMlVoxxOXAk8CLwUQihdWITSZIkSZK2lX2LlLPYt0iSlMmBMZKkfCeEUA+YCkwHWscY5yc2kSSAGOOmGOONwMnAkyGEi0MIIdG5JEmSJEn/zL5FypnsWyRJciklSVI+E0I4BbgFODfG+FSi80jashBCJeA5YA5wWoxxZYIjSZIkSZL+gn2LlDvYt0iS8itnjJEk5QshhEIhhLuAK4BWljRSzhZjnA00BxaROdXvvgmOJEmSJEn6E/sWKXexb5Ek5VcOjJEk5XkhhD2Bd4DdyVzf+qsER5K0FWKMG2KMZwA3Am+FELonOpMkSZIkKZN9i5Q72bdIkvIjB8ZIkvK0EEI74EMypwjt5vSgUu4TY3wIaA/cEEIYHkIokOBIkiRJkpSv2bdIuZ99iyQpPwkxxkRnkCRpuwshJAGXAucCJ8QY30xwJEn/UQihNPAoUBI4Nsb4c4IjSZIkSVK+Yt8i5T32LZKk/MAZYyRJeU4IoSQwCjgMaGhJI+UNMcZlZP7/eiIwNYTQIsGRJEmSJCnfsG+R8ib7FklSfuDAGElSnhJCqAtMBeYCLWOMcxMcSdJ2FGPcFGO8HjgdeDaE0C+EEBKdS5IkSZLyMvsWKW+zb5Ek5XUupSRJyjNCCCcAtwEXxBgfT3AcSTtYCKEKmevZ/wj0ijGuSmwiSZIkScp77Fuk/MW+RZKUFzljjCQp1wshFAwh3A4MBNpa0kj5Q4xxJtAMWAlMCSHUSmwiSZIkSco77Fuk/Mm+RZKUFzkwRpKUq4UQ9gDeAvYEDooxfpHYRJJ2phjj+hhjb2AY8G4I4ehEZ5IkSZKk3M6+Rcrf7FskSXmNA2MkSblWCKE18CHwInBUjHF5YhNJSpQY4/1AJ2BoCOGWEEJKojNJkiRJUm5k3yLpN/YtkqS8IsQYE51BkqRtEkIIwMVAP+CkGONrCY4kKYcIIZQFHgNSgeNijAsSHEmSJEmScgX7Fkl/xb5FkpTbOWOMJClXCSGUAJ4DugENLWkk/VGMcQnQhcwpv6eGEJomNpEkSZIk5Xz2LZL+jn2LJCm3c2CMJCnXCCHsC3wELARaxBjnJDiSpBwoxpgRYxwI9AFGhRDO+/XJR0mSJEnSn9i3SNoa9i2SpNzMpZQkSblCCOE44Hbgohjjw4nOIyl3CCFUBZ4HvgF6xxjXJDiSJEmSJOUY9i2S/g37FklSbuOMMZKkHC2EUCCEcBswGGhvSSNpW8QYfwKaABuAKSGEGgmOJEmSJEkJZ98i6b+wb5Ek5TYOjJEk5VghhPLAm0B14MAY42eJTSQpN4oxrgNOB0YAk0IIRyY4kiRJkiQljH2LpO3BvkWSlJs4MEaSlCOFEFoAU4HxwGExxmUJjiQpF4uZ7gEOBW4LIdwUQkhJdC5JkiRJ2pnsWyRtT/YtkqTcIsQYE51BkqQsIYQA9AMuBU6OMU5IcCRJeUwIYRfgSSAZOC7GuDDBkSRJkiRph7JvkbSj2bdIknIyZ4yRJOUYIYTiwNNAD6CRJY2kHSHGuBjoBLwHTA0hNE5wJEmSJEnaYexbJO0M9i2SpJzMgTGSpBwhhLAP8CGwAmgWY5yZ2ESS8rIYY0aM8UrgHGBsCOGsX5+glCRJkqQ8w75F0s5k3yJJyqlcSkmSlHAhhKOBu4DLYoz3JzqPpPwlhFAdGAV8DvSNMa5NcCRJkiRJ+s/sWyQlkn2LJCknccYYSVLChBBSQgi3AEOBTpY0khIhxjgd+G163/d/LW4kSZIkKVeyb5GUE9i3SJJyEgfGSJISIoRQDngd2Bc4MMb4cYIjScrHfn1q6WTgbuC9EMJhCY4kSZIkSdvMvkVSTmLfIknKKRwYI0na6UIITYGpwJtAlxjjkgRHkiRipjuBw4A7QgiDQgjJic4lSZIkSVvDvkVSTmTfIknKCUKMMdEZJEn5RAghAOcCA4DTYozjEhxJkrYohLAb8BSwEegRY1yc4EiSJEmStEX2LZJyC/sWSVKiOGOMJGmnCCEUAx4HTgMOtqSRlJPFGBcCHYBPgKkhhIMSHEmSJEmSNmPfIik3sW+RJCWKA2MkSTtcCKEG8AGwAWgSY/wpwZEk6R/FGDfGGC8D+gEvhxD6/PokpiRJkiQlnH2LpNzIvkWSlAgupSRJ2qFCCEcCdwNXAvdGf/FIyoV+LZxHAR8BZ8UY1yU4kiRJkqR8zL5FUl5g3yJJ2lmcMUaStEOEEFJCCDcBtwGHxhjvsaSRlFvFGL8HGgGFgPdCCFUTHEmSJElSPmTfIikvsW+RJO0sDoyRJG13IYTdgIlAfaBBjPGjBEeSpP8sxrgGOAF4EHg/hNA5wZEkSZIk5SP2LZLyIvsWSdLO4MAYSdJ2FUJoDHwMvAccEmNcnOBIkrTdxEwjgKOAe0II14YQkhOdS5IkSVLeZt8iKS+zb5Ek7WjBWRYlSdtDCCEAZwHXAD1jjC8mOJIk7VAhhHLAU8A64MQY45IER5IkSZKUx9i3SMpv7FskSTuCM8ZIkv6zEEIR4BGgD9DEkkZSfhBjXAC0A6YBU0MIDRIcSZIkSVIeYt8iKT+yb5Ek7QgOjJEk/SchhOrAB0AEDo4xTk9wJEnaaWKMG2OMFwMXA6+EEHomOpMkSZKk3M++RVJ+Zt8iSdreXEpJkvSvhRAOA+4jczrf/4v+UpGUj4UQagGjgMnAuTHG9QmOJEmSJCkXsm+RpN/Zt0iStgdnjJEkbbMQQnIIYTBwB3BYjPEuSxpJ+V2M8VugEVASmBRCqJLYRJIkSZJyE/sWSdqcfYskaXtwYIwkaZuEEHYBxgONgQNjjB8kOJIk5RgxxlVAd+Bx4IMQQscER5IkSZKUC9i3SNJfs2+RJP1XDoyRJG21EEJD4GNgKtAxxrgwwZEkKceJmYYDxwIPhBCuCiF43y1JkiRpi+xbJOmf2bdIkv6L4EyMkqR/EkIIQB/geqBPjHF0YhNJUu4QQqgAPAMsB06KMS5LbCJJkiRJOYV9iyT9O/YtkqRt5UhKSdLfCiGkAg8C5wLNLGkkaevFGOcDrYEfgKkhhHqJTSRJkiQpJ7BvkaR/z75FkrStHBgjSfpLIYSqwHtAQaBRjPH7BEeSpFwnxpgeY+wHDABeDSGckuhMkiRJkhLHvkWS/jv7FknStnApJUnSFoUQDgUeAAYBd0R/YUjSfxZC2BcYBbwJnB9j3JDgSJIkSZJ2IvsWSdr+7FskSf/EgTGSpGxCCMnA1UBPoHuMcXKCI0lSnhJCKEHmlOl7AkfHGGcnOJIkSZKkHcy+RZJ2LPsWSdLfcSklSVKWEEJZ4GWgJXCgJY0kbX8xxpXA0cCzwIchhHYJjiRJkiRpB7JvkaQdz75FkvR3HBgjSQIghNAA+Bj4EmgXY1yQ4EiSlGfFTEOB44FHQghXhBC8N5ckSZLyGPsWSdp57FskSX/FpZQkSYQQegE3AmfGGJ9LdB5Jyk9CCBXJfJppEXBKjHF5YhNJkiRJ2h7sWyQpcexbJEl/5ChJScrHQgiFQwj3Af2B5pY0krTzxRjnAa2A2cBHIYT9EptIkiRJ0n9h3yJJiWffIkn6IwfGSFI+FUKoAkwCigMNY4zfJjaRJOVfMca0GOO5wEDg9RDCiQmOJEmSJOlfsG+RpJzDvkWS9BuXUpKkfCiE0Al4CLgZuC36y0CScowQQl1gFDAB6B9jTEtwJEmSJElbwb5FknIu+xZJyt8cGCNJ+UgIIQkYAJwBHBdjfDfBkSRJWxBCKAk8DOwOHBNjnJvgSJIkSZL+gn2LJOUO9i2SlH+5lJIk5RMhhNLAWKADcKAljSTlXDHGFcBRZP69/WEIoXWCI0mSJEnaAvsWSco97FskKf9yYIwk5QMhhAOAj4HvgTYxxp8THEmS9A9ijJtijDcCJwFPhBAuCSGEROeSJEmSlMm+RZJyH/sWScqfXEpJkvK4EMKpwFDgnBjj0wmOI0n6F0IIewLPAXOB02KMKxMcSZIkScrX7FskKfezb5Gk/MMZYyQpjwohFAoh/B9wGdDSkkaScq8Y4xygBfAL8FEIYd8ER5IkSZLyJfsWSco77FskKf9wYIwk5UEhhErAu8CuQMMY49cJjiRJ+o9ijBtijGcBg4G3QgjHJTqTJEmSlJ/Yt0hS3mPfIkn5gwNjJCmPCSG0Az4EngGOdvpHScpbYoyPAO2BwSGE20IIBRKdSZIkScrr7FskKW+zb5GkvC3EGBOdQZK0HYQQksicxvccoEeM8a3EJpIk7UghhNLAI0Bp4NgY4/wER5IkSZLyHPsWScpf7FskKW9yxhhJygNCCKWA0UAX4CBLGknK+2KMy4DDgfFkroPdIsGRJEmSpDzFvkWS8h/7FknKmxwYI0m5XAhhP+AjYCbQKsY4L7GJJEk7S4xxU4xxEHA68EwI4cIQQkh0LkmSJCm3s2+RpPzLvkWS8h6XUpKkXCyEcCIwHDg/xvhEovNIkhInhFAZeI7M4v70GOOqxCaSJEmScif7FknSb+xbJClvcMYYScqFQggFQwgjgWuANpY0kqQY4yygObAM+DCEsE+CI0mSJEm5in2LJOnP7FskKW9wYIwk5TIhhD2At4GKwIExxi8THEmSlEPEGNfHGPsAQ4F3QgjHJDqTJEmSlBvYt0iS/op9iyTlfg6MkaRcJITQhsz1rccAR8UYVyQ4kiQpB4oxPgB0BIaEEIaFEAokOpMkSZKUU9m3SJK2hn2LJOVeIcaY6AySpH8QQgjAxUA/4MQY4+sJjiRJygVCCGWAx4EiQPcY44IER5IkSZJyDPsWSdK/Yd8iSbmPM8ZIUg4XQigJPA90Axpa0kiStlaMcSlwKPAmMDWE0CzBkSRJkqQcwb5FkvRv2bdIUu7jwBhJysFCCHXInMp3AdAixjgnwZEkSblMjHFTjHEg0Ad4PoRw/q9PxkqSJEn5kn2LJOm/sm+RpNzFpZQkKYcKIRwPjAAujDE+kug8kqTcL4SwF5lPxX4H9I4xrk5wJEmSJGmnsm+RJG1v9i2SlPM5Y4wk5TAhhIIhhP8B1wPtLGkkSdtLjHEG0BRYB0wJIdRMcCRJkiRpp7BvkSTtKPYtkpTzOTBGknKQEEIFMtclrQocFGP8PMGRJEl5TIxxHdATuA14N4RwVGITSZIkSTuWfYskaUezb5GknM2BMZKUQ4QQWgJTgVeAw2OMyxIcSZKUR8VM9wKHAreGEG4OIaQkOpckSZK0vdm3SJJ2FvsWScq5Qowx0RkkKV8LIQSgP3AxcHKMcWKCI0mS8pEQwi7AE0AKcFyMcWGCI0mSJEn/mX2LJCmR7FskKWdxxhhJSqAQQnHgGeA4oJEljSRpZ4sxLgYOASYDH4cQDk5wJEmSJOk/sW+RJCWafYsk5SwOjJGkBAkh7AN8CCwFmscYZyU4kiQpn4oxZsQYrwLOAsaEEM7+9QlbSZIkKVexb5Ek5RT2LZKUc7iUkiQlQAjhGOBO4JIY44OJziNJ0m9CCNWB54EvgDNijGsSHEmSJEnaKvYtkqScyr5FkhLLGWMkaScKIRQIIQwDbgY6WtJIknKaGON04GAgAu//WtxIkiRJOZZ9iyQpp7NvkaTEcmCMJO0kIYRywOvAPsCBMcZPEhxJkqQtijGuBU4B7gLeCyEcluBIkiRJ0hbZt0iScgv7FklKHAfGSNJOEEJoBkwls6jpEmNcmuBIkiT9rZjpLqArcEcIYXAIITnRuSRJkqTf2LdIknIb+xZJSowQY0x0BknKs0IIATgPuAI4Ncb4SoIjSZK0zUIIuwJPAZuAHjHGRQmOJEmSpHzMvkWSlBfYt0jSzuOMMZK0g4QQigFPkjk1YmNLGklSbvVrMdORzKdxp4YQGiY4kiRJkvIp+xZJUl5h3yJJO48DYyRpBwgh1ASmAGuApjHGGQmOJEnSfxJj3BhjvBw4H3gphHDGr0/qSpIkSTuFfYskKa+xb5GkncOllCRpOwshHAXcDVweY7wv0XkkSdreQgh7A6OAj4EzY4zrEhxJkiRJeZx9iyQpr7NvkaQdxxljJGk7CSGkhBCGALcCh1jSSJLyqhjjD0BjoADwXgihaoIjSZIkKY+yb5Ek5Rf2LZK04zgwRpK2gxDC7sCrwP7AgTHGqQmOJEnSDhVjXAOcCNwPvB9CODTBkSRJkpTH2LdIkvIb+xZJ2jEcGCNJ/1EI4WBgKjAJ6BxjXJzgSJIk7RQx0x3AkcDdIYTrQgjJic4lSZKk3M++RZKUX9m3SNL2F2KMic4gSblSCCEAZwNXAz1jjC8mOJIkSQnz69O8TwPrgRNijEsSHEmSJEm5kH2LJEm/s2+RpO3DGWMk6V8IIRQFHgV6AQdb0kiS8rsY4y9AO+BL4OMQwoEJjiRJkqRcxr5FkqTs7FskaftwYIwkbaMQwt7AB0AG0CTG+GOCI0mSlCPEGDfGGC8GLgJeCSH0SnQmSZIk5Q72LZIkbZl9iyT9dy6lJEnbIIRwOHAvmdP53h39S1SSpC0KIdQCRgHvA+fEGNclOJIkSZJyKPsWSZK2jn2LJP07zhgjSVshhJAcQrgBuB3oGmP8P0saSZL+WozxW6AhUAyYFEKokthEkiRJymnsWyRJ2jb2LZL07zgwRpL+QQhhV2AC0AhoEGOckuBIkiTlCjHG1cBxwKPAlBBCpwRHkiRJUg5h3yJJ0r9j3yJJ286BMZL0N0IIDYGpwEdAxxjjogRHkiQpV4mZbgOOBu4PIVwdQvDfQyRJkvIx+xZJkv4b+xZJ2jbBmSklaXMhhAD0Ba4DescYxyQ4kiRJuV4IoTzwDLASODHGuCzBkSRJkrQT2bdIkrT92bdI0j9z5KAk/UkIoQjwIHA20NSSRpKk7SPG+DPQBvgOmBpCOCDBkSRJkrST2LdIkrRj2LdI0j9zYIwk/UEIoRrwHlAAaBxj/CHBkSRJylNijOkxxv7A5cDEEMKpCY4kSZKkHcy+RZKkHcu+RZL+nkspSdKvQghdgPuB64GR0b8gJUnaoUIItYFRwNvAeTHGDQmOJEmSpO3MvkWSpJ3LvkWSNufAGEn5XgghGbgGOA3oHmN8L8GRJEnKN0IIJYAHgErA0THG2QmOJEmSpO3AvkWSpMSxb5Gk7FxKSVK+FEI4OYTQLYRQFhgHNAcOtKSRJGnnijGuBI4BngE+DCG0DyGkhhCeCCH47yuSJEm5iH2LJEk5g32LJGXnX3yS8p0QQmHgJqAg8DHwOdA+xvhLQoNJkpRPxUy3AMcBDwP9gGrAkQkNJkmSpK1m3yJJUs5i3yJJv3MpJUn5TgjhDOBMoDxwPjDKNTYlScoZQgi1gPuBAmR+qXJA9F9aJEmScjz7FkmSci77Fkn5nQNjJOUrIYQUYCmQAswB9gQujTHentBgkiSJEEI54AtgI7ABqAL0jDE+kMhckiRJ+nv2LZIk5Vz2LZKU+S8qkpSfFCJzKt/ngMnAlz69JElSzhBjXBBC2B2oDDQATiDzSSZJkiTlbPYtkiTlUPYtkuSMMZIkSZIkSZIkSZIkScqjnDFGSoAQQrMSJUo8um7dugoxxpDoPNo5ChUqtDopKemRVatW9XPtTklSThZCKFOyRPEXNmxIa7AxI6NgovMooWJq4cKLVq1e3TfG+HKiw0iS9GchhColihUZvX5DWo1Nm6JdZz5XuFDBZRvS0q9MS0+/N9FZJEkCCCEUKJFa4IH0jE2HpW/clJroPMp5QgibChdInrlqffrRMcZpic4j5VXOGCPtZCGE+kWKFHnnsUceKdqmTWsKFHC2uvwgxsgvv/zCkd2OXjNjxowHVq5ceV6iM0mStCUhhMLFihb99NQex1S9vN85BYsVLZroSEqgjE0ZfPjxZxxzat+1q1av6RpjfCPRmSRJ+k0IYbcihQt9OaDvcWVP6tomObVwoURHUgJt2rSJ72fO44jzrl+7as3aszakpT+c6EySJJVILTiqXpVdOt5+WvMipYp6r6LNpWdk8NIns+IVT36wYl1aRoMY40+JziTlRQ6MkXaywoUL33LZpZdcOPCaaxIdRQkwf/58qlbfe+369ev9llGSlCOFEBpX26vyxG+mvFU8BCe2U6a7HniUqwYPfXr5ihXHJTqLJEm/CSEc17ZxvXvH3nFNsURnUc4xftLH9L7mf58sWb6yQaKzSJLytxBCkZSksOKnO05MKVzAie3098578N0NT703/ZIY44hEZ5HyoqREB5Dym9TU1Ip7VNwj0TGUIOXLlyctLa1ICCE50VkkSfoLu+5RofwmB8Xoj/aoUI6UlOQKic4hSdKf7Fq5wm5+y6RsKu5eloxNm3ZJdA5JkoCyxQoXSHNQjLZGpV2KFwqBXROdQ8qrHBgj7WQBQm7+oumtt97ign79E3LtjIwMevfpS7MWLejdpy8ZGRnZXn/mmWdpdPDBNGvRgvMv6JeQjP/k1//tnapLkpSj5cZ7lbcnv0//Adcm5Nrf/jCdBq0OodgeNVi+YsVmrz87+iWadDycloceTb8rBmZ7bdXq1ZSreQBjxk3Itv2M/pfT7eTeOzL2NsmN/0xIkvKH3Pw76p2p07h42P0JufZ3M+fSuEc/yjQ5luWr1mz2+hMvv0WnPlfSqc+V1Dy0N3c+9RIAR/cbTMc+A2h5yiW8+/G0nR17q+TmfyYkSXlPCCFPfB8w+bufufKpKQm59g8/L6f1tWPY88xHWLF2w2avr16fzskjX+fIW17h4sfeY9OmzI/8xNtf4/Ch4+h0w4u8992CnR17m4UAAW9kpB3FgTGSdph/Wqpt/fr1bNq0aavPN27cOEqUKM6kd96hRInijBs3LtvrDRsexHuTJjHpnXdYuHAhH3zwwb/KLUmS8rbtfY+yZ4UKvDH2aRo1OGCLrx9Uf3/eHTeKt19+jkWLl/DB1E+yXrvtrvs4sN5+2fb/ccYsFi5atNXXlyRJed8/3r9sSNum+5c9dt+FCfcMomGdGlt8vcehrRh/zyDG3zOIvSruTtdWjQB4YsglTLhnMI/ceBGD735q69+AJEnKN/7xviV9Y9bgla1RoUxRxlx8CA2qbnkylUfe+Y62dSrywkWHUKpIId74ai4AD5zZmjEXd+aePq0YMvbTrX8DkvIk5+6SBGTeqFzQrz8ff/IxBQsW5KEHHiAlJYVTTj2NtPQ0qu5VlfvvuzfbMc8++xy33DqMEAKXXHQxRx11JKeedjqpqan89NNP3HfvPey5556bXeujjz7igQcf4utvvmb8uHGkpqZuVcZJkyfT+ZBDAOhy6KFMmDiRrl27Zr1epUqVrD8XKlSIpCTH/kmSlNvFGOk/4Fo++XwaBQsW4P7bbyElJYXTz7mQtLQ09qpciXv/NyTbMc+NeZlb77yHEAIXnXMGR3bpxOnnXEhqamFmzJzN3bfdzJ4VN18V6KNPP+ehJ57hm+9+4OWnHyE1tfBWZSxatMjfvl6l0u/3QwULFsy6R1m6bDnfT/+Jhg3qZdv/pttG0v/svgy/856tur4kScpZYoxcPOx+PvvmRwoUSOGegeeRkpxM72tGkL4xnSoVy3HXVWdnO2bUa5P536NjCCHQ7+QjOLzNwfQZOILUQgWZMe8X7rzybPYot/nqQB9/9QOPjH2db2fMYfSIq0ktXGirMhbdyvucnxctZWNGBnuWy/wiqmCBAgCsXLOW2tUqbdU5JElSzhVj5Mqnp/D5rCUUTE5ixGnNSUlO4pwH3iU9I4PKuxTntlOaZTtm7NQZ3DlxGoHA2Z3q0KV+Fc594F0KF0xm1qJVDD+lKRXLFNvsWp/OWMQTk3/g+5+X89T5HUgtuHVfUxctVOBvX5+xcCXHNdkbgP0ql+X973+hXd09KZiSDMCq9enUqlhqq64lKe9yYIwkAF566SXS0tKY9M47AGzatIkL+vXn/PPOpUuXLlx8ySWMGTOW0qVLAZnLGl03aBAffvA+AAc3bcYRRxwOQN26dbjrzpHZzr9q1Sruu/9+Xnr5ZerWqUuf3r044IDMp6qXLl3KUUcfvVmmO++4g9q1a2f9vGzZckqWLAlAqVKlWLp02Rbfy0cffcTPP/9Mw4YN/8MnIkmScoKXJ75OWno6b7/8HJB5j9J/wHWc2+c0Du3QlksH3sDYVyZSulTmPUJGRgaDho3g/QljAGh2yJEc3rkDAHX2qcXIoYOznX/V6tXc/9hTjJv4BnX2qUmvk47ngP3qAJkDV445te9mmW4fMojaNffe5vfy0aefs+CXhTSsXw+AW27/P84/sxfjJr6etc9X335PsaJF2KNCuW0+vyRJyhleeXcq6ekbee3+G4HM+5dLhj3A2ccfyiHND+KK/z3ES29/SKnimV8YZWRkcOO9z/DOw5mDfVufflnWDC37Vq/M/y4/I9v5V61Zx0OjX+WVSVPZt3plTjuyA/VqVQVg6YpV9Lj45s0yDb+sL/tU3fzhpX8y6rXJHNmuSdbPaenpdDlrIN/Pmsc9A8/b5vNJkqScZeIXc0jbuImXLj0UgE2bMgfK9Glbmw7778nAZz/ilc9mU6poQQAyNm1i2EufMf6KzIeWO9/4Mp3rVQZgn4qlGXpik2znX70+ncfe/Z5Xv5jDPhVLc3KLmtStVBaAZWs2cNqdb2yW6eYTDqZmhVJb/R5qVSzNu9/Mp0HVXXnr63lZ29M2ZnD0rROYvmAFd5zefOs/FEl5kgNjJAHwzbff0rJFi6yfk5KS+OGHHxhwxeUANGrYiO9/+J5Gvw42Wbx4MXtUrJg128seFSuy6Ncp/xs3arTZ+efPn8/9DzxIp44d6NWzJ7Vq1cp6rUyZMrz1xuY3P39WunQpVqxYAcCKFSsoU6b0ZvvMnDmT8/v1Y/SoUVv71iVJUg727ffTadHk93uLpKQkpv80g8v7ZT5l3bB+PX74cUbWrCuLlyxlj/LlsmZ72aNCeRYtXgKwxaWO5i/4hYcef4YObVpy+ondqbV39azXypQuxetjnt4u72Pm7Dn0H3Atzz+cOQvMgl8WMmvOXA6st1+2gTE33TaSmwdeQVpa2na5riRJ2vm+nTGXZvX3zfo5KSmJ6XPmc/HpmQ8FHbRvDX6YNZ+Dfl3GaPHyVVTcvWzWbC8VdyvLomUrM/etu/lSRz8vWsrDY16jfZP6nHpEO2pW2SPrtTIlizP+nkHb7b288Np7PHrTxVk/FyxQgIn3DmbW/IUc3W8wHZrU327XkiRJO9/3P6+gSY3fH85JSgr8tHAlFxy6PwANqu7Kj7+syFrGaMnqDZQvXTRrtpcKpYuwePV6AA7cwlJHC5av5YlJ39O6TkVObFaDvcuXynqtdNFCjL74kP/8Hk5otjdXPDmFbsPGs3f5kpQpltkJFUxJZuwlnZm9eBUn3fEabers8Q9nkpSXOTBGEgC1atZi/IQJHHdcdyDzaabq1avz4Ycf0rVrV6Z8OIUmB/8+0neXXXZhzty5rFu3DoA5c+ey666ZNz1bWsKoZs2aTPvicyZNmsTQW4Yxa/Ysuh15FH369GbFihVbNWNM0yZNmfjqq7Rt25ZXxo+nWdOm2fZftmwZx59wAg/cdx+77bbbf/9QJElSwtXcuxoT3nib7kceBmTeo1Tbqwofffo5XTq248NPPuPgg37/QmaXsmWYO/9n1q3LLGXmzJ/PrrtkPomUlBQ2P3/1anz27kQmffARw+64h9lz53Fkl070PrkHK1au2i4zxixbvoIT+57Hvf8bym67Zi6B8NW33zN73nwOPfZkfpwxixfHv0bd2vswc/Ycep93MevWr+e76T9xz8OP0+eUE7b+A5MkSQlXs0pFXn3/U47pmPlk8qZNm6i2R3k+/uoHOrc4iI+++p7G+/3+wNAupYozd8Fi1q3fAMDcX5awa+kSACSFzTuWGlUqMvWZEbz32dfc9shoZi9YxBFtDub0I9uzYvXa7TZjzJwFi0hJTqb8rmWAzJltYoSUlGSKF02lWJGtW45JkiTlXHuXK8kbX83jyIaZs89t2hTZa9cSfDpjER33r8THPy3ioGq/f99Stlgh5i9dw7q0jQDMW7aGXX4diBLC5r1L9XIleefaI/ngh18YOWEac5aupkv9KpzcogYr16VvlxljChdI4daTM78vuurpKRxSrxIZmzZl3rckJ1E8tSBF/mE5Jkl5nwNjJAHQtWsXJkycSNPmzSlUqBAPPfAAl116CSefeipDhw1jryp7cfjhh/HOr0stJScnc9WAAbRs3ZoQAlcNGLDFATF/1qxZM5o1a8bq1at59tnnSEtL2+oZYw49tDNjxo6lecuW1Ni7Bp07dwagV+8+3HfvPdx0883MnTuPM8/OfIL86iuvpE2bNv/hU5EkSYnWpWM7Jr7xDi06d6NQoYLcf/stXHL+mZx2dn+G3XEPVSrtwWGHdODd96cAmfcoV/Q/lzaHdycEGND/vK27R2l8EM0aH8Tq1Wt4buzLpKWlb/WMMb8sXMTJZ17AF199Q7eT+3D+GT057JAO9LngUu657WaGjLiTefMXcM7FAwC48qLzaduyGW1bZq7Rfd2Q4exfpzZVq1Ti3XGZs97NnD2HC6+8zkExkiTlQp1bHMRrH3xK29Mvp2DBFO4ZeB4XnnoUva75H7c9OprKFXajS8uGTPrkayDz/uWyXsfSsc+VhBC4rOcxW3X/0qRebZrUq83qtesY9dp7pKVv3OoZY35ZspzTrxrOlz/M5LgLb+ScHl3p0qoRZ10/kjuvyuxVnn81+zJKq9aup/uFN5AUktiYkcF155z0Lz8hSZKUU3Tcf0/e/Goeh970MoVSkhhxWnPOO6Qu5zzwLiMnTKPSLsU4pF4l3v9hAQDJSUn077I/Rwx9hRDgwi71tvgg0p813nt3Gu+9O6vXp/PixzNJ27hpq2eMWbhyHWfe9zZfzV3KKSPfoG/72hxSrzL9Hp7E8FOa8eXsJVz19IckJwU6H1CJupXKsmLtBk4e+TpJIbAxI3LVUQf+589KUu4WYoyJziDlK2VKl35q6JAh3Xv2PD3RUZQgSSkFYoyxQIwxI9FZJEn6sxBC11bNDn701ReeLJnoLMo5XprwGr3Ou/jdxUuWtvjnvSVJ2jlCCOf27NZxyIjLz3DqEmWZNn0WHXoPmL185erKic4iScrfQgh7li5a6JvvbutRNNFZlPMNe+kzho79bHDGpk1XJjqLlBf986MHkiRJkiRJkiRJkiRJUi7kwBhJkiRJkiRJkiRJkiTlSSmJDiApsVq1acPoUaMoVapUoqNs0amnnc60r76iWLGiNGvalEHXX8+qVas46eRTWLFyBbVq1mLkHbezZMkSjj3uODZu3EiBAgV48P77qVy5Mk899TTXXHstqampfPbJxwDMnDmTAxs2ok6dfQG47557qF69Os8++xzDht9KgQIFuPWWWzjooIOyZWnbvj0ZGRls2rSJadO+YuniRQDcMXIkL4weTUZGBrf/73/UrVuXSy69lA+mTKFE8RI89OAD7LLLLjv3g5MkKQ9pe3h3nn/kHkqVzJmrOw286Vbeee8D1q5bz4nHHsU5vU/l2x+mc0Lvc/lu+o/M/eqjrOzzF/zCeZdexYqVq6hXd1+GXncl1w0ZzqgXX6FsmdJU26sK99x2M6+99S43Dr8DgJ8XLKRzhzbccv1VvP/Rx1xyzWAAhlw7gIMPasCwO+5m3KtvAPDN99O5e/hNdO3UPivfll6vUmlPLrj8GgCWLl9B9b0q8+xDd5OWlsaFV17Pd9N/BGDiqCd2zocoSVIe0anPlTw17HJKFc+ZKyakpadz6a0P8N3MeQCMu+s6nn91MiMeG0OBlGTq7VONWy7qlbX/qjXr2Pewvoy86my6tmrEvc+N55nx75C+MYPmDfbl+nNPBuCiW+7jk6+nE2Pklot60WDfvXn342lcM/IxkkLgwlOP4pDmB/HO1Gn0vPo2qu1RDoDnbhtAsSKp2a7X6+rbWLl6LTWqVGT4pX1ISkri6H6DWbVmLes3pDPovJNp3qAOcxcspufVwwEoW7IED93Qn4IFCuysj1KSpFzpiKGv8PDZbShZpFCio2zR/736Ffe+/jX77lmGR85uC8AnMxZx5dNTKJCcRPHCBfm/3i0pVrgA97z2FaOnziC1QArDTm5KlV2Lc/3zU3nv+wUQ4fQ2+3BM42q89fU8bnv5CwAWLF9L+/325PruDXnr63nc+MInJCUF2tfdg/5d6vHM+9N5YtIPAMxavIqzOtShd9vavPzJLO6Y8CUFkpMYfnJTqpXL3lE1vOI5KpTOvP/r2WYfujaoQoyRm8d8ykc/LSQjI3L/Ga0pW7wwA576gE9nLiZGuOG4Rhyw16478ROW8i8Hxkh52KZNm0hK2jETQ/353P90rf+S5b577qZevXpZP99z770c0qkTffv24YoBAxg/fjwtWrTgqSeeYPfdd2fChAnceNPN/N9dd9KuXVuOOupIGjY+ONs5mzVtyugXRmX9nJGRweAbb2TK+++xZs0ajunenddffTXbMb/9/Oabb/LY45lfEn366ad899332fb9+OOPmTNnLu+89RYTJ05kyNChDLn55n/13iVJyuvywv3KFf3PYeBl/dm4cSMHtOhI31NPYM8KFXhj7NMcdVLvbPtees1gbh18DZX2qJht+7WXX8jhnTtm/dyuVXPatWoOwGln9+eIX1+7/NqbeP7hewA49rQzeeulZ7nwnL5ceE5fAOo170C7ls2znXtLr6emFub1MU9nXvvmW6m2VxUA7nzgEVo3b8LtQ67f5s9BkqS8Li/ct9z9zCu0PHA/hl/aN2vbgfvuzRsP3EhycjKnXDGMD7/8joZ1awJw++Njqb9v9ax9Tzm8Lb2P7gRkDgKaNX8hSUmBb36awxsP3MS3M+Zw7Z2P8+TQy7jq9kd5/teBL53PuJoOTeoDcETbgxl6Yc8t5nvghYl0aFKfnt06cs3Ix5j43qd0ataAJ4ZcQsECBZg1fyF9B45g/D2DePTF1zn1iPYc37kVV454hFff+5RDWzbc5s9EkqS8YtOmSFJS2Cnn/qdr/dssRzWqSsf99+SaZz/K2lZ3z7KMu6wLAEPGfspLH8+kTd09ePnTWbx86aH89MtKBo+ayr19W3NC8xpc1e1A0jZm0Pa6sRzVcC9a1a5Iq9qZPcw5D7zDoQdUAmDEuC948Mw2VChTlENueIlebWpz7MHVOfbgzHufI4a+wiH1KrExYxO3jfucsZd0ZsbClQx+4WMeOLNNttxFCxVg9MWHZNs27tPZlChSkOf7d8raNnfJar6dv5xxl3Xh+5+Xc8MLH/PQWW23+XOStO0cGCMl0LRp0+jVpw+pqanU2LsGd//fXbz55pv0v+hiqlSuzNJlS/nf8OEsX76c0WPGctvwW5k5cyYX9OvP6BdGMfSWW3hl/HiWL1/BwKuv5rDDujLw2muZMWMmS5Ys4coBV/DmW28xfsIENm7cyK233EKjRo144oknGTZ8ONWrVWPZsuV/me/Gm27a7Nj96h1Am9atmTt3LnXq7JvtWi+MHs3k994jOTmZu++6i1q1amXb/7lnn9nmzyiEwBlnnUXRokUZfP31NG7cmOnTf+TUUzKfSKp/QH3eefddOnfuTLFixQAoVKhQVjn0VzO1fDBlCs1btqThQQdx8003sWTJEsqXK0ehQoUoVKgQCxcuYv369RQuXHizY59+5lm6H3sMAKPHjCEjI4O27dtTda+q3D7if0yf/iP16u2fma9+fa4eOHCb37ckSTnFtG++o2+/S0ktXJi9q+3FXcNu5K1J73HRVYOoUmkPli5bzq2Dr2HFypWMGTeRWwdfw8zZc7jwyut4/pF7GXbH3Yx//S2Wr1jJ1ZdcQNdO7bluyHBmzJrD0mXLubz/Obw96X0mvPE2GzdmMPT6K2nU4ACefH4Mw++8l+p7VWbZihV/me/m20ZuduwBLTvRutnBzJu/gH33qZHtWmPGTeC9KR+TnJzEncNuoNbe1bPt//SDd23zZ1SwYEEANmxIo0qlPSlQoAAFtvC08saNG/lx5iwGXH8z8xf8whX9z6Vty2YAXD/0f9x21/1cdG5fDu3weyGyYcMGPvn8Sx64Yxjr1q0HYLddM+9vkpJCtvuVD6Z+Qt3atUhN3fz+5e9eH/vKq7z5YuZ92riJb3Bgvf0Yed9DdOnUnn5n9trSqSRJypG+mj6LswfdSWqhglSvVIHbB5zJ21O/5LJbH6Ryhd1YtnIVQy7sxYpVa3jx7SkMvbAns+Yv5JJh9/P0sMsZ/sgLTHzvE1asWsuAPt05tGVDBt/9FDPn/8LSFau4tOcxvD11Gq+9/wkbN27ipv6ncVCdGjw9/h1GPDaGanuWZ9mqNX+Zb+iDz292bMPjLqDlQXWZ/8sSalerlO1aY9+cwgeff0NychIjrjiTmlX2yLb/40Mu2ebP6JVJU2lQuzr/9/TLdG5xEOedeDiVK+yW9XqhggVICplfYi1dsYrvZ83joH1rZL3+24wsGzdmUKJYEcqWKk4IgaKFC5GRkcGKVWsoU7I4AGnpGylbqgQApUoUZfqcnwF46a0pfPbNj3RoUp+LTz86W76f5vzMiV0zv2iqV7Mqkz/9ik7NGmRdd+WatdSulvllVs299mDR0sz7xD9eV5KknOqbecvo//BkChdMpuruJRh2UlMmffszVz/zIXuWLcbytRsY1L0RK9el8cqnsxl0XCNmL17FlU9/yCNnt+WOCV/yxpdzWbEujYu7HkCnepUYMvZTZi9exbLVG+h36P5M/m4Bb3w1l40ZkeuObUiDqrvy/JQfuWviV+y1W3GWr93wl/n+N+6LzY5tOXA0zWuVZ/6yNdSqWDrbtcZ9OosPf1xIclLglhObsHf5Utn2//Pgka2xW4lUZqdtzLatQMrvg4HXp22kermSzFm8mhrlSxFCoFq5knw+awkAVXfLvPcokJxEUhIEfh+csyE9g89nLuH203YHYO/ypVi5Lo1dNhYmKSlku86C5WvZuGkTe5Qtxvc/L2fv8qVILZhC7T3KMG/p5vd769M3csTQVyhbvDA3HN+I3UsW4ZXPZlGmWGGOvOUV6lXZhau7HUjpYoUoWjCFjE2bWLE2jTLFttzhSNr+HBgjJdCEiRPp06s3p59+Gps2bQLg8gEDeHXCeEqWLMl+9Q742+PPPussLr7oIpYvX06HTp047LCuAOy++248/NCDTJs2jWnTvuLtN99k8eLFHN/jBMa/Mo6bhw5lyvvvkZaWRpWq1bZ47i0d++rECaxatYo+vXtRu3ZtBl57bda1PvnkE3788ScmvfMO06ZN49LLLmfM6Bey7f9HTzzxJPfcd2+2bZX2rMQjDz+UbdstQ4dQtmxZZs2axWFHHMlnn3xMnTr78vobb9CoUSNefe21bPtv2LCBgdddx//deedffm7ly5dn+vffUaxYMS686CIeeuhhTj/9NObNn8+yZctYvnw506dPZ9myZZQvXz7bsRs3buSdd9/ljttHALBgwS/EGHn91Ve58aabuP+BB2jZogUPPfwwF190Ea+++trfDj6SJCmne/XNd+h1Ug9OO+HYrPuVAYOGMP65xyhZojj1W3b62+PPPP1kLjynL8tXrOCQY07OWuJn99125cGRtzLtm++Y9u33vDH2GRYvWcqJfc/j5acfZujtd/He+NGkpadTvX6zLZ57S8eOf+4xVq9eTa+Te1C75t5cN2R41rU++XwaP82YzdsvP8e0b77jiutuYtSj92Xb/4+efH4M9z2SfSmhPfeoyEMjb90syzmXXMmYlydwxukn/eVnsWjxUr746hsev+cOSpUsQbsjjuOjN17m7F6ncvUl/ViydBkdu51A00YHZi29NOGNt2nXqjkhBJatWEHJEr9/4VOqZAmWLl9BhXKZJcqzo1/imCO6/OX1t/T659O+Zq/Ke1KieOZ5581fwGkndGfQlZdwxAk96dC6BfvWqrGl00mSlOO89sFnnHZke045vF3Wfcs1dzzGi3cOpGSxIjQ67oK/Pb7vsZ3pd/KRLF+1hsPOHpg1+8huZUpx77Xn89X0WXz942wm3DOYxctXcuoVtzLm9qu49eEXePuhm0lL30jtw/pu8dxbOvalOweyeu06Tj+yA/tU3ZPBdz+Vda1Pv/2RGXMX8Nr9N/LV9FlcNeIRnrn1imz7/9HT49/hwVETs23bo9yu3Hfd+dm2zf9lCacc3o5rzz6Ro/vdQLuDD8gaaPLxVz+wYPEyDqyT+bt/+CMvcN4Jh/HKu1OznePGe5/mkbGv06bR/hT9dcDtHrvvwgFHn8uadet56c5rAShSuCAz5/1CyeJF+fSbn1i+cjX1a1fj81EjSQpJnHblrbwx5XPaNNo/69y1q1XirQ+/4KA6NXhjyudZ29PS0+ly1kC+nzWPewaeB0DDOjU54rzruPe58ZTftQyN96/1t//7SpKUaG9+NY+TWtSgR7MabNoUARg86mOe7deREqkFaXXt6L89/vRW+3BOx7qsWLuBY4dPpFO9zN/hu5ZI5Y7TW/DNvGV8M28ZYy7uzJJV6+l779s8fUF7bh//JeOv6EL6xk00uOzZLZ57S8c+178ja9anc1KLmtSsUIohYz/NutYXsxYzc9EqXrr0UL6Zt4zrn5/KI+e0y7b/Hz0/5Ucefef7bNsqlinKyJ4ttuqzG//ZbG4e8ykFU5I495D9iDHyxawlrE/fyJezl/LzsrXZ9r/39a/pUr9Ktllr3vhqLq32rUD4dRDwofUr0/22iaQkJ3FCs71JLfj71+Zjp87gsAZVAFi+ZgMlUn9/ACrGzfO9fNmhlClWmPGfzWbgsx9xV6+WLFyxjuq7l+SFiw7hwkcn89qXc2lXdw8qlClKk6tGsXbDRp7r//e9mqTtx4ExUgKdduqpXD9oED1OOJFOHTty8sknsWFDWtYsJ/X2zywGfvslDRD/8Bv38cef4OFHHyE5OZk5c+ZmbW/cqDEAX3/9DVM+/JBWbTJH5a5du5ZFixZRoXx5ChcuTOHChalZc8tfdGzpWIDixYtnG+Ty27V++GE6Bx10IAB16tRh/s8/b3H/3/TocTw9ehz/j59R2bJlAahcuTIVK1Rg8eLF9Dz9dM4973zatm/PPrX2YZddymZ9Nqf37MVZZ5xJrVp/XYb8NisMQPdjj+XhRx4lKSmJW28ZypHdulGhfAUOOKAeu+66+bqOb7zxBi2aNyclJfOvz1KlSlL/gMypgNu3a8cDDz7E2WedRfv27WjTrh2NGzWicqVK//g+JUnKqU45/hgGDxvBSX3Po0OblpzUvVvm/UrZMgDsXyfz9/wfn8D5Y0HwxPOjefSp50lOTmLuvPlZ2xs1yBwA/M13P/DRx5/R9vDuAKxdt55Fi5dQYffds+5XalSvusVsWzoWoFixYtkGufx2rek/zeDAA/YDoM4+NZm/YOEW9//N8d0O5/huh2/V53THkEEMvfZKWnY5mpOPO5o9K1bYbJ9SJUtQtXIl9qqc+UXWHhXKs3jJ0qwZYMqWKU3jg+rzw08zOeiAzPvAZ0e/xNm9TwWgdMmSrFi5Kut8K1auokypzAE0MUZee+tdbrjq0i3m+6vX/zxYpmTJ4rRp3oSkpCRaNTuYr7/93oExkqRc46Subbjpvmc5dcCttD/4AE7o0poNaens8uusJXVr7AXAH2qWbD3L06+8zeMvvZl53/LLkqztDetm/i78dsZcpk77nk59rgRg7foNLFq2kvK7lqZwoYIULlSQvStvfg/wV8cCFCuSmm2Qy2/X+nH2z9SvnTmN/77VK/Pz4mVb3P833Tu1oHunf/5iqWTxorQ6aD+SkpJocWAdvvlpDrWrVWLW/IVcPOx+nrrlMgAWLF7G7PmLqF+7+mYDYy7v3Z2LTzua4y6+ifc//4a169NYsXotn48ayY9zfqbfzffw4siB3HJxb84efCfFUguzX80qlNulDMWKpGad54i2Tfj8u5+yDYw55fB2XDj0XjqfeTW1quyRNeNMwQIFmHjvYGbNX8jR/QbToUl9rrz9EYZc2JM2jfbn+v97gifHvU2PQ1v942cgSVKiHN90b2596TPOuPdtWu9bke5NqrNhYwZli2cONK2zZ2bX8lcdy/NTfuTp96eTnBSYt+z3WUsaVM38LuP7+cv5ZMYijhj6CgDr0jayeNV6ypUqQuECKRQuANXKldxiti0dC1C0cIFsg1x+u9ZPC1dSr0pmn7FPxdIsWL5ui/v/plujanRrtOUHtbdGp3qV6FSvEiNe+YIH3/yG/l3q0bttbbrfNpG9y5WiftXfVw949Ys5TP5uAQ/+acaaMR/NpFebfbJ+HvDkFF6/+nBKFSnI8SNeZc6S1exZNnNlgrEfz+S+vq0BKFW0ECvXpWcdt6XVLH+b+aVTvUoMe+kzAEoWKUjzfTLvDVvVrsi385eTkpzEynXpfDCoGzMWruTSJz7g2X4dNz+hpO3OgTFSAqWmpjL81luJMbLPvnXo0eN4ChYswJIlSyhZsiSff/EFAKVLl2bu3MyBL59++lnW8cOGD+fLzz9j9erV1Nnv9xLht2WEatWqSbOmTXnowQcASEtLIzk5mfk//8yGDRtIS0vj++9/2GK2LR37x3P/+VrVq1fjmWczRxpPmzaNCr/OtPJX611v7YwxK1asoGTJkqxYsYLZc+ZQtmxZkpKSuPeeuwHo178/Rxye+YXVZZdfTp06+3Lsr8sc/ZWVK1dSokRmsfL2O+9QvXrmzVi7du1o164dc+fO5YoBV2YNfvmjp595lhNP6JH1c4vmzZk0eTLdux/LJ598StWqmSVb/3796N+vH6NHj9ls1hlJknKT1MKFGTboamKM1G3SluO7HZ55v7J0GSVLFOeLr74BMgeLzpu/AIDPvvwq6/jb7ryXT9+ZwOo1a6nXvEPW9t+e2Km5dzWaNDqQB+4YBvzhfuWXXzLvV9LT+eHHGVvMtqVjgazp//98rWpVq/DcmJeBzNlmKpTbbYv7/2ZrZ4zZsGEDhQoVonDhQhRJTSV1C0sxAqSmFmbXXcqydNlyihZJZd7PCyhbpjQrVq6kZIkSpKWl8cnnX3L1xRcAsG7der78+lsaH1g/63iAxUuWApCRsSlrGaXJH3xE/f3rZg3+/bO/ev3lV9/g8n7nZP3c/OBGfD7tazq0acmnX0yjRdPGWzyfJEk5UWqhggy58HRijNQ/+ly6d2pBwQIpLFm+kpLFijLth5kAlCpRjPm/Dnz5/Lufso4f8dhYPnz6NlavXc9B3X+faeW3bqNGlYocXG+frBlL0tLTSU5K4udFy9iQlk5a+kamz/59IPAfbenYzHP/+b4l81rV9izPqFcnA5mzzZTfpfQW9//N1s4Y07R+bb74fgbtDz6Az779iRYN6rBs5WpOHTCMu64+h93KlALg6x9nM+eXRRx+7nX8NOdnXn7nI+pUr0yF3cpSqGABUlKSKZpamNTChVi1Zh1lfl1SqXSJYqxem/nFWL1aVXn5zmtZsXoNfQfeTuUKu7Fi9RpKFisKwKRPptG64f7Z8hUuVJCRV54NwCXDHqBLq0ZkZGQQI6SkJFO8aCrFimTe/2zatClr4EzZUiVYuTr7k+KSJOU0hQskc333RsQYaXr1C3RrVJWCKUksXb2eEqkF+Wpu5r/vlyxakPm/Dnz5cs7vg3XvevUr3r7mCNZsSKfFwNFZ23/rNaqXL0mj6rtz++nNAUjbmEFyUmDB8rVsSM8gPWMTP/2ycovZtnTsH8/952vttVsJxkydCWTONlOuVOoW9//Nf5kxZkN6BoUKJAOZg03WbsgctHN042oc3bgaX8xazHNTMu/pPpu5mNvHf8mT57fPdt+0Lm0jX89dyoHVfl9CMjk5ULxwAVKSkyhaKIXV6zPvz+YuWU1KUhLlShUBMpdnmv7zCtanb2TWotWUL110s3wAhQok8+mMRZT/9bjGNcoxbc4SGlTdlS9mLWG/ymXZtClSpmghQgiUKloo65qSdjwHxkgJ9MQTT/Lwo48QY+SQTh1JSUnhhkGDaN+xE5UrVaJChcwBFXXr1iU9PZ12HTpwQL16Wce3atmS5i1b0qB+A0qVKrXZ+ffbbz9q196Hlq1bk5SUxMGNG3PD4MFcfOGFNGnWnJo1alC5cuUtZvurY/9KgwYN2GuvKjRt3pykpCTuvuuuv33vWztjzPE9TmDlqpVs3LiRm24YTFJSEp999hkX9O9PcnIyRx5xBPXq1eObb77h1uG30bRpEyZMnEjDgw5iyM03M3HiRIbccgs//vgj7Tp04L577mHatGlcc+11FC1ahPLlyvPgA/cDcEG//nzx5ReUKF6CO0feAcD48eNZvXoNRx/djfT0dN7/4IOsQTkAhxxyCC++9DKt27alWNFiPPH4YwC0atOG5ORkataoyW3DN19uQZKk3OLJ58fw6NPPE2OkY9tWpKSkMGjAJXQ6+kQq71mR8uUy12WuW7sW6RvT6djtBOrV3Tfr+BZNG9Oq6zHU368upUqW2Oz8++27D7Vr7k2bw44lKSmJxgfWZ9CVl3Dh2X1p3rkbNatXpdIeFbeY7a+O/SsN9q9Llcp70qJzN5KSkrhz2A1/+963dsaYM/pfzuy580hLT+e4ow5nl7Jl+GXhIk4+8wK++Oobup3ch/PP6Mlhh3Tghqsv46iTepOWnsbF551BcnIyF189mG++/4GMjAx6ndQjawaZca++Qce2rbJda/BVl3LkSb0AuOmaK7K2PzP6JY45PPsySX0uuJR7brv5L1+f+tkX1KxWlaJFi2Rtu+icvvQ89yJuuPUODqq/PwfW2+8f378kSTnFM+Pf5fGX3yTGSPsm9UlJSWbg2SfS9exrqVR+V8rtmvkUdp3qlUnfuJFDz7qG/WvulXV88wb70r7XAA7Ypyqlihfd7Px1965Crb32pGOfASSFJBruV5Nrzz6RC046nDanX8belSuyZ7ndNjvu7479KwfsU43KFXen7emXk5QUGHHFmX/73rd2xph+Jx9J34G3M+T+Z2mw797Ur12dK0c8wryFS7jgxsy+47Lex9Km0f5ZM7kMvvsp9qu5F3vtUY4rRzzC1Gnfk74xg2YN9uWAWtXIyMjgyXFv06H3ANZvSOOqMzMfKLrloed5/f3PKFiwADf1Ow2A5yZM4qExr1EwJYW6NarQtVUjAM66fiR3XnU2n383g0uH3U9SchKHtWrM/jX3YvmqNXS/8AaSQhIbMzK47pzMpSsvOq0b/W++h5TkZAoVKsjDN1z4j+9fkqREGjXlJ55+fzoxQts6FUlJTuKKIxtwzPAJ7FGmGLv/OqCidsXSbMzYRLdbx1N3z7JZxzepUY7Dhoxjv8plKZlacLPz77tHGWpUKMXhQ8eRFAIHVt2NAUc14OyOdTn0ppepXq4ke5Td/B7n7479K/tX3oVKuxTj0JteJikEbjmpyd++962dMebp96bz6Lvf8dMvK+l263geP7cdr3w6m4fe/pakEChZpCB3nJ55z9PnnrdYvHIdu5UswtATDwbgsifeZ13aRk4Y8RoAD57VhtJFC/Hal3NpU2ePbNc6t1PdzPebFKhXeRf2qZg5EHnM1Bl0PbBK1n4pyUmce0hdjrxlPAWSk7j15KYAPDX5B6rsVoIquxbnhNtfpWihAqQkBYaemPlZHN9kb85/6F1e+HAG5UsX4bIjMmc0fvaDHzlsyDg2pGdw6eH1//EzkbR9hLilhdAk7TBlSpd+auiQId179jz9H/c99bTTueD886j3h8Ewyv2SUgrEGGOBGGNGorNIkvRnIYSurZod/OirLzy55bl1/+T0cy7kvL6nZxsMo7znpQmv0eu8i99dvGTp1i3+LUnSThBCOLdnt45DRlx+xpana/uTPgNHcPbxXbMNhlHeM236LDr0HjB7+crVW34aTJKknSSEsGfpooW++e62HlsejfIn5z7wLn3a1aZupbL/vLPynGEvfcbQsZ8Nzti06cpEZ5HyImeMkcR3331H3zOzP3l09113UbNmzQQlkiRJyu676T9y1oVXZNt257AbqFn9369PLUmStCN8P3Me592QfSbdEVecSY0qW54FT5IkaWeavmAFFz36XrZtt5zUhOrltuoZKUnKlRwYI+VgDz34wE65Ts2aNXnrjTd2yrUkSVLe8sAdw3bKdWpWr8brY57eKdeSJEl50z0Dz9sp16lRpSLj7xm0U64lSZLyjttPb75TrlO9XElGX3zITrmWJOUUSYkOIEmSJEmSJEmSJEmSJO0IDoyR9J/Uq99gh1+jWImStGrThlZt2jBp0iQATjjxpKxtqUWLsWzZMjIyMujdpy/NWrSgd5++ZGRkAFC9Rs2sfZ977nkAvvrqK1q0akWLVq249977dvh7kCRJideg1Y5/GqrNYceyS7W6jBk3IWvbbf93H9XrN6Xbyb2ztm3cuJETep9D667H0rrrsfw0czYAz415maadjqBVl2P46NPPs/Yfed/DdDiqB20P786XX3+7w9+HJEnKGRr36LdTrjNr/kJKH3wMn383A4DPv5tB69MupX2vK7ItC/XeZ19z6FnXcEjfq3ji5bcA6Hzm1XTqcyUdeg9gjzYn7ZS8kiQp52l97Zgdfo3Dh46j+nmPM+7TWVnb3vtuAZ1veokuN7/MxM/nAPDDz8tpfe0Y9jzzEVas3ZC177Mf/EiHQS/ScfCLPDHp+x2eV1LO4VJKknK86tWrb7bU0+OPPQrAjBkz6N23L6VLl+bFF1+kRIniTHrnHS686CLGjRtH165dKVas2GbHX3b5Fdx7993UqFGD9h070q3bUZQpU2anvSdJkpQ3PXbP7dz3yBPZth1/1OF07dieS675fUmF9z/8mKJFi/Lmi88w/rU3ufP+h7l54BXcOPwO3pswmjVr13Fcz7OYOOoJPv1iGt9P/4mJo5748+UkSZK2i2EPPc/B9fbJ+vmup15i8Pmn0KRebU6+/Ba+/GEme1eqwLCHRjHqtispVLBA1r7j7roOgLenfslT497e6dklSVL+cXfvVjzyznfZtl3//FQeP68dRQsV4Khh42lbtyIVyhRlzMWHcPLI17Pte+eEaYy7/FBSkpJoN2gMPZrV2JnxJSWQA2OkPG7atGn06tOH1NRUauxdg7v/7y6G3nILr4wfz/LlKxh49dUcdlhXBl57Ld9//wPLly9nQ9oGehx3PE889STJScm8Mu5l3n33XQbfcCOpqanMmz+fu0beQcOGDbOus3jxYnr17sPKVSspW6Ysjz7yMNOnT9/s2v/GzJkzadGqFdWrVed/tw2nePHiWa89/cwzHHv0MQBMmjyZzodkPgne5dBDmTBxIl27dmXdunW0atOGXXfZldtH/I9y5coxb/58atasCUCtmrX48MMP6dSp07/9mCVJ0nYw7Zvv6NvvUlILF2bvantx17AbGXbH3Yx//S2Wr1jJ1ZdcQNdO7bluyHB++HEGy1esZENaGscddThPjRpDcnIyLz31EJM++JAbh48ktXBh5v28gDuGDqJh/XpZ11m8ZCl9+13KylWrKVu6NA/deSvTZ8za7Nr/RoVyu2+2bffddmXd7DnZtlWutAfp6ekALF+5krKlS7N4yVLK774bhQoVolChQixcvIT169cz9pWJZGzKoMNRPdirciX+d+NAChcu/K/ySZKk7eur6bM4e9CdpBYqSPVKFbh9wJkMf+QFJr73CStWrWVAn+4c2rIhg+9+ih9mz2fFqjVsSE+ne8cWPD3hHZKTkhg94iomf/oNQx54jtRCBZm/aAn/u6wvB9b5/YuaxctXcvb1I1m5Zi1lSxbnvusu4Mc5P2927X/j+5nzKFigAHvsvkvWtpp77cHK1WuJMbJm3XpKFS/KlC+/I7VQQbpfdCPJSUncekkfKlfYLeuY5ydOoluHZv/+w5QkSTvUN/OW0f/hyRQumEzV3Usw7KSm3DHhS974ci4r1qVxcdcD6FSvEkPGfspPv6xkxdoNpG3cxFENqzLqw59ISgo8dX57PvjhF4a//AWpBZP5edlahpx4MPX32jXrOktWraffI5NZvS6N0sUKM7Jnc2YsXLXZtf+NcqWKbLYtLSODMsUye5JSRQry0y8r2bt8qS0eX233EqzZsJFCKUkULVxgi/tIypscGCPlcRMmTqRPr96cfvppbNq0CYCzzzqLiy+6iOXLl9OhUycOO6wrADVq7M3Aa66hd5++zJ03l9dffZXeffry3nvvAbBq9SomjH+F2bNnc1rPnrz5+u8jbW+6+WbOOvMMOnTowMg77+Sxxx5nxcoVm137j04+5VRmz5mdbVufXr3p0eP4bNt+/OF7ypYty4jbb+fmIUMYdP31Wa89P+oFXnn5JQCWLVtOyZIlAShVqhRLly4D4L1J71K2bFnGjn2Riy6+hMcefYRqVavy3nvvUb9+fSZNnkzTJk3+0+csSZL+u1fffIdeJ/XgtBOOzbp3OPP0k7nwnL4sX7GCQ445ma6d2gOwd7W9uPqSfvTtdxnzfv6ZiaOeoG+/y3j/w48BWLV6NeOeeYTZc+fR67yLeW30U1nXGTLiLs447STat27Bnfc/wuPPjmblqlWbXfuPTj27P3Pmzsu2rdfJPTi+2+H/6r2W221XVq1ezX5N27Fu/Xomjx/NLmXLMG/BLyxbvoLlK1by44yZLFu+kgULFxEjTBz1BDffNpIHHn+Gs3qe/K+uK0mStq/XPviM045szymHt8u6h+h7bGf6nXwky1et4bCzB3Joy8wHi/auVIEBfY/j7EEjmbdwCePuuo6zB43kgy8yn3pevXYdY++4mjkLFnPGtbfzyt2/9x/DHhpF72MOoV3jetz9zDieeuVtVqxeu9m1/6jX1f9j7oJF2baddlQHundqkW3b0Aef49qzT2TgnY9nbWvfpD7H9r+BAikP0PSAfdmz3K68/9m3/DD7Z95+6GY+/+4nBvzvIR67+RIANm7MYPKnX3PrJX22w6cqSZJ2hDe/msdJLWrQo1kNNm2KAJzeah/O6ViXFWs3cOzwiXSqVwmAqruX4JLDDqD/I5OZv2wNz1/Yif6PTOaj6QsBWLM+nWcu6MDcpas5/6FJvHDR78tXjxj/Bae1qkXrfSty/5vf8NwHP7FyXdpm1/6js+9/h3lL12TbdlKLGnRrVO0f31dqwRRmLVpFySIF+Xz2EpavTfvLfTvVq0Tb68awKUau6nbgP39okvIMB8ZIedxpp57K9YMG0eOEE+nUsSMnn3wSjz/+BA8/+gjJycnMmTM3a9/999sfgIoVK7Bf3f2y/rx06TJKlizBAfUOICkpiSpVqrB8+Yps1/n662/4YMoUbrjpJtavX89hXbtyRt++m137jx55+KGteg9ly5YF4Lju3Tnt9J5Z27///nvKlinDLrtkPtFUunQpVqzIzLVixQrKlCmd7fjDDuvKdYMylzAYOuRmzjn3PDIyMqhZowbly5fbqiySJGnHOeX4Yxg8bAQn9T2PDm1aclL3bjzx/Ggefep5kpOTmDtvfta+++2bOdV/xfK7U7d2raw/L12+nJIlilOv7r6Z9y2V9mT5ipXZrvPNdz8wZeqn3HTbSNZv2EDXju3pc+oJm137jx4aeet2fa8PP/UctWvW4LmH7+HNd99jwKAh3Pu/Idxy3ZUcfUofKpTbnXp192XXXcpQqmQJDqhbB4C2rZrz0BPPbNcskiTp3zupaxtuuu9ZTh1wK+0PPoATurTm6Vfe5vGX3sy8f/llSda+dWtUAaDCrmWps3flrD8vW7GKEsWKsn/NvUhKSqJyhd1Yvir7F0Pf/jSHj778jlseeI71aekc2uIgenbruNm1/+i+687/x/xffD+DUiWKUWG3stm2X3Dj/zHm9qupXqkCfQaOYPKnX1OyeBEa71eTwoUK0mi/Wlx0y/1Z+7819UuaHlCblJTkbfr8JEnSznN807259aXPOOPet2m9b0W6N6nO81N+5On3p5OcFJi37Pf7j333KANkztBS+w9/XrZ2AyVSC1KnUhmSkgKVdinOij8NRPl+/nI+/mkR/xv3BRvSM+i4/56c0qrWZtf+o5E9sw/c3RY3Ht+Y/o9OpmihAtTZswy7l0zd4n6r16dz+/gveX9QZudz5C2v0KV+FYoU8utyKT/w/+lSHpeamsrwW28lxsg++9ahR4/jGTZ8OF9+/hmrV6+mzq+DYQBCCFv8c4yZo3c//+JzYozMnj2bUqVKZrtOrVo16dqlC61bZ5YwaWlpZGRkbHbtlJTf/9rZmhlj1qxZQ+HChUlOTubtt9+hevXfb5aefuYZuh97bNbPTZs0ZeKrr9K2bVteGT+eZk2bsmHDBgAKFSrERx99RMUKFQCoUqUKL704lg0bNtD9uONp3LjxNn6ykiRpe0stXJhhg64mxkjdJm05vtvh3HbnvXz6zgRWr1lLveYdsvb9p/uWL776JvO+Ze48SpUske06NfeuRpeObWnVLHPGuMz7lk2bXfuP9y3be8aYjIwMyv42iLdMaVauXAVA25bNaNuyGXPn/8yVg4eSkpJC88aNmDzlI449siuffjGNqpUr/atrSpKk7S+1UEGGXHg6MUbqH30u3Tu1YMRjY/nw6dtYvXY9B3X/fXDKX96//PrfX/4wkxgjcxYsolTxotmuU6NKRTq3OIiWB9YFIC09nYyMTZtd+48DU7ZmxpjPv5vB59/+xOHnXsdX02fx4+yfGTvyGmKE0iWLE0KgTMnirFy9hkb71eK2R0cTY2T67PnsXrZU1nmenziJ4zq3/NefoyRJ2vEKF0jm+u6NiDHS9OoX6NaoKne9+hVvX3MEazak02Lg6Kx9/3Crku3Pv9YufDV3KTFG5i5dQ8kiBbNdp3q5UnTcf0+a1SoPQNrGDDI2xc2unZKclHXMf5kxpm6lsjzfvxMr16Zx7oPvUmmX4lvcLwQomJJEasHkrPeSsYVZ9yTlTQ6MkfK4J554kocffYQYI4d06khKSgqtWrakecuWNKjfgFKlSm31uUqXKs1hhx/B/J9/ZuTtI7K9NuCKK+jT9wyuHzwYgGuuuorp03/c7Np/tDUzxnz77bf07nsGxYoVpXix4jz4wO9PI70wegxvvPZq1s+HHtqZMWPH0rxlS2rsXYPOnTvzyy+/0OWwwylWrCgpKSn83513AvDQQw/z8KOPkJSUxMCrr6Zw4cJb/TlIkqQd48nnx/Do088TY6Rj21akpKTQomljWnU9hvr71d1sgMvfKV2yJEee2Iv5C35hxM3XZXvt8n7ncGb/yxk87HYArrrofKbPmLXZtf9oa2eMOfnMC/jgo48ZPW4CX379LVdedD6PPv089z3yJD/8NIOO3U5gzOP3c8IxR9Kj1zmMfWUiaenp/O/GzIz9B1zLl19/S4nixbh9SOZMd53ateKlia/R7ojjKFa0KI/e/b+t/hwkSdKO9cz4d3n85TeJMdK+SX1SUpJp3mBf2vcawAH7VN1sgMvfKVW8GMf0v4GfFy1l+KXZlyS65PSjOXfwXdx0X+bMcVf07s5PcxZsdu0/2poZY07q2oaTurYBoM/AEZx9fFeKphbmyjOO5+gLBlOwQArldilNu4MPoEBKCke3b0aH3gOIMXLb5WcAkL5xIx9++R0jrzxrq9+rJEna+UZN+Ymn359OjNC2TkVSkpNoUqMchw0Zx36Vy1IyteA/n+RXpYoU4qQ7XmfB8rXc1CP7g8f9Dt2PCx99j1tf+gyAi7oewIyFKze79h9t7YwxZ973Nh/9uJBxnxbg67nLuKhrPUa88gVvfjWPginJXHds5hKWC1eu48z73uaruUs5ZeQb9G1fm0PqVebIhlXpfOPLRCJdGlSm+Da8Z0m5W/jtiUpJO0eZ0qWfGjpkSPeePU9PdJRt8tZbbzF6zFhuG759lxHIj5JSCsQYY4EYY0ais0iS9GchhK6tmh386KsvPFnyn/fOmd6e/D5jxk3k1sHXJDpKnvHShNfodd7F7y5esvTfz20sSdJ2FkI4t2e3jkNGXH5Grn/a5Z2p03jx7SkMvbDnP++svzVt+iw69B4we/nK1ZUTnUWSlL+FEPYsXbTQN9/d1mPrR8rmApO/+5lXPp3NoOMaJTpKnjLspc8YOvazwRmbNl2Z6CxSXpT0z7tIkiRJkiRJkiRJkiRJuY9LKUnaKq1ataJVq1aJjqH/Z+8+o6Oq9jgMvzsJCRB6R3rvRar03jtiw0q3oYICUlRQRAEBaVJUBFRQQSnSe69K7yBNivSEUEOSfT8MNxoDGCDJmZn8nrXuWpfJmZn/5F4Ob2Z29hEREZH/VK1SBapVquD0GCIiIiIxVrVMUaqWKer0GCIiIiL/qVKBzFQqkNnpMURE7ot2jBERAEqWKh3nz3Hx4kXKPfYYyVKkZNu2bZG3d+jYiWo1alC2/GNMmzYdgIkTJ5E3fwGq16xJ4yZNI48d/cUXVKxcmbr16nP27Nkoj79z506q16xJ9Zo1KV7yUVo+3gqAAwcOULV6dSpUqsSMGTMB2LRpExUrV6ZajRo0adqMK1euxO2LFxERkThRunqDOH+Oo8f/JFOBR6nV7ClqNXuKQ4ePAlCr2VNUa9SKWs2eYvRXkwCYNHUaBctWo1azp2jW+u9LZw4ZNY6K9ZpRsV4z5i9eHu05/n+fWs2e4ufZ8wDo9eGnVG7Qgkr1m/P9tBlx/jpFREQkdjzWukucP8fF4BCqvtCNDFWeYfv+IwBERETQ9PV+1G7Xk9rterJt32EALl+5RrPOH1K/Yx+avNaXS5dd74GcPneRp9/5lAYvv8e7w74BwFrLh2Om0OjVD6jfsQ/ngy5Hed6Px/1AmSffoH7HPrz60ei7zgLwWv/R1OvYmyovdOOXJWvj/HsiIiIi969Gv1lx/hzr9v9FgwFzaDpoHp3Gr+BWWETk18IjIqj8/i+MW7IbgB/WHqRcr+k0HzyfZ0csjjyu3/TNNB00j2dHLOZCyI3Ix2346RwaD5zLou1/Rnvenccv0OCTOTQZOI93vl0XeXvvHzbQ8NM5NPhkDluPnAMgNCycHt+v5/EhC3h8yII4+T6IiLO0Y4yIxJvkyZMzb84c3unWPcrto0eNxN/fn5CQECpWrsITT7gWtLz+2qu89eabkcdduHCBqT/8wJpVq5g7dy4DBw1iyGefRX69WLFirFi2DIAP+vYlb568APTq3YfRI0eSN29eqlavQZMmjXn00UdZt2YNAH379WP69J956aUX4/T1i4iIiOeqVL4MP0/+Mtrts6Z8TaqUKaPc9kq7F3jz5XaRfw4PD2fyD9PZumohIVeu0PDJF2hQp0aU+wQGJmXprB+j3Nb2uacZ8P67hIaGUrZmI55u2RRfX99YfFUiIiLiqZIHJuGXEe/R6/OJkbcZYxj+bidyZc3EgaMn6Tbka2aNfJ9fV2ykYolC9Gj/BF9OX8DUeSt49enG9Px8IoPfaUe2TOkjH+PXFRtJmTyQuV/0u+tzf/DqszSpXv6eswAM69ER/0SJCLl6nZpt36Vl7Uqx9vpFRETEc+TKkJwZ3eqTOJEf/X/5jTlbjtKiXG4Apm34g2xpk0U5vl3NQnSqXSTyz9uPnefUxavM7t6Q5btPMmrhTj5oVZaPfv6N79+oTWBAIloOWUCtYlnw9fl7T4ivlu3lg1ZleSxfRjqMW87uExdJmcSffaeCmPduYw6cDmLAjN+Z+GotJizfR+WCmRn4rHYgFvFW2jFGxIt1fuNN1txe/PHbb7/RoWMnzpw5Q606dahavTpNmjbj5s2bUe7zUpu2kbu59O3Xj5kzXauFP/n0U6rVqEGlKlXYuHHjA82TKFEi0qVLF+12f39/AK5du0ahggUjbx83/kuqVKvGhAmu31ratGkTNapXx8fHhwYNGrDhHnPMmv0rzZq5dpo5euwYxYoVI0mSJBQuVIhDhw6RKFGiyGOvX79OwYIFHug1iYiISOx7890PWLNhMwC/bdtBpy7vcubsOeq2bE2NJk/S/Nl20Rqm7etvs22n67eLPhw0jFnzFgIw8PPR1Gz6JFUbPs7G37c+8Ewbf9tK9cZP0O39/oSFhQGuD59aPNeBps+0Yf+hPyKP/WryFKo3foJvvv8JAF9fX7JnzcLNm6FcDrlC6n8tpAG4ceMmtZo9xdNtX+WvM65d8fLmzgm4Gsr4+GCMeeD5RURE5OG8PehL1m3bA8CWPYd4rf9ozlwIouEr71O3Q29adfmYm6G3otynY98RkTuofDzuB35d4XofY/A3P1OvY29qte3J5l0HHmieRH5+pEuVIsptxhhyZc0EQIB/Inxut0O+HI9w5fp1AIJCrpImZXLCwsI5cuIv3hv5LfU79mHZxu2Aa2HM6XMXadDpPXoPn4S1NtpzDxj/I3U79Gb+6s13nQXA//Z7L9du3KRgrqwP9DpFRETk/vWcsoENB88AsO3oebpOXsvZy9d5fMgCmg6ax3Mjl3DzVniU+3SesJqdxy8AMGj2VuZtPQbA8Hk7aDZ4Ho0+ncvvh8890DyZUweSOJFrrwZ/P9/IRrkVFsHcLcdoWiZXlOMnr9xPk4HzmLLG1UlHzl6mSLY0ABTPnpYNB1yvLTQ8nDTJEhOQyJdUSf05fCbqTnf5Mqck5Hoo1lqu3QwjZRJ/UicLINDfj/CICIKvhZImWWIAFu/4k21Hz9N88HzGLNr1QK9TRNybFsaIeLFnnn6KH350fSAz9YcfaP3M06ROnZqF8+ezasUKihUryq+/zvnPx9m1axe7du1m5fLlzJoxgz7vvR/tmLr16kdexuj//1l2e/eWmGj5eCuKlShJg/r1AWjevBm7d+5g4fz5TPp2Mvv37+fSpSBS3v4gyc/Pj9B/veH0f9u3bydXzpykSOF6UyYi4u9t+VKlSsXFixcBmD37V0qWKs3yFSvInz9/jGcVERGRuPVUy6b8NONXAH78ZTbPPN6U1KlSMu+nySz/9SeKFirAnIVL//Nxdu3dz659B1g2+yd++fZLPvhkSLRjGjzxfOQljP7/n+Wr10U5JnPGDOzbtJIVc6YBMGmq69KPP04Yw/Jff+KDd7vy2ju9AWjWsC7b1yxm3k+T+fbH6ZELZqpWLE/RirWoUKcpb7/eKdocq+b9zNJZP/Lsky3o3ndAlK+NHP8NjzdpgI+PfnwTERFxyhP1qjB9oeuXj35auJon61cldYpAZo/8gEVffkyRvDmYt2rzfz7O7kPH2PPHcRaO/5gfh/ak3xdToh3T5LW+1O/YJ8p/VmzeEeNZrbX0+nwib73QHID8ObOyftteyjz5BtMXraF5zQqcCwpm58Gj9H31WaZ+9i69hk8kIiKCMxeCSJsyOfPHfcTlK9dYuPb3KI/98lMNWT9lKFMH9+DDMVMJCrl6z1me6fYp5Z5+kzoVS8V4fhEREXk4LcrlYuZm1yUVf9l0mJblcpMqqT8/vlWX2d0bUihLahbtiH7poX/be/ISe09eYla3hkx+rRafzNwS7Zgnhi2k+eD5Uf6zeu+pOz7esXMhLN99kgaPZgfguzUHeLJCXv75a0ANHs3O6n4t+PGtuvy4/hCH/gqmwCOpWXfgLyIiLCv3nCLomuuXpZL4+3HsXAhBV2+y/fgFgq6FRnm+mkWy0HPKBir0+YUMKZOQNW0ykvr78UiaQCq+9wttxyyL3Jnm1KWrFM6aml/ers/qfafZd/LSf35/RMSz6FJKIl6sYsWKdHn7bW7dusWatWsZPGgQZ8+e5eVXXuXipYucPXuOjBkzRrnPP38T+f+/FbRnz142btpE9Zo1AdfOLv+2aOHDXXPxl5+nc/HiRcqWf4znn3+OVKlSAZA0aVIaNWzIjh07SZ06FXv37QVclyTw9090x8f68aefeOrJJyP//M8PkYKDg0mTxrWyuGnTJjRt2oSBgwbxxZgx9Ond+6Feg4iIiMSOiuVK8857H3Lr1i3WbtzMwL69OHvuPK91683FS8GcO3+eDOmj7kJ3p4bZu/8gm3/fRq1mTwFw7fqNaM81f9q3/zlPQEAAAQEBADzRvDHf/vAzAGnTpAagdIlihFxxfSj0/8sqJU2ahIZ1arJz9z6MMSxctpL9m1dyKSiYpq3bsn5R1Gt4//+xmtSvQ//PRkTePm/RMlat28BP34z9zzlFREQk7jxWoiA9hk7gVlgY67ftZcCbL3L2YjBvfjKWS5evcO5iMBnSRN0VLkqf4OqTfUdO8NuuA9Tv2Adw7abyb7+O7vtQs74/6lvKFM1HtTLFABg2eQbPNanJS83rMGnWEj7/diZvPteMXFkykjOL632hLBnScj7oMqmSB1K9XHEAapYvwZ4//qR+5TKRj5329s4waVOloHzxAvxx/BSli+S76yxTB7/LxeAQqr7QjdYNq+Pnp8tCioiIxLVyeTPy/k+buBUWwaZDZ+jbqiznQq7T7bv1BF29yfmQG6RPkTjKff65Se3/N4w7cCqILUfO0XzwfACuh4ZFe65pXerFaKagqzd59etVjGxTBX8/X27cCmPR9uNMeaMOP647FHlcyqSu91+SBvhRu1g29py4SNMyuahW6BFaDllA6dzpyXr70kufPPMYXb9dS2BAIopmS0PGlEmiPGf379fz41t1yZ0xBZ2/Wc2GA39x/VY4l6/fYkP/xzly9jI9pmxgWpd6pEzqT5VCj+DjY6hUIBP7TwVRMEvqGL02EfEMWhgj4uVq1qhBvw8/pFLFivj4+PD9lCnUrVuHV195hV69e0fbEjd16lScOHGCkiVLsnXrNh4t+SgFCxagcqVKTPxmAgChoaHRnqduvfqE3op6+/t9+lDz9mKae7l58yYBAQEEBgaSPHlyfH19CQ4OJmXKlERERLB69Rpq16pF9uzZ+WTgQKy1LFq0iMfKl7/j482ZO4/evXpF/jlH9uzs2bOH3Llzs2fvHvLmzRv5nACpUqbi6rV7/4aTiIiIxK8alSvy0eDhVCxXBh8fH6b+PIva1avyStvn6dN/UPSGSZWSk6f/omSxImzbuYeSxYpQIF8eKpYvw4RRrp1i7tQwDZ54Ptrtfd55kxpVKkb++XJICCmSJwdg9bqN5MmdI8rtx/48EfkhT/Dly6RMkYKIiAjWbNhMzaqVCQ+PIGWK5Pj5+ZEieTKu34i6QOf/l4UKCAhg89btZMns+oDqt207GDxyLHN+mKjdYkRERNxAtbLFGDD+Rx4rURAfHx9+XLCKWo+VpOMTDfhg9Hf8+6pDqZIHcurseUoUyMX2fUcoUSA3+XNmoULJQozv+wYAobei74bb5LW+3LoV9YOndzs8SfWyxf9zxi+nLyDo8lU+6vxC5G3h4RGRC1rSpUrBviMnSJI4gPSpU3IxOITAJIk5dfYiaVMmp9Kjhdmx/whli+Zn2/7DlCyQO8rjB1+5SspkgYTeusXWvX/Qq+NTd53lZugtAvwTEZgkMckCk+Drq54RERGJL5ULZuazX7dSNk9GfHwMP288TPXCj9C2RiE+/uV3/n2xxJRJAzh96RrFsqdl158XKJY9DXkzp6R83oyMbFsFgNCw8GjP88SwhdwKi4hy29uNS1Cl0CORf755K5z241bQu0Vp8mZyLSQ+fv4KF0Ju8vTwxfwVdJWwcEupXOkpkDkVKZL6ExFh2XjwDNUKZQbglbpFeaVuUeZtPRa5AKZY9rT83LU+l6+F0vmb1WRPlzzKHNZCqsAAjDGkDkzM5eu38PUxpLl9W6rAAK7ccLXYY/kysev4RWoWzcLO4xepVCDzg3/zRcQtaWGMiJdr/cwzPFq6DBvWrQWgVs2aPP/iSyxYsJDkyZOTIUOGKMe/9OKLPP/iS0z4ZmLkwpHixYtTuHAhqtWogY+PDxUee4wBH38c5X4x3TGmdt267Nmzl33799H2pTZ07NiBps2aczP0JqGhofTu2RNjDEOGDmXR4sUANGrYkFKlXFvuPtGqFZWrViUwaSDfTp4EwKcDB9Lq8cfJmzcvv/32GwXy5ycwMDDyOQd83J8OnTpx69YtenTrjp+fH9On/8yYcWPx8fEhdarUTJr4zQN8d0VERCSuPP14M8rWbMSaBTMAqFGlIi+91pVFy1aSLFkg6dOljXL8C0+34qXXujBxyk8E+PsDULxIIQoXyEfNpk/i4+PDY2VK0b9P9yj3i8mOMavXb6LfwGEEJk1K5ozp+WrEZ0RERFC7+TMkTZKEiIgIhvR3XWpy2BdfsXjFKgAa1qlJqRJFAciVIztVGz5O6K1bvP1aRwAmTZ1Gnlw5yZ0zO81atyVZYCB+fr6M/szVWW/0eI9r12/QtHUbAKZNHEea1Kke5NspIiIiseDJ+lWp+GxXVnwzEIDqZYvT/v3PWbxuK8kCk5A+ddQdY55rUpP27w9n8uylBPi73oYtli8nBXNlo17H3vgYH8oVL0C/156Lcr+Y7hjT6NUP2Hf4Tw4cPckLTWvxZP0qvD34S8oVzU/9jn3Imik9X334Ji8/2ZAOHwxn9JRfsVi+7PcmAB+98QJPvf0JobfC6PpiC3x9fXm+aS1e7jeSaQtX80jGtLz/8jP8df4S436axwevPkvPYRPZd+RPwsMjaNuiLhnSpLrjLG1b1uWJrgMIDb1FaFgY3du2irKDjoiIiMStluVyU+uj2czv2RiAKgUz8/qEVSzffZLAgESk+9eOMU9XystrX69iytoD+N/+5Z8iWdOQ/5FUNBs8Dx9jKJM7A71blo5yv5jsGDNl7UF2/3mBQbO3AvB81fw8Xj4Pi/o0AeCHtQcJvh5K2TwZ+HTWFlbudl2KqXbxrBTP4doxuPng+fj6GPJkSkn/p8oBMGL+DpbvPom/ny8fPum6befxC2w6dIZ2NQvTo9mjPDdyCYn8fMiYMgk1imTBxwembfiDpoPmcfNWOD2auT57er1+Md74ZjXD5m7n0VzpKJkz6k7FIuL5zL9/01JE4laa1Kl/GDxo0FPt2rV1ehRxiI9fImutTWStjb68WkRExGHGmCbVK1f4dvGMqSn/+2hJKOYsXEL7N7qtPn/hYlWnZxEREfk/Y0zndo/XGzSi58uJ//toSSh2HTpG3Q69jwddvpLD6VlERCRhM8ZkSx0YsHf/560D//toSeiGzNnG4NnbPg6PiOjj9Cwi3kj7V4rEs7Dw8KvXrl9zegxxyPXr1zHGREC0nQpFRETcxY2r19QqEtXVa9ew1l53eg4REZF/uXH12vWI/z5MEpJr129g4KbTc4iIiAA3bt4K93V6CPEMV27cCo+w9sZ/HykiD0ILY0TiWUhIyLpx48ZfCw4OdnoUccDIUaPDkwUG7rfW6o07ERFxV7t37dnvv2nLNqfnEDdx48YNxnw9+drVq9fWOD2LiIjIv2ybv+Z3/vjztNNziJuIiIhg9NQ5NyIi7EanZxEREQHOR1h75eeNf+gXZeWezgRdY/qGP24CW5yeRcRb6VJKIvHMGGOSJUs2PlmyZM+UK1s2wt/f3+MusGyxhIeHJzGYcF9f39B4eU5rTXh4WFJfX79rxhiPO3FF2AhOnTwVsXPXrmtXr14tb6097vRMIiIid2OMaZw0aZIfK5UrE5Y8eTKPX0wfHh6exBgT7uPjE0/dggkPD0/q6+t7zRjP3iUuPDzcbt2x21wKCloacuVqK2ttmNMziYiI/JN/okQvJw5INLRCiUK3kiYJ8OxusRAeEZHEGOK3WyLCk/r6eH63RERYu//ICXPy7IW9V65dr2Gtver0TCIiIsaYIkn8fdeUzJHOpEuRxGt2j7HWEmFtEoMJ9/Ex8fc5UYRN6utjPPJzoru5cSvMbv7jrO+N0PBB10PD+jk9j4i30sIYEQcYYwxQHsgNeGIIPQY0Bd4DwuPxeRsAJYBP4/E5Y9MFYL219pLTg4iIiPwXY0weoCSQ1OFRHpa65eFEAMeBddba+Pz+iYiIxJgxpghQBAhwepaHpG55eKeAtVaXIRARETdijMkIlANSOTxKbFK3xJ5bwH5r7VanBxHxZloYIyL3xRiTFtgFNLPWborn5/YD1gNjrLUT4vO5RURExPOoW0RERMRTqFtERETEU6hbRMQTaWGMiNwXY8wk4KK1totDz18CWAyUsNbqIuIiIiJyV+oWERER8RTqFhEREfEU6hYR8URaGCMiMWaMqQuMB4paa684OMcAIJ+19gmnZhARERH3pm4RERERT6FuEREREU+hbhERT+Xj9AAi4hmMMYHAOKCTk7Fz20dACWNMc4fnEBERETekbhERERFPoW4RERERT6FuERFPph1jRCRGjDFDgPTW2hecngXAGFMN+B4oYq0NdnoeERERcR/qFhEREfEU6hYRERHxFOoWEfFkWhgjIv/JGFMW+BXX1njnnZ7n/4wx4wBrrX3Z6VlERETEPahbRERExFOoW0RERMRTqFtExNNpYYyI3JMxJhHwO/CptXaK0/P8kzEmFbAbeMZau8rhcURERMRh6hYRERHxFOoWERER8RTqFhHxBj5ODyAibq8bcAKY6vQg/2atDQJeB740xiR2eBwRERFxnrpFREREPIW6RURERDyFukVEPJ52jBGRuzLGFADWAKWttcednudujDHTgX3W2j5OzyIiIiLOULeIiIiIp1C3iIiIiKdQt4iIt9DCGBG5I2OMD7ACmGatHenwOPdkjMkMbAdqW2t3OD2PiIiIxC91i4iIiHgKdYuIiIh4CnWLiHgTXUpJRO6mA5AI+MLpQf6LtfY00Av42hjj6/Q8IiIiEu/ULSIiIuIp1C0iIiLiKdQtIuI1tGOMiERjjMkCbAOqW2t3OzxOjBhjDLAMmG2tHeb0PCIiIhI/1C0iIiLiKdQtIiIi4inULSLibbQwRkSiuB0OM4Bt1tq+Do9zX4wx+YD1QFlr7RGn5xEREZG4pW4RERERT6FuEREREU+hbhERb6RLKYnIvz0O5Ac+cXqQ+2WtPQgMBsbdDjcRERHxbuoWERER8RTqFhEREfEU6hYR8TpaGCMikYwxqYERQHtr7U2n53lAQ4H0wPNODyIiIiJxR90iIiIinkLdIiIiIp5C3SIi3kqXUhKRSMaYr4Ab1trXnZ7lYRhjSgPzgGLW2rNOzyMiIiKxT90iIiIinkLdIiIiIp5C3SIi3koLY0QEAGNMTWAiUNRae9nhcR6aMWYwkMVa29rpWURERCR2qVtERETEU6hbRERExFOoW0TEm2lhjIhgjEkC7ATestbOcXqe2GCMSYrrNb1hrZ3r9DwiIiISO9QtIiIi4inULSIiIuIp1C0i4u20MEZEMMYMBLJba59xepbYZIypBUzAtbo5xOl5RERE5OGpW0RERMRTqFtERETEU6hbRMTbaWGMSAJnjCkFzMdLr7NojJkAXLXWdnZ6FhEREXk46hYRERHxFOoWERER8RTqFhFJCLQwRiQBM8b4AZuA4dbaSU7PExeMMWmAXUAra+06p+cRERGRB6NuEREREU+hbhERERFPoW4RkYTCx+kBRMRRXYDzwGSnB4kr1tqLwJvAV8aYAKfnERERkQembhERERFPoW4RERERT6FuEZEEQTvGiCRQxpi8wAagrLX2iNPzxCVjjAFmAluttX2dnUZERETul7pFREREPIW6RURERDyFukVEEhItjBFJgG4HwFJgjrV2qNPzxAdjTFZgG1DNWrvb4XFEREQkhtQt6hYRERFPoW5Rt4iIiHgKdYu6RSSh0aWURBKmNkByYITTg8QXa+0J4D1cW+X5Oj2PiIiIxJi6RURERDyFukVEREQ8hbpFRBIU7RgjksAYYzIBO4A61trtTs8Tn4wxPsBK4Edr7Sin5xEREZF7U7eoW0RERDyFukXdIiIi4inULeoWkYRIC2NEEhhjzDTggLW2t9OzOMEYUxBYA5Sy1h53eh4RERG5O3WLukVERMRTqFvULSIiIp5C3aJuEUmIdCklkQTEGNMcKA585PAojrHW7gM+B8bcvoamiIiIuCF1i7pFRETEU6hb1C0iIiKeQt2ibhFJqLQwRiSBMMakBEYBHay1N5yex2GDgOzA004PIiIiItGpW6JQt4iIiLgxdUsU6hYRERE3pm6JQt0iksDoUkoiCYQxZgyuv/MvOz2LOzDGlANmA0WtteednkdERET+pm6JSt0iIiLivtQtUalbRERE3Je6JSp1i0jCooUxIgmAMaYqMAUoYq0Ndnoed2GMGQaktda+4PQsIiIi4qJuuTN1i4iIiPtRt9yZukVERMT9qFvuTN0iknBoYYyIlzPGJAa2Az2stTMdHsetGGOSAbuATtbahU7PIyIiktCpW+5O3SIiIuJe1C13p24RERFxL+qWu1O3iCQcPk4PICJxrg+wU7ETnbX2CvAyMPZ2/IiIiIiz1C13oW4RERFxO+qWu1C3iIiIuB11y12oW0QSDu0YI+LFjDHFgSVACWvtaafncVfGmG+Bc9bark7PIiIiklCpW2JG3SIiIuI8dUvMqFtEREScp26JGXWLiPfTwhgRL2WM8QXWA+OstV87PY87M8akw7VVXlNr7San5xEREUlo1C0xp24RERFxlrol5tQtIiIizlK3xJy6RcT76VJKIt7rDeAKMMHpQdydtfY80BX4yhjj7/Q8IiIiCZC6JYbULSIiIo5Tt8SQukVERMRx6pYYUreIeD/tGCPihYwxuYDNQAVr7UGn5/EExhgDzAXWWms/dnoeERGRhELdcv/ULSIiIs5Qt9w/dYuIiIgz1C33T90i4t20MEbEy9z+h3sBsMxaO9DpeTyJMSYH8DtQ2Vq7z+l5REREvJ265cGpW0REROKXuuXBqVtERETil7rlwalbRLyXLqUk4n2eA9IDQ5wexNNYa48B/YDxxhidH0VEROKeuuUBqVtERETinbrlAalbRERE4p265QGpW0S8l/5Ci3gRY0wG4DOgvbU2zOl5PNQXQCKgo9ODiIiIeDN1S6xQt4iIiMQDdUusULeIiIjEA3VLrFC3iHghXUpJxIsYY6YAJ6y13Z2exZMZY4oAK4CS1tqTDo8jIiLildQtsUPdIiIiEvfULbFD3SIiIhL31C2xQ90i4n20MEbESxhjGgHDgeLW2mtOz+PpjDH9gJJAc6sTpYiISKxSt8QudYuIiEjcUbfELnWLiIhI3FG3xC51i4h30aWURLyAMSY5rq3dOip2Ys0AIB/wuNODiIiIeBN1S5xQt4iIiMQBdUucULeIiIjEAXVLnFC3iHgR7Rgj4gWMMSOBpNbadk7P4k2MMRWB6UBRa+1Fp+cRERHxBuqWuKFuERERiX3qlrihbhEREYl96pa4oW4R8R5aGCPi4fSPctwyxowCkigmRUREHp66JW6pW0RERGKPuiVuqVtERERij7olbqlbRLyDFsaIeDBjTACwFfjAWjvN6Xm8kTEmBbALaGOtXer0PCIiIp5K3RL31C0iIiKxQ90S99QtIiIisUPdEvfULSLewcfpAUTkobwLHMC1EljigLX2MvAqMM4Yk9TpeURERDyYuiWOqVtERERijboljqlbREREYo26JY6pW0S8g3aMEfFQxpgiwAqgpLX2pMPjeD1jzFTgT2ttd6dnERER8TTqlvilbhEREXlw6pb4pW4RERF5cOqW+KVuEfFsWhgj4oGMMb7AGmCStXas0/MkBMaYDMBOoIG1dovT84iIiHgKdUv8U7eIiIg8GHVL/FO3iIiIPBh1S/xTt4h4Nl1KScQzvQKEAeOdHiShsNaeBboDXxtjEjk9j4iIiAdRt8QzdYuIiMgDU7fEM3WLiIjIA1O3xDN1i4hn044xIh7GGJMd+B2oYq3d5/Q8CYkxxgALgSXW2kFOzyMiIuLu1C3OUbeIiIjcH3WLc9QtIiIi90fd4hx1i4jn0sIYEQ9y+x/cOcA6a+3HTs+TEBljcgGbgcestYecnkdERMRdqVucp24RERGJGXWL89QtIiIiMaNucZ66RcQz6VJKIp7laSAbMNjpQRIqa+0RYAAw/naAioiIyJ2pWxymbhEREYkxdYvD1C0iIiIxpm5xmLpFxDNpYYyIhzDGpAOGAe2ttaFOz5PAjQCSA22dHkRERMQdqVvcirpFRETkHtQtbkXdIiIicg/qFreibhHxMLqUkoiHMMZMAi5aa7s4PYuAMaYEsBgoYa097fQ8IiIi7kTd4l7ULSIiInenbnEv6hYREZG7U7e4F3WLiGfRwhgRD2CMqQuMA4paa686PY+4GGM+BvJba59wehYRERF3oW5xT+oWERGR6NQt7kndIiIiEp26xT2pW0Q8hy6lJOLmjDHJcMXOy4odt/MRUNwY09zpQURERNyBusWtqVtERET+Qd3i1tQtIiIi/6BucWvqFhEPoR1jRNycMWYokM5a+4LTs0h0xphqwPe4VmkHOTyOiIiIo9Qt7k3dIiIi8jd1i3tTt4iIiPxN3eLe1C0inkELY0TcmDGmHDAb1z+m552eR+7MGDMOsNbal52eRURExCnqFs+gbhEREVG3eAp1i4iIiLrFU6hbRNyfFsaIuCljTCLgd+ATa+1Up+eRuzPGpAR2A62ttaucnkdERCS+qVs8h7pFREQSOnWL51C3iIhIQqdu8RzqFhH35+P0ACJyV92BP4EfnB5E7s1aGwy8DnxpjEns9DwiIiIOULd4CHWLiIiIusVTqFtERETULZ5C3SLi/rRjjIgbMsYUBNYApay1x52eR2LGGDMd2G+t7e30LCIiIvFF3eKZ1C0iIpIQqVs8k7pFREQSInWLZ1K3iLgvLYwRcTPGGB9gBTDNWjvS4XHkPhhjMgPbgTrW2u1OzyMiIhLX1C2eS90iIiIJjbrFc6lbREQkoVG3eC51i4j70qWURNxPB8AP+MLpQeT+WGtPAz2Br4wxvk7PIyIiEg/ULR5K3SIiIgmQusVDqVtERCQBUrd4KHWLiPvSjjEibsQYkwXYBlS31u52eBx5AMYYAywF5lhrhzo9j4iISFxRt3g+dYuIiCQU6hbPp24REZGEQt3i+dQtIu5JC2NE3MTtfyhnAluttX2dnUYehjEmH7AeKGetPez0PCIiIrFN3eI91C0iIuLt1C3eQ90iIiLeTt3iPdQtIu5Hl1IScR+PA/mAT5weRB6OtfYgMBgYeztkRUREvI26xUuoW0REJAFQt3gJdYuIiCQA6hYvoW4RcT9aGCPiBowxqYERQHtr7U2n55FYMRRIDzzv9CAiIiKxSd3ildQtIiLildQtXkndIiIiXknd4pXULSJuRJdSEnEDxpivgWvW2s5OzyKxxxhTCpgPFLPWnnV6HhERkdigbvFO6hYREfFG6hbvpG4RERFvpG7xTuoWEfehhTEiDjPG1AK+AYpYa0OcnkdilzFmEJDNWvuM07OIiIg8LHWLd1O3iIiIN1G3eDd1i4iIeBN1i3dTt4i4By2MEXGQMSYpsAN4y1o7x+l5JPbd/t94J/Cm/jcWERFPpm7xfuoWERHxFuoW76duERERb6Fu8X7qFhH3oIUxIg4yxgwEsmuVqHfTam8REfEGjnnxqAABAABJREFU6paEQd0iIiLeQN2SMKhbRETEG6hbEgZ1i4jztDBGxCG6rmDCcvv6oNetta87PYuIiMj9UrckLOoWERHxZOqWhEXdIiIinkzdkrCoW0ScpYUxIg4wxvgBm4Dh1tpJTs8jcc8YkwbYBbSy1q5zeh4REZGYUrckPOoWERHxVOqWhEfdIiIinkrdkvCoW0Sc5eP0ACIJVFfgPDDZ6UEkflhrLwJvAl8ZYwKcnkdEROQ+qFsSGHWLiIh4MHVLAqNuERERD6ZuSWDULSLO0o4xIvHMGJMX2ACUtdYecXoeiT/GGAPMBLZaa/s6O42IiMh/U7ckXOoWERHxNOqWhEvdIiIinkbdknCpW0Sco4UxIvHo9j94S4FfrbXDnJ5H4p8xJguwDahurd3t8DgiIiJ3pW4RdYuIiHgKdYuoW0RExFOoW0TdIuIMXUpJJH61BZIBI5weRJxhrT0JvIdrqzxfp+cRERG5B3VLAqduERERD6JuSeDULSIi4kHULQmcukXEGdoxRiSeGGMyA9uBOtba7U7PI84xxvgAK4GfrLUjnZ5HRETk39Qt8n/qFhERcXfqFvk/dYuIiLg7dYv8n7pFJP5pYYxIPDHGTAMOWGt7Oz2LOM8YUxBYA5Sy1h53eh4REZF/UrfIP6lbRETEnalb5J/ULSIi4s7ULfJP6haR+KVLKYnEA2NMc6A48JHDo4ibsNbuA4YBY25fU1RERMQtqFvk39QtIiLirtQt8m/qFhERcVfqFvk3dYtI/NLCGJE4ZoxJCYwCOlhrbzg9j7iVwUA24BmnBxEREQF1i9yTukVERNyKukXuQd0iIiJuRd0i96BuEYknupSSSBwzxowFsNa+7PQs4n6MMeWA2UBRa+15p+cREZGETd0i96JuERERd6JukXtRt4iIiDtRt8i9qFtE4ocWxojEIWNMVWAKUMRaG+z0POKejDHDgLTW2hecnkVERBIudYvEhLpFRETcgbpFYkLdIiIi7kDdIjGhbhGJe1oYIxJHjDGJge1AD2vtTIfHETdmjAkEdgEvW2sXOj2PiIgkPOoWiSl1i4iIOE3dIjGlbhEREaepWySm1C0icU8LY0TiiDHmYyC/tfYJp2cR92eMqQeMBYpZa684PY+IiCQs6ha5H+oWERFxkrpF7oe6RUREnKRukfuhbhGJW1oYIxIHjDElgMVAcWvtX07PI57BGDMZuGCt7eL0LCIiknCoW+RBqFtERMQJ6hZ5EOoWERFxgrpFHoS6RSTuaGGMSCwzxvgCG4Cx1tqvnZ5HPIcxJh2urfKaWWs3Oj2PiIh4P3WLPCh1i4iIxDd1izwodYuIiMQ3dYs8KHWLSNzxcXoAES/0BhACTHB6EPEs1trzQBfgS2OMv9PziIhIgqBukQeibhEREQeoW+SBqFtERMQB6hZ5IOoWkbijHWNEYpExJhewGXjMWnvI6XnE8xhjDDAHWGet/djpeURExHupW+RhqVtERCS+qFvkYalbREQkvqhb5GGpW0TihhbGiMSS2/9QLQSWWGsHOT2PeC5jTHZgC1DZWrvP6XlERMT7qFsktqhbREQkrqlbJLaoW0REJK6pWyS2qFtEYp8upSQSe54H0gFDnR5EPJu19jjQD9dWeTpPi4hIXFC3SKxQt4iISDxQt0isULeIiEg8ULdIrFC3iMQ+/UUSiQXGmAzAYKC9tTbM6XnEK3wB+AIdnR5ERES8i7pF4oC6RURE4oS6ReKAukVEROKEukXigLpFJBbpUkoiscAYMxU4bq3t4fQs4j2MMUWAFUBJa+1Jh8cREREvoW6RuKBuERGRuKBukbigbhERkbigbpG4oG4RiT1aGCPykIwxjYHPgeLW2msOjyNexhjTF3gUaG51whYRkYekbpG4pG4REZHYpG6RuKRuERGR2KRukbikbhGJHbqUkshDMMYkx7WVWUfFjsSRT4B8QCunBxEREc+mbpF4oG4REZFYoW6ReKBuERGRWKFukXigbhGJBdoxRuQhGGNGAkmtte2cnkW8lzGmIjAdKGqtvej0PCIi4pnULRIf1C0iIhIb1C0SH9QtIiISG9QtEh/ULSIPTwtjRB7QP/4RKmKtveT0POLdFNciIvIw1C0Sn9QtIiLyMNQtEp/ULSIi8jDULRKf1C0iD0cLY0QegDEmANgKvG+tne70POL9bm/HuBtoY61d6vQ8IiLiOdQtEt/ULSIi8qDULRLf1C0iIvKg1C0S39QtIg/Hx+kBRDxUT+AA8LPTg0jCYK0NAV4Fxhljkjo9j4iIeBR1i8QrdYuIiDwEdYvEK3WLiIg8BHWLxCt1i8jD0Y4xIvfJGFMEWAGUtNaedHgcSWCMMVOBP6213Z2eRURE3J+6RZykbhERkfuhbhEnqVtEROR+qFvESeoWkQejhTEi98EY4wusASZZa8c6PY8kPMaYDMBOoIG1dovT84iIiPtSt4jT1C0iIhJT6hZxmrpFRERiSt0iTlO3iDwYXUpJ5P68CtwCxjs9iCRM1tqzQDfga2NMIqfnERERt6ZuEUepW0RE5D6oW8RR6hYREbkP6hZxlLpF5MFoxxiRGDLGZAe2AJWstfudnkcSLmOMARYCS621A52eR0RE3I+6RdyFukVERP6LukXchbpFRET+i7pF3IW6ReT+aWGMSAzc/gdmDrDOWvux0/OIGGNyAZuBCtbag07PIyIi7kPdIu5G3SIiInejbhF3o24REZG7UbeIu1G3iNwfXUpJJGaeBrIBg50eRATAWnsE+BgYfzvIRURE/k/dIm5F3SIiIvegbhG3om4REZF7ULeIW1G3iNwfLYwR+Q/GmHTAMKC9tTbU6XlE/mEEEAi0dXoQERFxD+oWcWPqFhERiULdIm5M3SIiIlGoW8SNqVtEYkiXUhL5D8aYycB5a21Xp2cR+TdjTAlgMVDCWnva6XlERMRZ6hZxZ+oWERH5J3WLuDN1i4iI/JO6RdyZukUkZrQwRuQejDH1gLFAUWvtVafnEbkTY8zHQAFrbSunZxEREeeoW8QTqFtERATULeIZ1C0iIgLqFvEM6haR/6ZLKYnchTEmGa7Y6aTYETf3EVDMGNPC6UFERMQZ6hbxIOoWEZEETt0iHkTdIiKSwKlbxIOoW0T+g3aMEbkLY8wwII219kWnZxH5L8aYqsAUXKvWgxweR0RE4pm6RTyJukVEJGFTt4gnUbeIiCRs6hbxJOoWkXvTwhiROzDGlAdmAUWstRecnkckJowxYwGstS87PYuIiMQfdYt4InWLiEjCpG4RT6RuERFJmNQt4onULSJ3p4UxIv9ijPEHfgM+sdZOdXoekZgyxqQEdgPPWmtXOj2PiIjEPXWLeCp1i4hIwqNuEU+lbhERSXjULeKp1C0id+fj9AAibqgb8Cfwg9ODiNwPa20w8BrwpTEmsdPziIhIvFC3iEdSt4iIJEjqFvFI6hYRkQRJ3SIeSd0icnfaMUbkH4wxBYHVQGlr7XGn5xF5EMaYacABa21vp2cREZG4o24Rb6BuERFJGNQt4g3ULSIiCYO6RbyBukUkOi2MEbnNGOMDrAR+tNaOcnoekQdljMkE7ADqWGu3Oz2PiIjEPnWLeAt1i4iI91O3iLdQt4iIeD91i3gLdYtIdLqUksjfOgK+wBinBxF5GNbav4CewFfGGD+n5xERkTihbhGvoG4REUkQ1C3iFdQtIiIJgrpFvIK6RSQ67RgjAhhjsgDbgOrW2t0OjyPy0IwxBlgCzLXWDnV6HhERiT3qFvE26hYREe+lbhFvo24REfFe6hbxNuoWkai0MEYSvNv/MMwEtlpr+zo7jUjsMcbkBTYA5ay1h52eR0REHp66RbyVukVExPuoW8RbqVtERLyPukW8lbpF5G+6lJIItALyAp84PYhIbLLWHgIGAWNvh72IiHg+dYt4JXWLiIhXUreIV1K3iIh4JXWLeCV1i8jftDBGEjRjTBpgONDeWnvT6XlE4sBQIB3wgtODiIjIw1G3SAKgbhER8RLqFkkA1C0iIl5C3SIJgLpFBF1KSRI4Y8zXwDVrbWenZxGJK8aYUsB8oLi19ozT84iIyINRt0hCoG4REfEO6hZJCNQtIiLeQd0iCYG6RUQLYyQBM8bUAiYARa21IU7PIxKXjDEDgezW2mecnkVERO6fukUSEnWLiIhnU7dIQqJuERHxbOoWSUjULZLQ6VJKkiAZY5IC44FXFTuSQPQDyhpjGjs9iIiI3B91iyRA6hYREQ+lbpEESN0iIuKh1C2SAKlbJEHTjjGSIBljBgFZrbWtnZ5FJL4YY2oCE3Gtfr/s8DgiIhJD6hZJiNQtIiKeSd0iCZG6RUTEM6lbJCFSt0hCpoUxkuD84zp6xay1Z52eRyQ+GWO+Am5Ya193ehYREflv6hZJyNQtIiKeRd0iCZm6RUTEs6hbJCFTt0hCpYUxkqAYYxIBm4Bh1trJTs8jEt+MMamB3cAT1tq1Ts8jIiJ3p26RhE7dIiLiOdQtktCpW0REPIe6RRI6dYskVD5ODyASz7oCZ4FvnR5ExAnW2kvAG8CXxpgAp+cREZF7UrdIgqZuERHxKOoWSdDULSIiHkXdIgmaukUSKu0YIwmGMSYfsB4oa6094vQ8Ik4xxhhgBrDNWtvX4XFEROQO1C0iLuoWERH3p24RcVG3iIi4P3WLiIu6RRIiLYyRBOH2CX4ZMNtaO8zpeUScZozJAmwDqltrdzs8joiI/IO6RSQqdYuIiPtSt4hEpW4REXFf6haRqNQtktDoUkqSULQDAoERTg8i4g6stSeBPsDXxhhfp+cREZEo1C0i/6BuERFxa+oWkX9Qt4iIuDV1i8g/qFskodGOMeL1jDGZge1AbWvtDqfnEXEXxhgfYAUwzVo70uFxREQEdYvI3ahbRETcj7pF5M7ULSIi7kfdInJn6hZJSLQwRryeMWY6sM9a28fpWUTcjTGmALAWKGWtPe70PCIiCZ26ReTu1C0iIu5F3SJyd+oWERH3om4RuTt1iyQUupSSeDVjTAugGNDf6VlE3JG1dj8wDBh7+xqrIiLiEHWLyL2pW0RE3Ie6ReTe1C0iIu5D3SJyb+oWSSi0MEa8ljEmFTAS6GCtveHwOCLubBCQFXjG6UFERBIqdYtIjKlbREQcpm4RiTF1i4iIw9QtIjGmbhGvp0spidcyxowDrLX2ZadnEXF3xphywGygqLX2vNPziIgkNOoWkZhTt4iIOEvdIhJz6hYREWepW0RiTt0i3k4LY8QrGWOqAd8DRay1wU7PI+IJjDFDgXTW2hecnkVEJCFRt4jcP3WLiIgz1C0i90/dIiLiDHWLyP1Tt4g308IY8TrGmMTADqCbtXaW0/OIeApjTCCwC3jFWrvA6XlERBICdYvIg1G3iIjEP3WLyINRt4iIxD91i8iDUbeIN9PCGPE6xpiPgfzW2iecnkXE0xhj6gLjcW2Vd8XpeUREvJ26ReTBqVtEROKXukXkwalbRETil7pF5MGpW8RbaWGMeBVjTAlgMVDcWvuX0/OIeCJjzCTgorW2i9OziIh4M3WLyMNTt4iIxA91i8jDU7eIiMQPdYvIw1O3iDfSwhjxGsYYP2A9MNZa+7XT84h4KmNMWmA30Mxau9HpeUREvJG6RSR2qFtEROKeukUkdqhbRETinrpFJHaoW8Qb+Tg9gEgsegO4DExwehART2atvQB0Ab40xvg7PY+IiJdSt4jEAnWLiEi8ULeIxAJ1i4hIvFC3iMQCdYt4I+0YI17BGJMb2AQ8Zq095PQ8Ip7OGGOAX4EN1tr+Ts8jIuJN1C0isUvdIiISd9QtIrFL3SIiEnfULSKxS90i3kYLY8Tj3T4xLwIWW2sHOT2PiLcwxmQHfgeqWGv3OT2PiIg3ULeIxA11i4hI7FO3iMQNdYuISOxTt4jEDXWLeBNdSkm8wQtAWmCo04OIeBNr7XGgH66t8vTvhYhI7FC3iMQBdYuISJxQt4jEAXWLiEicULeIxAF1i3gT/R9YPJoxJiMwCGhvrQ1zeh4RLzQG8AU6Oj2IiIinU7eIxDl1i4hILFG3iMQ5dYuISCxRt4jEOXWLeAVdSkk8mjFmKnDcWtvD6VlEvJUxpjCwEnjUWnvC6XlERDyVukUk7qlbRERih7pFJO6pW0REYoe6RSTuqVvEG2hhjHgsY0xj4HOguLX2msPjiHg1Y8wHQGmgmdU/HCIi903dIhJ/1C0iIg9H3SISf9QtIiIPR90iEn/ULeLpdCkl8UjGmBTAF0BHxY5IvPgUyAO0cnoQERFPo24RiXfqFhGRB6RuEYl36hYRkQekbhGJd+oW8WjaMUY8kjFmFJDYWtve6VlEEgpjTAXgZ6Cotfai0/OIiHgKdYtI/FO3iIg8GHWLSPxTt4iIPBh1i0j8U7eIJ9PCGPE4xphKwDSgiLX2ktPziCQkxpgRQDJrbVunZxER8QTqFhHnqFtERO6PukXEOeoWEZH7o24RcY66RTyVLqUkHsUYEwB8Cbyh2BFxRG+gljGmttODiIi4O3WLiOPULSIiMaRuEXGcukVEJIbULSKOU7eIR9LCGPE0vYADuLbpEpF4Zq0NAV4Fxhljkjo9j4iIm1O3iDhI3SIicl/ULSIOUreIiNwXdYuIg9Qt4ql0KSXxGMaYosByoKS19qTT84gkZMaYKcAJa213p2cREXFH6hYR96FuERG5N3WLiPtQt4iI3Ju6RcR9qFvE02hhjHgEY4wvsBb4xlo7zul5RBI6Y0x6YCfQ0Fq7xel5RETcibpFxL2oW0RE7k7dIuJe1C0iInenbhFxL+oW8TS6lJJ4iteAUFzXjRQRh1lrzwHdgK+NMYmcnkdExM2oW0TciLpFROSe1C0ibkTdIiJyT+oWETeibhFPox1jxO0ZY3IAvwOVrLX7nZ5HRFyMMQZYACyz1g50eh4REXegbhFxT+oWEZHo1C0i7kndIiISnbpFxD2pW8STaGGMuLXbJ9S5wFpr7cdOzyMiURljcgK/ARWstQcdHkdExFHqFhH3pm4REfmbukXEvalbRET+pm4RcW/qFvEUupSSuLtngKzAIKcHEZHorLVHgf7A+Ns/oIiIJGTqFhE3pm4REYlC3SLixtQtIiJRqFtE3Ji6RTyFFsaI2zLGpAOGAu2ttbecnkdE7mokEAi0c3oQERGnqFtEPIa6RUQSPHWLiMdQt4hIgqduEfEY6hZxe7qUkrgtY8y3wDlrbVenZxGRezPGFAeWACWstaednkdEJL6pW0Q8h7pFRBI6dYuI51C3iEhCp24R8RzqFnF3WhgjbskYUx8YAxS11l51eh4R+W/GmP5AQWttK6dnERGJT+oWEc+jbhGRhErdIuJ51C0iklCpW0Q8j7pF3JkupSRuxxiTDBgLdFLsiHiU/kBRY0wLpwcREYkv6hYRj6VuEZEER90i4rHULSKS4KhbRDyWukXclhbGiNswxtQyxvjiOmmutNYucnomEYk5a+0NoAMw0hiTyhhTyRgT6PRcIiJxQd0i4tnULSKSkKhbRDybukVEEhJ1i4hnU7eIO9OllMRtGGNOA+2Br4Ei1toLDo8kIg/AGDMG18LLLMB4a+1sh0cSEYl16hYR76BuEZGEQN0i4h3ULSKSEKhbRLyDukXckXaMEbdgjEkEpAU+xbUSuL0xxjg7lYjcL2NMPWAl0AiwuKJHRMSrqFtEvIO6RUQSAnWLiHdQt4hIQqBuEfEO6hZxV1oYI+4iMxAKJAL64trNSNsZiXieC8D7wBmgGpDd2XFEROKEukXEO6hbRCQhULeIeAd1i4gkBOoWEe+gbhG3pIUx4i6KAYHAUaCstfZTZ8cRkQdhrf0NKAlMAZIAtR0dSEQkbqhbRLyAukVEEgh1i4gXULeISAKhbhHxAuoWcVdGiy3FHRhjUgCNrLVTnZ5FRGKHMSY/kN1au8TpWUREYpO6RcT7qFtExFupW0S8j7pFRLyVukXE+6hbxJ1oYYyIiIiIiIiIiIiIiIiIiIiIeCU/pwfwRsYYA7Q0xhT38/MLcHoeiV3WWsLCwk4A06y1Z5yeR7yfMaYUUCdRokSpnZ5F4kd4eHhoRETEfuAHa2240/OIdzLGVDOGyn5+fsmdnkXiR3h4RFhERMQRYIq19rrT84j3MMakB5709fXN4mOMLtebgIWFhQVbWGWtXev0LOL5jDE5geZ+vr6ZjHF6GnFSWHjENWvtJmvtAqdnEc8X2S0+Pll8fNQtCVlYWLi6RWKNMeYRoJWfj88jqFsStLDwiBBgvbV2mdOziOf7+9xiHnF6FnFWWITVuSUWaGFMLDPGmMDAwBGZMmZs8/TTTydJmjSpfsDyMhEREezYsePG/AULehhjyltrTzk9k3gvY0zdwMDAGe3avOifIX06nbMTiBs3btpZv865dvTosabGmNZaHCOxLVGiRG1Sp0o5qt2LzwakTJHS1+l5JH6EhYXZpStWXd++c3dbY0xtLY6R2GCMyRSYNOmGutUqZixRpGBiHx/9+JOQXQq+HPb1lOmhPj4+bSMiIn50eh7xXMaYAkkTB6x7vH61wNzZHgkwWhmToF25ej3825kLbyYO8P/wxs3QgU7PI57LGJMpMEnAhlpli2Ysni97Yh+dWxK0oJBrYRPnrFS3yEMzxuRIGpBoY8Oy+VLlz5JW3ZLAhVy7Gf7tsu03/f18u4aGhY9zeh7xXMaYHEn9fTfWL5opVf6MyXRuSeAuX78VPmXj8Zv+fj5dQ8MidG55QLqUUiwzxtTMmjXr7B3btwemTq3NHbxZz549w8aOG7fw0qVLjZ2eRbyTMcbH39//ypL5c5JUqljB6XEknl27do3HqlS/unvP3g66rq7EJmNM+oCAgD+3rF0aUCBfXqfHkXgWHh5O0yefu7lk+coPw8LCBzg9j3i+VClTTG/zdMtmA997Rwt4BYBdew9QodHToaG3bqW31l52eh7xTKlSJNva9402JTo93VTv/goAJ/46R+nmHa6HXL1W2lq71+l5xDOlTJZ0+ouNqzb7+NWn1C0CwO4/TlC1Y7/QW2Hh6hZ5YKmSJV72WuNyVd9uWVG/eCQAHP7rElW6Tbh5IzQsj7X2pNPziGdKldR/2SvVc1d9q05+nVsEgCPnrlLjsxU3b9yK0LnlAenX+WJfgVq1avloUYz3e/zxx/2AQk7PIV4tY4C/P1oUkzAlTZqUpo0bJQXyOz2LeJ28uXJkv6FFMQmTr68vLZs2DkieLFkJp2cR7+DjY4o2b1BbHy5JpKKF8pMpQ7obQC6nZxHPFXorLE+TmpW0KEYiZc2UnkcL5w1FPx/JQ/D18SnatGppdYtEKpInK5nSplK3yEOJiLAFG5XTB9fyt9yZUpMnc+obgN58kwcWYW3BBsUy69wikXKlDyR3+mQ6tzwELYyJfX6JEyd2yzdvVqxYwVtvveX0GAD07t2bylWq0OqJJ7h27VqUr61cuZLHKlSgarVqPNO6Nbdu3QJg8eLFlCtfngoVK9K/f38AQkJCaN6iBTVq1uSVV14hIiIi3l5DQEAA6HJkErf8EiVKFH//p34IK1atpss7PRx57vDwcDq++jpVa9ah46uvEx4e9apDK1atJnueAtSs24CadRtw5coVzp07R616DalWqy616zfi2LHjAPzw03QKFX+UUuUrOvFSokmcOLHx8fFJ5PQc4nX8AgL8nZ4hRlasXkvXd99z5Ln3HThI6cq1CMyQg6Cg4GhfDw8Pp1Pnt6larymdOr8dee4ZMeZLKtdpTJ0mrTh85BgAPT/oT6XajahYqyHf/zg9Xl/HnQQE+OPj4+MZ/ycQ92fxC/D3rH+qVq7fzNt9nbkSx75DhylbrxUp8pYmKDj6LyVv3rqTas2fo3arl2jR5nWuXHX9rDTy6++o1vw56j3dnsPH/gRg3OQfqdnyRao0fZbenwyL19fxX/z9/S36WUkego2wvp52blm1eTvdBo5x5Ln3Hz5O+VYvk7p0I4IuX7njMTMXr6ZBu27Ub9uNpet+j7w95Oo1slVpxeylawEY/+Ov1H6xK9WefYP3hn0dL/PHVIC/v0HnFnkIFuvnn8iz/i+0eus+eoyc4shzHzh2mkrtPiB9nY4EhVyL9vWwsHBe6jeW+p0/pX7nTzly6iwRERE0f2cIdV8fQN3XB7D9gOtnotPnL9Gs62c0eONTBnwzM55fyb35J/JTt8hDseAb4OdZn12v2X2cXhOXOPLcB05eoFr3b3jkuc8Ivnoj2tfDwiNo//ksGn/wPY0/+J6jZ4IAaP7RDzTtN4XGH3xPnrbDATh9MYSW/X+gSd8pDJy2Jj5fxn8K8PMDnVvkIViLb4CfZ32Mv/bQed6bscuR5z54JoRan60kR/e5BF+/Fe3rV26E8dKETbQcvY7u03cQEeG6os70305Qb9gq6g9bzZSNrs+J1h46T9WByyn83oJ4fQ0xcfv/Ezq3PCDP+hsl8ea/LrF148aNB16EsnPnTvbt38+a1aupVrUqX38d9Y2WvHnzsmL5clatXEnOHDn4+eefAfjk00/55eefWb9uHXPmziU4OJjx48fToH59li9bRurUqVmwwP1OUiISVWyfX+YtWEiK5MlZtWwxKZInZ96ChdGOebxFc5Ytms+yRfNJliwZSZIkYcrkiaxcuohub3fh08+GAFC7ZnW2/7bx/l6QiLiF2D63ZMvyCMvmzqB82VJ3/Pq8RUtJniIZqxbOJnmKZMxbtJQzZ88x49e5rF70K6OHDaR3v48BaPfCs6xdMpcV82cycOiIaAv4RMR9/fe55eb9nVseycSSad9Q/tHid/x6yaIFWTnzO5ZMn0ipYoX5Ze4izpw7z6z5S1gx41tGDujDe5+63gRu83RLlv0yidWzv2fTlh0c/VO76Ip4iv88t9wMva9zS9ZM6Vn0zRDKFb/zprZ/nb/IzwtXMffLgSyYMJhaFUtHfm3E5J8pVeTvTVhealmfJZOGsvL7EWzasZdjJ/+K8Rwi4qz/Prfcuq9zS5YMaZg3vAdlC+e549c37j5EsiQBLBj5Ll2fbcj4X5ZhjGFY1+dZNKoXo7u3oe+Xrvd1h3w3j85P12f+iHc59OcZ9h1Vt4h4iv88t4SGRX7AHBNZ0ibn176tKZPvkTt+fdP+kwQm9mdOv2d5q/ljfLXQtaB35ntPM/uD1vR4ojKNyuUD4POZG3i9cTl+7duaP05fZN+J8zGeQ0Sc9Z/nllvh93VueSRVEma8VpFSOe58RZdvNxyjZsEM/PJaRVIlScSyfWcBGLPiD2a+Volf36jE+JWHASiaJSULulQhc8okMX5+8QxaUeQFrLW89dZb/L5lC/7+/kz85hv8/Px48aWXCA0NJXfu3Hz91VdR7jNt2jQ+GzIEYwzdu3WjZcuWvNSmDUkSJ+bwkSN89eWXZMuWLdpzbd68mQkTJrBn714WzJ9PkiT3f1JYs2YNDRs0AKBx48b07NWLzp07R349S5Yskf89ICAAHx/X+q1CBQsSHBxMhgwZ8PX1xd/fn0OHDvHSSy8BUKpUKVatWkXDhg3veyYRuTNrLV3e6cGWrVvx9/dnwvix+Pn58VKHTtwKDSVXrpx8NfaLKPeZ9vMMhn4+AmPgna5v0bJ5M9p06ESSJEk4fOQoX34ximzZskZ7rs2//c43k79l7959zJs9I8bnl7Xr1tOgfj0AGjVswKLFS2jSKOp5YNavc9iydSv169WhZ/duJEuWjGTJkgFRzzPp0qW77++RiNw/ay1d332P37ftwD9RIiaMGY6fnx9tXn6D0Fuh5M6Zgy9HRd39YPqM2QwZOQZjDN3efI0WTRvR9pU3XO1y9DjjRw4hW9Ys0Z5r8+9bmfjdVPbsP8C8n6fG+NwSGBh4z6+vXb+RBnVqA9CoXh0WLV1BhvTpKFwgP8YY8ufNw5ZtOwDIm8e1K3eiRInw8fHBGLfcXFDE41lrebvvQLbu3IN/okR8ObQ/fr6+tOvam1uht8iVPSvjPvswyn1+nrOQYeMmYYzh7Vfa0LxBbdp36U3ixIk5cvwEYwf3I9sjmaI912/bdjHxxxnsO/gHv347liRJEsdoxsCkSe/59USJ/t4h4/qNGxTIm4tjJ05RMF8e17kld0627NwDgP/t3TTCwsJIkTwZ6dLocr4iccFaS7eBY9i65yD+ifwY378bvr6+dOw9iNBbYeTMmpmxH3aNcp9fFq7i80nTMMbQpc2TNK9dmY69B5M4cQBHT5zmi35dyJopQ7Tn+m3XfibPWMi+P44xa+wAkiQOiNGMgUnv3TeLVm8mSYA/TTv1JHXKFAx/rzNpUqbgYvBlDh45QdniBSOP9U/0/3NLOCmSBZI2dcoYzSAi98daS4+RU9l24Cj+fn6M6dkOP18fXh7wNaFhYeTMnJ7RPdpEuc+M5ZsZ8eMCjDG89UwDmlYtzcuffE0S/0QcOX2OUd3bkDVDmmjP9fveI3w3bzX7jp3il8FdSRLDHUQDk9z7HJQ9UzpuhbkW/QdfuUaalIEYY8j1iOv85p8oET63f/Y5fPIMxfO63msumT8Ha7cfoGDO6D+/icjDsdbSa9JSth/+i0R+vox+tRG+PobXvpjLrbAIcmRIyYiX//W+6fp9jJqzCQN0blqeJuUL8NoXc0ns78exM0EM79SALOlSRHuuLYdO8/2KHRw4cYGfej1Bkhju9heY+N7noOwZUnIr3LWIL/jaTVIni9o5M9fvo0UF12LgI2cuUTRnRgCK58rI+r1/UjCr3t8ViW3WWt6buZsdJ4JI5OvD8GdK4ufjwxtTtxIaFkGOtIEMeyrqVdtnbzvFmBV/YIDXaualUfHMvDF1K4kT+XL8wjWGPFmCLKmj/xyz9XgQUzcd58BfIUzt+BhJ/GO2I1dgwL2XPBw5f5Wny7papFjWlGw4fJHahTOSO30gV0PDCPDzIVli12OkTOJZu5dKzGlhjBeYM2cOoaGhrFm9GoCIiAjeeust3nzjDRo3bky3bt2YNWsWqVO73igNDw/nw48+YtNG164IFSpWpHnz5gAUK1aMMWOibv0bEhLCV199xZy5cylWtCgdO3bk0UcfBeDixYu0fPzxaDN9MXo0hQsXvuO8ly5dIn9+128jpUqViosXL97xuCNHjrBw0SJ69eoFQMuWLalXvz5+fn60b9eOJEmSULRoUZYuXUr58uVZvHjx/XzbRCQG5sybT+itUFYtc/39ioiIoMs7PXjjtVdo3LAB3Xv2Ztavc6KcX/p/8ikbVq8AoFL1WjRv2gSAYkWK8MWIz6M8fkhICF9/M4m58xdQtEgROrRtw6MlXQF18eJFWj39bLSZRg0fRuFCf79xeykoiJQpXD+cpUqZkouXLkU5vkypR9m3cys+Pj48+2JblixbTu2aNQC4efMmH/YfwBcjo84lInFrzoLFhIaGsmrhbMB1bun67nt0fqU9jevXpXuffsyeu4BUqVwfxISHh9N/0FDWL5sPQOU6jWnW2LXItmjhQoweNijK44eEXOHryd8zd8FiihUpRPuXnufREsUAuHjxEq2ebxttplFDPqVwwQIxfg1BQcGkTJEccJ17Ll0KIm/unPy+bQc3btxg645dnDh1Osp9Ro79ipbNGkcuxhOR2DV3yUpCQ2+x/JfJgOvc8nbfgbze9jka1a7Gu/2H8OvC5aRK5eqG8PBwPv58LGt/nQpA1ebP0bReTQCKFszHqE+iXsot5MpVJkz9mXlLV1G0YD7aP9uKkkVdb8hevBTMUx3fijbTiI/7UCj/nX/L+m5+XbScD4eMxj9RIt55pR0Wy9ade7hx4ybbdu/l5F9nIo/9+PMxTPpxJrWqVPjPD8ZF5MHMW7mB0FthLJ3sWrQbERFBt4FjePW5FjSs9hi9hozn1+XrSH27C8LDw/lk7HesmjoSgOrPvUnTmq5LtRbJl5MR770R5fFDrl5j4s/zmb9qI0Xy5aJtq4aULOS6ZPzF4Ms881bUBX0An/fpTKE8OWL8Gs5cuMiZC5eYPe4Tpi9YyWdf/cCAtzsybMI0Or/4OPNXbohy/IAx3zF55kJqVihFYAwX/onI/Vmwbju3boWxaJTrfc+IiAh6jJzKy61q06BiSfqM+Ym5a7aSKrlrwX54eAQDJ81m+ThXn9R+9WMaV3a9P1s4d1aGvf1ClMcPuXadSXNWs3D9dgrnzsJLTapRIr/rvHHx8hWee290tJmGdnnuvharZEyTkpCr1yn7Qm9u3LzFsrF9Ir9mraXPmB958+n6kTOu+H0vrWqVY+WWvVQsnv9uDysiD2Hhlj8IDQtn3ofPARAR4Voo06lBGeqVzssH3y1n3m8HSRXo+vc9PCKCwT+vZfEA1zmkfp/vaFTW9fezcLb0DGlfL8rjh1y/yXfLdrBwyx8UzpaOF2uVpHgu18KUS1eu8+KQGdFmGtSu7n0tVsmQKpCQ6zep0PUrboSGsejj5yO/FhYewbq9fzKwbR0ACmVLz6pdx2hZsRCrdx3nsYLRfxlTRB7e4j1nCA2PYHbnyoDr3PLezN20r5KbukUy0m/2Hhbs+ouUSV0LSsIjLEMXHWD+W1UAaDxiDQ2Kun7pqFDmFAxqFXUX3Ss3wvh+4zEW7zlLoUzJef6xHBTL6npf+NLVUNpO/C3aTJ8+XowCmZLH+DUUzJSc1QfPUypHalbtPxd5e/2imagzZBUR1tKn8Z134BTvoYUxXmDv3r1Uq1Yt8s8+Pj4cPHSI3r17A1C+fHkOHDhA+fLlATh//jxZs2aN/I3prFmzcu6c6yTw2GOPRXv8U6dO8fWECdSvV4/27dtTsODfH0inSZOGFcuX/+eMPXv2ZP2GDbR+5hlSp05NcHAwAMHBwaRJE/03GS5dusRzzz/PxG++wd/ftYL4jTffZOuWLaROnZqGjRpx7Ngx2rVrR+fOnalVuzaFChbUbg8isWzfvv1UrVw58s8+Pj4c/OMPevXoBkC5smU5ePAQ5cqVBeD8+QtkyZIl8vySJcsjnDvn2sKy/O1j/unU6dNMmDSZenVq067NixQs8PeH0mnSpGHZovn/OWPqVKkIvnwZgODLl0mTOupvS/9/ZxhwXVJp27bt1K5ZA2st7Tq9yssdO0R5XhGJe/v2H6BqpYqRf3adWw7T8523AChfphQHDv1BuTKuyxidv3CRLI9k/vvc8khmzp2/4Dq2bGn+7dRff/HNt1OoW6sG7V58loL580V+LU2a1CybG/2NmvuVKlVKgi+HAK5zT+rUqUibJg1vvNKBBi2fplD+/JQr82jk8XMXLmblmnVM+/bruz2kiDykfYcOU/WxMpF/9vHx4dCRY7zbuQMA5R4txsEjRyl7+zJG5y9eIkvmjJG7vWTJnJFzF1yL9suXin6po1NnzjLxhxnUrV6JNs+0pGDe3JFfS5M6JYunfRMrr6NJ3Ro0qVuDz774mnGTf6Dnm514vd2zNH6uEwXy5aZcyWKRx/Z+6xV6vN6BJzq8xbrNW6lU7s6XfxORB7f/8J9UKfP33zsfHx8OHTtJ9w6tAShbrCCHjp6M3HXl/KXLPJIxXeRuL1kypufcRdd7IHe61NHpsxeYNGMBdSqV5aWW9SmQO3vk19KkTMHCbz576NeQMnkyqpYtgY+PDzUrlGLKr0v46/xFjp36i9JF8kdbGNPrlefo3uEZnnqrL+u37qZiqaIPPYOIRLX/2Gkqlfz7vQgfHx/+OHGGbs83BqBModwcOnGGMoVcvXEhOIRH0qeO3O3lkfSpOR/k+nmkbJHoi3D/Oh/Et/NWU7tcUV5sVJX8OTJHfi1NimTMG97joV/D9/PXUDBXFqZ83JmVW/bSd/x0Rvdw/RJC3/HTKVMoN1VLuc57XZ9tSNeh3/L9/DVkyZCGTGm1G5VIXDhw4gKVCv19JQAfH8Phvy7StUUFAErnzcwfpy9SOq/rMkYXLl/nkbTJI3d7eSRtcs5fvgZwx0sd/XXpCt8t20Gtkrl4rmYJ8mdJG/m11MmSMPuD1g/9Gqau2EnBrOn49p2WrNp1jI+mrozc5Wb1rmNULJQNP1/XLxy91fwx3vlqEVNW7CBL2hRkTJ3sXg8tIg/owJkrVMzz9993Hx/D4fNXeKuO6z3XUjlS8ce5q5TKkQqAi1dDyZwqceRuL5lTJebC1VAASt8+5p/+unyDKRv/pEbB9DxbPjv5Mv694CV1oD8zXqsY7T73q3X57PT+ZRetxqwnX4ZkpAn058qNMEYtO8Tanq5fpG45ej2Nimcmqb+WT3gr/S/rBQoWLMiCBQt4+umnAddvGOTNk4dNmzbRpEkTNm7cSMWKf5800qVLx59//sn169cB+PPPP0mfPj3AHX+DuUCBAuzauZM1a9YwePBgjh0/zuMtW9KxY0eCg4NjtGPMJ598Evnfd+zYwccDBtCuXTvmz59PpYpRT2g3b97kyaeeYsDHH1PgHx9W+/n5kSJFCvz8/EiWLBkhISHkyJGDL7/8EoAuXbpE7nwjIrGjQIH8LFy8hKefbAXcPr/kzs2m336jSaOGbNq8mQqPlY88Pl26tJw4cSLy/HLixEnSp3ctWLvj+SV/fnb8vok1a9fx2bDhHD/+Jy2aN6NjuzYEBwfHaMeYihUeY/GSpdSqUZ0FCxdRqWKFKMcHBweTMqXrDZdVa9ZQq0Z1AHr2eZ+iRQrxZKuWD/z9EZEHUzB/PhYuWcZTrZoD/z+35GLT71tp0qAuG3/bQsXyfy+mS5c2DSdOnvr73HLyFOnTuX4Yu+O5JV9etm9YyZr1Gxky/AuO/XmClk0b0aHN8wQHX46VHWMqPVaOxctWUKt6FRYsXkalCq5zYesnH6f1k4+zZdsOpkz7GYDftmxj8OejmTv9e+0WIxKHCuTJxaIVa3mymWtHqYiICPLkzM7mbbtoXKc6m7bupELpkpHHp0uTmhOnznD9+g0ATpz6i/RpXYv273huyZOLrUtnsHbTFoaNncixk6do0aAO7Z9tRfDlK7GyY8zNm6EE3P7AK2WK5Fy95jrvPdOiMc+0aMzWnXuYOmNulGP9/PxIljQpSbWrg0icyJ8rG4vXbuaJBq43SyMiIsiTPQu/7dpHo+oV2LxzH+VL/v3+R7rUKTh55hzXb9wE4ORf50ifxvXzyJ3OLflzZeO3GV+ybssuhk2cxp+nztKsTmXatWpI8JWrsbJjTOXSxRg4fgoA2/YeJFfWzOw5eJQ/T5+j6cu9OHz8FHNXbKBY/tw8kjEtAf7++Pn5kixpkhhfzklE7k/+HJlYvHEXrWq5fo6IiIggd5aM/L73CA0qleS3vYcp/48FL2lTJufkuUtcv+n6UOnk2YukS+X60MjnDpdqzZc9MxsnfsT6HQcY/sN8/jxzgaZVy9CmSTWCr16LlR1jwiMsaVMmuz1fMi5fdXXLVzOXExRyjX6dnog8Nk2KZEzs+woRERF0+Pgr6pQvdsfHFJGHky9LGpZuO0LLSq42iYiw5MqYmi1/nKZ+6bz8fug0ZfP//fc8bYoknDwfwvXQWwCcPH+ZdClcl3/18bnDueWRtKwd0o4N+04w6teN/HnuMk3KF+DF2iW4fO1mrOwYEx5hSZvc9YtRaZMn4fK1m5Ffm7F+L09ULhL559TJkvD1W82IiLC8MmoOtUvmjvZ4IvLw8mVIxrJ9Z2n+qOv8ERFhyZUukK3HL1G3SCa2HAuibM6/f2E5TaA/p4JucD3UdcnFU5dukDbQ9V7Hnbolb4ZkrOxenY2HL/DF8j84cek6jYpn5vkKObh8/Vas7BiTOJEvQ25f7un9mbtoUCwTxkAiXx+SJHIt4LFYwiNsjB9TPI8WxniBJk2asHDhQipVrkxAQAATv/mGd999lxdefJHBn31Grly5aNasGatWrQLA19eX9/r0oVr16hhjeK9Pnxh9SFO5cmUqV67MlStXmDZtGqGhoTHeMeafihcvTu5cuahStSrp06fn28murc7feust+vfvz7fffsu2bdv4oG9fADp26EDr1q3p0b07VatVw9fXlzKlS1O0aFG2bdvGW1264OvrS4vmzSlZsuR9zSIi99akUUMWLVlKlRq1CQgIYML4sfR4pysvte/IkGHDyZkzB82aNGbVmrWA6/zS+90e1KjTAGMMvd/tEbPzS6WKVK5U0XV++WVG5PklJjvGNGpQn9lz5lKtVl3y5ctLw/quLT47vPIaX44ZzQ/TfmbCN5Pw909E8eLFaN60CXv37WPYiFFUqvAYixYvpWyZ0gwc0J9FS5by2dDP+ePwEeo2bML4MaPImSPmbziLSMw0blCXRUuXU6VuEwL8/ZkwZjjdu3TmpU6dGTLiC3LlyEbTRvVZtXY9cPvc0q0LNRq2cJ1bunWJ2bmlQnkqVyjPlStXmT5z9u1zS8x2jDlz9hzPt3+VHTv30PLZl3jr1U40bVSfjq93ZfyooTSsV5vZcxdQrX4z8ufJTcO6tQBo3aYTZ8+dJ3OmjIweOhCAzu/05Pr16zR50rWV8fRvJ5AmTeq7PreIPJjGdaqzeOVaqrd4ngB/f74c2p9ur7ajbZfeDBv7DTmzZ6VJvRqs3vg74Dq39HqzE7WfaIMxhl5vdorRuaVSuVJUKleKK1ev8fOchYSG3orxjjFnzp3nxTfeZcfe/TzR/k06t3+epvVq8nK3Dxg7uB+zFixl/Lc/4uPjQ6qUKfh62McAPPdqN85duEimDOkYOcB1CYV+Q0axeetOboWFUaV8GR4tdudL2YrIw2lU/TGWrP2Nms+/RYB/Isb378bb7Z6iQ+9BfP7NNHJmzUSTGhVZ8/tOwHVuebfTs9Rt8w7GwLudWsfo3FKxVFEqlirKlWvX+WXhKkJvhcV4x5gz5y/R9t1P2bn/ME+92ZfXn29Jk5oVeeWDoYzp15XCeXOSN0dW6r70Nn5+vozv342smdJTs4Jrl6n+X0ymeIE85MqWmT5Dv2Lzzn3cCgujcpniPFo43388u4g8iAYVS7Jk0y7qvDaAgER+jOnZjq7PNqTTgK8Y/sMCcmROR6PKj7J2+wEAfH196P5CExq8MRBjoPsLTWN0bqlQPD8ViufnyrUbzFyxmdCwsBjvGHP2YjDt+49n16E/ad1nJK89UZdGlR/l9UHfMKp7G56q+xgv9R3L3DVbCb0VxmdvPceVazfoNuJ7yhbOTcM3B5I1QxrG9+7A4o07+XzKfIyBDi1qkiGNdowRiQv1S+dl2fYjNHjvO/wT+TL61Ua82fwxXh09l1GzN5I9QyoalsnHur1/AuDr48M7j1ekSd+pGAPvPF7xjgti/u2xgll5rGBWrtwIZdb6fYSGhcd4x5izQVfpNPJXdh07y/Of/cLLDcvSsGw+3hw7n+EvN+CJKoVp//ls5v12kNCwcAa2cV026VZYOJsPnOLzjg0iH2vptsOMmLURDLSrV4oMqQIf8DsnIvdSt0hGlu8/R5MRa/D382H4MyXpXDMvnadu44vlf5AtTVLqF83E+sOuHb59fQxd6uSjxeh1GANd6uaL0bmlfO60lM+dlqs3w5i9/RShYREx3jHmXMhNXv1uC3tOXealCZvpVC039YtmouuP2xn6VAl2nQzmvZm78fUxNCiaiaJZXC3SolQWGg1fgwUaF3+E5IkTsftkMH1n7+Hohas8MWY9PRsWpFQOvZfrDYy1WvkUm4wxnTt16jRo7Jgx+nU9L7dz506qVqt2/NKlS/rUXOKEMSZbmtSp9547dVxFn0D1/2Qg/foP+Dg8PLzPfx8tEjPGmColihX59fc1S/VOZAL13Q/T6PruezMvXLzUwulZxPOlSZXy0Lwp4/OUKl7kvw+WBKNI1cbBh44cq2Wt/d3pWcQzJQkIuHpw6ZSkaVOlcHoUcSPNXu51efHa39paa392ehbxTKlTBB6aNeSdPI8WyOn0KOJGHn22Z/AfJ86oW+SBJU8acGbFpy9lyJVJH5rK3+r0mhy85Y/Tj1trlzo9i3im5IkTnVnydtUMOdPp4yH5W4PPVwdvPR6kc8sD0l7uIiIiIiIiIiIiIiIiIiIiIuKVtDBGRERERERERERERERERERERLySFsaIiIiIiIiIiIiIiIiIiIiIiFfSwpgEoHqNGgQFBTk9xl2tXLmSipUqUblKFebMmRPla1OmTCF1mjSRf27StCnVqlen/GOPsXLlSgD69u1L0WLFqF6jBu3bt49y/3Xr1mF8fKK9/qNHj5IufXqq16hB9Ro1OHToEADdunXjkSxZeOutt6LNOWDAAEo++mgsvGIRz1WzbgO3Pp+82K4jVWrUplK1mixa4rrE4k/Tf6FClRpUrVmHt97uHnnsiFFfULl6Leo0aMzhI0cAOHv2HPWbNKdy9Vp8MXY8AOHh4bzYriM16zag9QttuH79OgAdX32dGnXqU75SNab9POOO84SHh1P00TIMHzkagJGjx1ChSg0qVavJ4CHDIo9LkS4TNes2oGbdBqxZuy72vzEibq5moxYEBQU7PcZ/qt/8Kbq++x4A036ZRYWaDaharyldevSJclxIyBUy5irMrDnzAfhx+kwKl65E6cq1ohzXpUcfKtdpTKXajdj8+1YADhz6g+oNmlOpdiNm/jov2gxtX3mD8tXqUrNRC9776FMAwsLCaN2mE9UbNKd6g+YcPnIs8vjw8HCKlavC8C/Gx943QsSN1XmiDUHBl50e466GfzmZ/BXq0ardG5G3hYeH80r3vtRo+QKvdO9LeHg45y5cpO6TbanZ8kXqPdWOYydOATBu8o/UbPkiVZo+S+9PXC1x8VIwlRo/Q5oC5di+e1/k4274fRvVmj9HtebPseH3bQCc+ussDVp3oHarl/ho6BfR5hs14XsqN2lN1WbP8tmYCQDcunWL6i2ep3arl6jR8gX27D9019ci4q3qtXmHoMtXnB7jrkZO/pmC9Z7nyTc+iLxt1ebt5K3Vmnpt3qFem3e4cs31c8zUX5dQ+enXqfJMZybNWADAr8vWUeuFLtR6oQsdeg8iPDwcgL1/HKPZy72o37Ybw775CYDVm3dQ47m3qPVCF+at3HDP5/q/sLBwXuj2MXVe7EqdF7ty5M/TADRs3516bd6hzotdyVLp8Sj3GfTlVMq3ejkOvlsi7qPhmwMJCrnm9Bh31fHjL6nz2gBqvfIxSzfvAiA8PILOgyZS9/UBdB40kfDwCADafTSeXE3fYPS0RdEe543BE3mm98got23cdYgU1dpGvv4mXQbT8M2B1O/8KdkbdwZg+NT5NHxzIA3fHEjuZm8yb+3WKI9xt6/vO3qSlt2G0ujNQQyf6vqZ7OVPvqZax340fHMgH371Syx+l0TcT9N+Uwi+esPpMe7qlVFzaPDed9Tr8y3Lt7vek525fi91ek+m4fvf0XPikshjy7wxjqb9ptC03xRmb3D9rHPy/GWa9J1Ck75TeHHIDELDXN2y78R5nvzkJ5r1m8rI2RsBWLvnOPXf+5aG73/Hwt8PRZlj+po95G77ebT5fly1K/I5i7/6BePm/8b5y9cib6vdazI1ekyMcp8u4xfw3GCdW8S7tRi9juDrt5we467emLqVukNX0WL0Oj6d5zpfHDwTQq3PVpKj+9wos0//7QT1hq2i/rDVTNl4HIC/gm/w5Nj1NB+1lsEL9kceu/+vEJ4Zv4GWo9cxepnrPPLqd1toMXodLUavI2f3uQRdC2XWtlM0+Hw1TUeuoc+MXdHmu3IjjJcmbKLl6HV0n76DiAgb5WuF31vA/J2un5M+mLU78vHz9pzPnlPu+z6Xp/FzegB5OBEREfj4xM36pn8/9n8914PO0uPdd5k7Zw7JkiWjZq1aNGjQAF9fX8LCwpg2fTrZsmWLPPbn6dPx9/fn6NGjvNSmDSuWLweg/0cf0bx582iP/fnw4ZQpU+aOz1u5cmVmzoj6YXbXrl1p2LAhs2bNinJ7UFAQu/fsue/XJuJJvOF88l6vHuTNk4dLly5Rt1FT6tauRbmypVmzYgm+vr60fqENGzZuIlfOnMyYNZvVy5dw8NAher3Xlx++m8SgIUN57eWONGpQn+q16/HUE4+zYtUasjySmUlfj2f81xOYOPk7XunUgVGfD8Xf35+QkBAq16jNE4+3iDbPd1N/IEeOHJF/btigHp1fewVrLdVq1eW51s+QOXMm8ubJzbJF8+/79Yp4Am84twCsXLMOPz/fyD+XLf0oaxbPwdfXl2fbvsyGzb/zWNnSAAwbPZYypUpEHlurRhVaNG1IhZoNIm87/ucJdu/dz5rFc9i7/wDvffgp07+fQJ9+Axj52SfkzZ2TGg2a07hBXfz8oib7uJFDKVm8aOSf123cTLLAQFbMn8n8xUsZ/eUEhgzoB8D3P04nR/ZsiHgDbzifPN28IY3r1KDHR4Mjb5u/bDXJkwWy/JfJdP9wMPOXraZ6xXJ8O3oQGdOnY9GKtQwa/RWjP3mfNk+3pNMLTwGuRUBH/zxJlkwZmDX5C9796LMoz9Xr42FM+2q463k7dmXZL5MYNPorunR8ibrVK/HC693Ze+APCuXPE3mfBjWr8nrbZ7HWUvPxF3m2ZRMyZ0zP4p8mkChRIlau38zQsd/w1bCP7/haRDyRN5xbnmxYk0Y1KvDu4HFRbm9RtwqDe7wS5bbPJ01nxXfD8fP1peKTr/Jii/rUq1KWJjUrAtCx92DWbtlF1bIl6DPsKyYN6kWqFMki79/n86/4ZXR/kiVNTIN23alXuexdn+v/NmzbTWDSJCyeNJSFqzcxduosBnZ/mXlfDQJg5aZtTJ2zNPL4oMtX2Hvo6H1/H0TciTecW3q82JQ8WTNyKeQqzbp+Rq2yRVm0YQfJAxOzaFQveo3+gUUbdtCgUkn6v/IEy8oUJuhK1IU+h0+e5eylyxhjotz+xbRFPFogZ+Sffx3WDYBVW/by4+L1ALz5TAPefMb1M1T5l96jRpkiUR7jbl9/f+x0Jrz/MqmSJ41y/MhubSieL/t9fx9E3ElEhMXHx/z3gbHw2P/1XA86S7dWlcidKTVBV27Qsv8P1CiRi1J5HmHBR8/h6+NDh+Gz2XzgJGXzZyEwsT+zP2gd5f5TVuzk+VoleLJKEfp+v4Kl2w7ToEw+Pvx+BV++0ZSUgYkjj+33/Qp+ePcJAhMnovmHP1D70dz4+vgQFh7BrA37yJI2RbT5nqpalKequt5zadpvCo3K5iddiqSRc3y/fAenL4ZEHn/kr0ucDb6KIW7+dxGJD95wbgEY+lQJimZJGfnnR1IlYcZrFXlxwuYox41Z8Qdz3qiMn6+hzpBVtC6fnRFLD/JK9TzUKJiBV77dwv6/QiiQKTn95+xl7POlSZkkUeT9v3iuFADHLlzjnZ+2kyqpP49mT8WcNyrj62N4+dvf+f3oJUrnTB15n283HKNmwQy8UDEnA+buZdm+s9QunBGAsSv/oES2VJHH9mvmapqrN8NoPGINhR+Jfq6SB6OFMXFs165dtO/QgSRJkpA/Xz7GjRvH8uXL6fr22+TMmZOLFy8y/PPPCQoKYubMmXz++eccPXqUt7p0YeaMGQwePJj5CxYQFBRE3w8+oGnTpvTt25cjR49y4cIF+vTuzfLly1mwcCFhYWEMHTKE8uXLM2XKFIYMHUrevHm5dOnSXef75JNPot23eIkS1KxRgxMnT1K0SJEozzVjxgzWrluHr68v48aOpWDBglGOnz5t2n1/j0JDQ0mbNi0AqVOn5uDBgxQsWJCJEyfS+pln+HjAgMhj/f39Abh8+TJFi/z9w1C/Dz9k6LBhdO/WjcaNGwOwZMkSypYpw9mzZ+/4vBs2bKBK1aqUK1uWgQMH4ufnR+bMmdm/f3+0Yz/77DPefOMNOnbqdN+vTyS27Nq9h46vvEaSJEnIly8vY0eNYPnKVbzToyc5smfn0qVLDPtsEEHBwcyaPYdhnw3k6LFjdHmnBzOm/cBnQz9nwaLFBAUH837vnjRt3Ih+/Qe4/o5fvEjvHt1ZsWoVCxctISwsjM8GfkL5cmWZ8sNPDBsxkjy5c3PpHrvFfDr4s2j3LVn2MWpUq3b7fFI4ynPNnP0r69ZvwNfXlzGjhlOwQIEox0+b+t19f4/y5nF9sJM48d8/AOX8x8KUgAB/fHx8OHrsGIUKFcQYQ/58+diydRsA6zds5JP+H+Lj40PNGtXZ/PsW/vjjD0oULw5AqZIlGfL5CF7p1CHyfHTt2nUKFigQbZZbt27xy8xZtGrZnMu3f3M9T+7cABhjSJQoUeQbU0ePHad67XrkyZObzz8bRPLkye/7tYs8qF179tKx89skSZKY/HnyMGb4YJavWkO3Xn3JkSMbFy9dYtin/QkKDmb23AUM/fQjjh47Ttee7/PLlIl8Nnw0CxYvIzj4Mu/3fIcmDevR75PBHD12nAsXL9GrWxdWrFrLwqXLCAsL57MB/ShfphRTp/3CsJFjyZM75z13i/l0yIho9320Yg1qVK3MiZOnKFK4YJTnmvnrPNZt3Iyvrw9jPh9Mwfz5ohz/07dfP9D3aeSYr3ilQxuWLl8FQM4cf7+h6jq3uH5gu3jxEgcO/kG5MqUiv57uduf8U9o0qQkMTEp4eDhBwZdJm8b1g9Kx439SrEghAAoVzM+hw0comD9f5P2MMbzapTuBSZPy0fs9eaxsaXJmz8atMNdvPQQHXyZtatdj3bp1i19mz6VV8yYEXw5BJK7t3neQl7v3JUniAPLmzsEXn37AinWb6P7hYHJkfYRLQcEM6fcuQZdDmL1wGUP69uDonyd5p+9Apn89giFjv2HR8jUEXQ6hT5dXaFK3Bh8N/YKjf57kwqUger7RkZXrNrNoxRrCwsMZ9H43yj1anB9mzOXzLyeRJ0d2Lt1jt5hBo76Kdt/SdVpSvVJ5Tp4+Q5ECeaM816wFS1n/2zZ8fXwY9en7FMybO8rxP4wbet/fo4zp03H9xskot63bvIX6NasA0LB2NRavXEvjOtVJFuj6MCcgwB8f42oGf3/XGzFhYWGkSJ6MdGlSkyhRItKlSR3lMa9fd/2GaIZ0rvOPj4/hxo2b/HH0OCWKuLqlZNHCrN74e5SFMXlyuhbSGWNI5OcXeW5LlMj1vJdDrlC4QL67vhaRuLD74BFe7TuMJAEB5M2RhVEfvMXKTdvoMXgcOR7JyKXgEAa/+yrBIVf4ddk6Bvd4hWMn/6LbwDH8NKIfw775iUVrNhMUcpXerzxP4xoV6P/FZI6d/IsLQSG827E1KzdvY/Ga3wgLD+fTbp0oV7wQP85dxvBJ08mTPcs9d4sZ/NXUaPct17IT1cqX5OSZcxTOmzPKc81eupb123bj6+PDyPffpEDu7FGOnzL0/fv+HmVMl5pjJ29Gu/3XZevYuucgdSuXpXuHZwDIlyMrV65dJ8A/UeR5xv/233FrLRZLziyZOHriNKGht+jYZzBXr91gwDsdKVEwD6G3wkibyvXGbKoUyTl07ORdn+v/cmTJRFhYGADBIVdJkyrqG7vTF6ykVf1qkX/+fOI0Xn2uBa/3+/y+vxciMbXn8AleHzyRJP7+5M2WkeHvvMiqLXvpNfpHsmdKy6WQqwzs3JrgK9eYs2YLAzu35tjp87w7aipTP+7M8KnzWbxxJ8FXrtGzTTMaVnqUAd/M5Njp81y8fIVuzzdh9dZ9LNm0k7DwCAa89hRlC+fhp8UbGPXTQnJnyUBQyNW7zjfku7nR7luhzftULVWQU+cuUShXlijPNWf1FjbsOoivjw/D336R/DkyRzn+2w9fu+/vUZ6srg9rEvv//UHQ+p0HqfuY6z2S+hVKsHTzLhpUKknmdKnv+BhDvpvDm0/XZ8SPCyNvW/7bbkoVzMW5oOg/o/yyfDMta5aLctum3X9QJHdWkgT43/E5/vn1o6fPcfNWGK98+jVXr9+g/ytPUTxfdgzw1tDJBCYO4L32LSlXJM8dH0vkYe09fo43x80niX8i8mROzdCO9Vm96xjvfbuMbOlTEnTlBgNeqkXw1ZvM23yAAS/V5vjZYHpNWsp33VoycvZGlmw7zOWrN+n+RCUalMnHwGlrOHY2mEtXrtO1RQXW7D7Osu1HCAuP4KMXalIm3yNMX7OHL+ZsItftBSd3M2zG+mj3rdJtAlWKZOfUxRAKZUsf5bnmbj7Ipv0n8PXxYUiHeuTPkjbK8RO7Rv9Fwf+SO5PrfBHg//cvH2XP8PcH2f6JfCN/DrkeGkbTflNImzwpn7atTcZUycifJS3nLrsW4V2+eoM0yZJw7GwQN8PCee2LeVy9EcqHz9egWM6M3AqLIE3yJACkSpaYP05fIn+WtExdsZNWlQozdMb6u855+mIIYeERZE0XtVtmrt/HJy/V/vt7OnM9nZuUZ9Svm+77eyESU3tPX+btH7eTOJEvedIHMvjJEqw5eJ6+s3eTLXVSLl0LpX+LogRfv8WCnX/xUYuiHL94jfdn7mJi23KMXnaIZfvOcvn6Ld6pV4B6RTMxeMF+jl+8xqVroXSpnZ+1h86zbN9ZwiMs/ZoVoVSO1Pzy+wnGrjxMznSBBF+7+24xI5YcjHbfGoNXUDlvOk4F36BgpuRRnmveztNsPnoRH2MY/ERx8mVMHuX4r1+684YH92IwdJ+2g6QBfvRsUJDSOVMTGHDnZRC50wdyNTSMAD8fkiV2HXPk/NXIRTXFsqZkw+ELJE7kS2hYOG9O3crVm+F80LRwlIU3s7edpGnJRwDInubvBbn+fj78a00wR85f5emy2f7x+BepXTgjl66G8sfZq5TKHr2lFu85Q53bi2ckdmhhTBxbuHAhHTt0oG3btkREuLaW7NmrF4sXLSJlypQUL1Hinvd/7bXX6NatG0FBQdStV4+mTZsCkDFDBiZNnMiuXbvYtXs3K1es4Pz58zzTujUL5s9n4KBBbNywgdDQUHLmynXHx77TfRcvWkRISAgdO3akcOHC9O3bN/K5tmzZwh+HD7Nm9Wp27dpFj3ffZdbMmVGO/6cpU6Yw/ssvo9yWPXt2Jk+aFOW2pEmTcuTIEVKlSsXvv//OpUuXuHnzJjNnzeLX2bOjLIwJDQ2ldp067N+/n0kTJwLQuXNn+vbty4ULF6hdpw6VK1cmVapUjBg5kh+mTmXuvOiXIcicOTOHDh4kWbJkvP3220ycODHaZZj+79y5c/xx+DDlypW749dF4suixUto364NbV98IfJ80vu9D1g4ZxYpU6akZNnH7nn/V1/uyDtd3yIoKIj6jZvTtHEjwHU+mfjVeHbt3sOu3XtZvngB58+fp/WLbZk/ewaDhw5j/arlhIaGkrtg0Ts+9p3uu2jubEJCrtChXRsKFypIv/4DIp9ry9Zt/HH4CKuWLWbX7j282+d9Zk77Mcrx/zTlh5/4asI3UW7Lli0bk76+86VBer/fj9dfjbrt9ubffuf0X2coV7YMFy5cYMuWbdy4cYOt27Zz4qTrzdyboaGRH/ykSpmSixcvUaRIYWbPmctTTzzOkmXLoiwOevyp1qxdv55P+n8YbYavvpnE861bc+Vq9DfRZ87+lRw5spMxYwYADu7eTtq0aRk5egyDhgzjo773/2a4yINatHQFHV56jjbPt/773NJvAAtm/UjKFCl4tGLNe97/1Q5teOfN1wgKCqZ+i6do0rAeABnSp+ebsSPZtWcvu/fuY/m8mZy/cIFn277CvF+mMvjzUaxbOo/Q0FvkKVb2jo99p/sunPUTISFXaP/ScxQuWIB+nwyOfK4t23Zw+MhRVi2cza49e+n5QX9mTJ0U5fh/mjrtF76c+G2U27JnzcLEcaOi3DZ/8VIqlC9DYNKov3EIsPn3rZz+6yzlSrsWwgwePpq3XuvE3IWL7/l9S5o0KdmyPEKRMpW5eu0aC2e5Lk/wz200U6VMycVLQVHuN6j/B6RNk4Zjx/+kxTMv8vuapWTKmIHLIVcoVq4K16/fYN0yV/t8Pel7nn/6Ca5cvfsb7iKxadHKdbRr3YqXnm4ReT5579PhzJsynpTJk1G67uP3vP8rLz7N2y+7LoXU6NlONKlbA3At7vh62Mfs3neQ3fsPsmT6RM5fvMTzr3dnzrdj+WzMBNbMnkLorVvkr1Dvjo99p/vOn/IlIVev0b51Kwrlz8NHQ7+IfK6tO/dw+NgJlv8ymd37DtJ7wDB+njAyyvH/9MOMuXw9ZXqU27JlycyEzwfwXy4FXybl7UWxqVIk5+I/FgvevBlK/6FfMPKT9yJv+/jzMUz6cSa1qlQgMGmSuz5min/s8JDy9uMWKZCP5Ws28mSzBqxYt5HK5Urf8f6zFiwlR9ZHyJg+HQDHT57mhde78+fJ05G70IjElyXrfqdtq4a82KJ+5Lnl/eETmDP+U1ImC6Tc4/f+BZZOTzelS5snCbp8hSadetK4RgUAMqRNzZcfd2f3wSPsOXiURROHcP5SMC91H8CssQMYOuEnVk4ZQeitWxSq98IdH/tO953z5UBCrl2jbauGFMqTg/5fTI58rq17DnL4xCmWTh7G7oNH6DPsa6aN7Bfl+H/6ce4yJkyP+p5GtswZ+GpAd/5LqSL52TFnAj7Gh5d6fMKy9VuoWaEUjWtUoMITrxJhI+jf5e/3Qb6eNpeRk38md/YsZEibmu17D7HzwBG2zvqK4JArtO89mCWThpI0cQBHT5wmZfJkbN1zkKDLV+76XP+XMV1qLl+5Rqlm7bl+8yYrvx8R+bWwsHDW/r6TYb1eB+DcxSCOnDhN2WJRfyYUiW1LN++iTeNqPN+oSuS5pe+XPzNryNukSJaECm0+uOf9O7SoyZvPNCAo5BrN3xlCw0quy69nSJ2Ccb3as+fwCfYcOcn8Ee9yISiEth+O45fBXfl86jyWjXmP0LAwij5157/Ld7rvrKHvcOXaDdo0qUbBnFkY8M3MyOfaduAYR06dZdGoXuw5fIL3x03jhwFvRDn+n35avIGJc1ZGuS1rhjSM793hjvP0+/JnOj3u+hA4KOQqKQJd/ZEyWVIuXb77zxp7j5wkMEliHkmfJsrtY39eyjcfdGLhhh1Rbg8LC2ft9v189uazUW7/ZfkmHq959/dl//n1MxeC2X34TzZP/pjgK9fo9PFXLBzVk/6vPkXalMk4/td5nu41grVf94u2i41IbFi2/Qgv1i7JszWKR/58/9HUlfzc+ylSJA2gSrcJ97x/u3ql6Ny0PMFXb/D4xz/RoIxrUXqGlEn54rVG7D1+jn1/nufXvq25cPkaHUbMZlqvJxkxawOLPn6B0LBwHn197B0f+073/aXP01y5HsoLtUtSMGs6Bk5bE/lc2w//xdEzl5j34XPsPX6OflNW8H23x6Mc/0/T1+xh8tJtUW7LkjYFY15vfMd5+k9dRYcGUX8e2XLoNGcuXaF0XtcHzQv+x959BkZRLWAYfic9EEioUqT33qS30HvvKEjvCIqigAqIdBFREFCvlSYgvYMg0kSQXqWI9E4agdS5PxYSYgKEkGFTvufPhcnsnrO55mWze/bMmNdIm8qdtXtP8eFPW5g9sAmv5MtC2/GL+HbDPjKnTUW5AlnZe+oyx/69wa5Pe+AbeJ9+M1azevSruLs68e91HzxTuHHw7FV8794nKCSUNXtPMW9oqycujFnxx0maVYj6fOS2/z3uBNwnbxZb105cuEFKNxeypNWHHMVav528wWsVc9CxfPaItoxbfZyfe1cgtbszNSdvfeLtu1bJSf+aefG9F0K7WX9Qr2gmADKkcuWLjqU4fsWPE1f9WTagMrcCgug7Zx/ze1Vg+uYzrBlchZCwcMqO+TXG+47ptgv7VCQgKJTXKuagQKZUTF53MmKsQxd9OHcrkBUDq3D8ih8frzrOD93LRTn/UUv+ushPf5yPcixrGnemdywV5djIpoVJm9KFC7cDef1/e/j17WqP/be+ftFM1JnyO+GmyfuNbR9QLJgpNdv+vkHzUlnZfuomFXKn5Yb/fY5d8Wfbu9743gvljXn7WT6wcsT9rDp0hXk9y0e57/3nfbjuF0TpHFEXuhTMlIptp25SOkcafj95I+L4jC1n6O2dm41Hr0Wb5/L9l3m7Xv4YH4PEjRbGWKxr166MGTOGjq++Sv169ejcuTNBQUGkT2970lCyZEmAKD+cphn5hsjcuXP54ccfcXR05MKFCxHHK1SwvQF+7Ngxdu/ejXcN24vGgYGB3LhxgyxZsuDm5oabmxsFYtjJ4HG3BUiVKlWURS4Pxzp16hRlH1yWqGjRoly+fDnG8x/q2LEjHTt2jHb8v774/HN69uqFh4cHJUuWJHPmzMyePZtuXbtGi5aLiwu/b93KuXPnaNK0KfXr14/YbSZdunRUrFCBU6dOceXKFbyrVydFDG9gAbi6uuLq6gpAu3bt+OE/i3UeNWHCBN4eMuSpj0PEal06v8bH4yfx6uvdqFe3Np1f7UhQcHBETx7uavLYniz4mZ/mzLP15NLFiOPly9nekD52/AR/7tlLzbq2bWgDA+9x48ZNMmfOHNmTfHljnFtMtwVIlcojyiKXh2OdOn2Gsg/eRC5apDBXLl+N8fyHOrZvS8f2bWP1fZr19f8IDgnm9dciX0ix7ZwzlCULFwC2Xgzs35cGTZpTsGABype1tc3VxYXQ0FCcnJzw9fOjYMEC1KtTm23bd1CrXkPKlC5F5kyRK3R/+Xket2/fpnwVbzp17BBxuZP79++zas1aVi1dzA9z5kaZ31/79vPFjJmsXBr55tnDjrVr05puvaMu6BGxWpdX2/Px5Km81r0v9WrXoFOHtgQHBUfsclKimG2Htse1Zd7CJfw4fyGOjg5cvHQ54vjDywodP/E3f+7dR81Gtk8RBQbe48bNW2TO9FJEW/Lni/nTejHdFh604pFFLg/HOn3mLK+ULglA0cKFuHLlaoznP9ShTUs6tGn51O/Rl199y88/fM2ff0W9pv25f8/z5nsfsGSebeHe1WvX+ff8BV4pXfKpC2M2bt6Kr58/x/ft5PTZfxg4ZBjrlv0cZatQXz8/0qbxinK7dGltL77kyJ6NLJkzcfPWLZatXEvhggX4Ze53bN66nRGjxvHFlPGsWreBlYvm8uO8n5/6GEXiw+ttmzNu2iw6DxhKXe8qvNa6qe25yoPdTEoUtv0b/+gz/Ed7Mn/pauYsXoGjgwMXH/z8ApQvbXuOc/zUGf7cf5g6bboCEHjvPjdu3SHzSxlwc3PFzc2V/Hlyxji3mG4LkCpliiiLXB6Odfqf87xSwta/IgXzceXajRjPf6h9i0a0b9Eodt+o/0jjmRpff9snpn39A0jrZfv0kWma9Hr7A3p3bkfBvLkjzh8xuC/vDuhJm56D2blnP5XLlY7xPv0e2eHC78H9Du3fg4HDx/DDomVky5yJTBnTR7vtvkNHmfHtXJb9MCPiWPasmflt6U/8uf8Qw8dPZd38b+L0WEXiolPzukyYNZcuQ8dTp8orvNq0DkHBIaRPY/tZKV7Q9jP56Pb1j7ZlwerNzF2x0daWq5EvQJYtbnsB9MSZ8+w5fJJ6Xd8GIPB+EDfu+JIpQ1rcXF1wc3UhX86XY5xbTLcFSJUiRZRFLg/HOnP+EmUe7NpUJF8urty4FeP5D7VrVJN2jZ68SPlxPB5ZONeiTlUOnjhN2eIF+fTbhRxaZXtTrl63d2heuwop3N3o3qYR3Vo3ZPDYL1i64XdKFclPiYJ5SOOZijSeqbgfFAzAlGH96T/qM1KmcKN4gdxkypA2xrEeXRjz07INFMqTg5+njeK33fv5cNq3zPrI9jrLb3/up3KZYhGXrJzyv58Z9HrrOD1mkWfxaoMqTPpxJd0+mk3tckXpWL8ywcGhpPOyvRlTLG/kLmoPmUS2ZeHGP5i3fgeODg5cun474njZBzuRnDh3mb3Hz9Jw0EQAAu8Hc9PHn0zpvHBzdcbN1Zl82TLFOLeYbgvgkcItyiKXh2OduXiN0gVtH4wsnPtlrtz0ifH8h9rWqUDbOk/+cNVD/1u+heCQUF6tb3sTyCtVSvzu2n4v87t7jzSpUz72tp/MWc3HfdsQHBIWcWzNjv1ULVmAFG6u0c7fuv84lUsUiHIJW9M02bznKKN7xdyF/37dyyMFxfNmJ02qlKRJlZL7wbZPt6fztC0Yzp4pPZnTp+GWrz/pvXRZAol/HWsU45NfdtLr8xXULJGb9tWLEhwaRrrUtvcpiuW0va746Nsej7Zl8fajLNh6BEcHBy7fitwNs0w+20KRk5du8tfpyzQdPQ+AwKBQbvoFkimtB24uTri5OEUs2vivmG4L4OHuEmWRy8Oxzl69Q6k8mQEolD0DV28HxHj+Q62rFKZ1lejvE8Xku437CQ4No0P1YhHHbDvnbOKntyNfp3m420uDV/Ix+ZedAIye9xtjX6+Fd/GcjF+4jYXbjlIydyaK5cqIl4cbXh5u3A+2PbYJXeswePY6Urq5UDRnRl7y8uD7TQfo6F3sqYvjlv9xgv8Nbhbl2MrdJ2lcLvJN6qlL/2DUa96EhIbH6nGLxFX7stmYuvFv+v60jxoFM9C2bDaCw8JJ52H797RIVtu/aVFfb4n885K/LrFw7wUcDIPLPvcijpd5sHjj72sB7Pv3Di1m2H7O7gWHcSsgiJc8XXFzdrTtVJPRg5jEdFsAD1enKItcHo519sZdSj64bFChzKm56nc/xvMfalnmZVqWifn3sUelTWnbWS5b2hRk8nTj1t1g0ntEf74RcD+U6ZtPs2OY7b3xljN20ah4Zt6olZd3fznMgj0XyOLlTsbUbqR2d6Zo1tR4pXDBK4UL90Mjn9OcuR5A2hQuEf8fAJy/HcgHy47wXdfoHwLtWD47I5YcofXMXeTL6EHalC5c97vPhduBlMzmFW1hjP/9EM7fDqTIIzvUyPPTwhiLubu7M3XqVEzTpFDhwnTs2BEXFxdu3bqFp6cnBw8eBGyXEHq4Y8H+/ZFvukz59FMOHzpEQEAARYtFPkl4ePmNggULUqVKFb7/zvaGTHBwMI6Ojly+fJmgoCCCg4P5+++/Y5xbTLd99L7/O1bevHlZ+OBSSUeOHCFLliwxnv9QbHeMKVWqFJs2bsTX15cuXbuSM2dOjh8/zuo1a/jq6685e/Ys/fv35/PPP8c0TZycnEidOjUeHrYI+/r64unpSXBwMH/t28eoUaPYsGEDm7dsYcPGjRw6dIjXu3Rh+bJlEWP6+fmROrXtH4qtW7eSN2/Mb/YDnP3nH0a8/77tz2fP8tFHH/Hhh9rNQV48d3d3Pp08AdM0KVKyDB3btcXFObInhw4fBiCNl1dkTw4cjLj91GlfcHDvbgICAiheJnIVa0RPCuSncqUKfPe17br0D3ty5cqVyJ6cPh3j3GK67aP3/d+x8ubJzaJflgC23WYyZ8kU4/kPxXbHmFVr1rJ2/XqW/Dw/4tidO3d4tXNXvpn9JRkzZog4/mqHdrzaoR379h9g3gLbm8YVypdj46+bqV+3Dr9t/Z0BfXtjGAYTxo4BYNoXM6hcyfYJ06CgIFxdXUmZMiWpUnng6Bj5ws0/585x88ZNGjZryeXLlwkNDaVc2VfInDkTAwa9xdJFCyIW7t29exc3NzccHR3Zum07eXNrO195sdzd3fh0/EeYpknRslXp0KYlzi7O3Lp9G8/UqTl05CjwsC22hS8HDh2JuP3U6bM4sGsLAQF3KVHRO+L4w5/nAvnzUbliOb6daftkcERbrl570JYQTp0+G+PcYrrto/f937Hy5M7FoqUrAdtuM5kzP7ktsdkxxt8/gCtXrtH6te7cvnOHGzdvUr1KJapVrsir3fvyzYypZMyQ4cGYJzh/8RINW3bgzNl/WLVmA8WKFCZ3ruhvdIWFh5EubRoMwyBtGi/8A2wvMGXPlo1jJ06SO2cOjp34m7y5o+785+vrh6dnanx9/bhw8RLp0qYlLCyM9OlsL3ylT5cWXz8//vn3PDdv3qJRq45cvnKF0NAwyr1Smorlnn0rUpHYcndz5ZNR72KaJsVrNKV984a4ODtz644Pnqk8OHTcdsnSNF6puXTF9gv/waMnIm7/2Vc/sG/jEgLuBlK6duSLoQ9fsCyQNxeVy5bim6ljAQgODsHR0YEr124QFBRMcEgIp87+G+PcYrotRO/Dw7Hy5MzG4lW2Lf+PnjhF5pcyxHj+Q8+zY0zFV0qx6fed1KxSgfVbtlGprO3N5BHjp1KkQD5aN6kfcW5QUDCuri44OTnhkSIFKdzdYrxP9wfHb962XVY3LCw8YvHQ3JmfEB4eTtdBw6hXo0qU2527cIk3Roxl8f8+J4W77UXo4OAQnJ2dMAwDz9SpSOEW8y41IlZxd3Vl0rt9MU2TUk27065hTVycnbjl44enR0oOn7Q9j/BK7cGlB4vYDpw4E3H7z39YzJ4lXxEQeI9XWvaKOO7w4Oc9f65sVCpVhK/GvgNAcEgIjg4OXL1xm6DgYIJDQjn9b+QHCx4V020BDIeob7Q8HCt3tiz8st52Wcajp/4hc4Z0MZ7/0PPsGOPrfxfPVLY3rLftPUSNiqVwMAycnZ1wf/CGtGmahIaFERQcjKuLi+3n3CMl7u5u5M2eFV//uwQFB3P33n2cHvy+U7JQXlZ/MxFf/7v0en8yObJminGsR4WFh0csZErn5YlfQOQOE4vXbaVD41oRf//n4hVGffE9AOcuXmXczDkM7/vaUx+vyLNyd3VhwoAOmKbJK51H0LZ2BZydHbnlG4BnSneOnLF9QNErVQou37D9e3roVOSnlb9YuJ4/vvuIgHtBVOgSubNbRFtyZKZisXzMGtYdgOCQUFtbbvkQFBxCcGgopy9GLgR+VEy3BaIson90rNxZM7J0yx7AtttM5vReMZ7/UGx3jFm78wAb/jjMvI8HRByrUCwvm/ccxbtMYTbuPkzFYvl4nH+v3KDfxO+4HxTM3+ev8u2K37jl68/v+07w696jHDlzkT7jv2HBuDcAWLL5T9rVqRjlPnYdOkWpAjlxfeRyTk/6ep6XX8I34B5BwSHcvR8U0S7fgEA8PVLgGxDIxeu3SZs65jf3RJ6Xm4sTY1+vhWmaVHjrG1pXKYyzkyO3/e+ROoUrR/69DoBXSjcu37Ytjj/0T+SboTNW7WH75G7cvR9C5bcjLwX98Oc5X5Z0lC/4MjP62RblB4eG4ehgcPV2AEEhoQSHhnHmSuRivUfFdFuIbMl/x8qVKQ3Ldtl+Xzt+/gaZ0nrEeP5Dsd0xZv1fp9m0/yw/vh15GSafgPv0/HwFn/dpQAZP23OKoAftc3V2Yt/pK2R+MH5YuEm61LbfSdKmcscvMIg8mdPiezeIoJBQAoNCcHK0/d5WPNdLLP2gPX6BQfT/cjXZM3ry96VbbNx3hh9/Pci56z68878NTO5eN8ocL970w8nRgcz/2Qlm2a4TTO0V+fvZvzd8eGPWWu4Hh3Lq8i2+33iALnVKxvj9EXkebs6OfNS8KKZpUnXiFlqWzoqzowO37waT2s2Jo5dtC+m8Urhw2de20OTIpcjdaGdtPcOWd7y5GxSK96TI5wAPnyrky+hBudxp+byD7Xl8cGg4jg4G13yDCAoNIyTU5OyNmC8vG9Ntbff93+cttv/NlT4lKw/YXmM+fsWPTKndYjz/odjuGON3L4TU7s743Qvhks890qaI+RKMhgHOjg64O9ueI5iYhIWbpEnpwledyxAebjJg3n5qFcpImhTO+N0LJSg0jMCgMJweeU1o+YHLNC2VJeLvPoHB9P1pH1PblyBDqugLctycHZnSznYVmQ+XHaFBsUycuOrPJZ97dJj9B//cvMuGo04UzpKaHOlSsu7I1YidfST+aGGMxebNm8cPP/6IaZo0qF8fJycnxo0dS526dcmRI0fE4pJixYoREhJC7Tp1KPVgFxkA7+rVqVqtGmVKl8bLyyva/RcvXpzChQpR3dsbBwcHKlaowLhx43jn7bepVLkyBQoUIEeO6G/GPOm2j1OmTBly5cxJ5SpVcHBwYPasmLfkeyi2O8ZMmDCB9Rs24OrqyqdTpgAwc+bMiK+XLFWKGTNm4OPjQ7PmzXFwcCA0NJQJ48cDMGTIEI4dP05YWBi9evYkY8aMjBgxghEjRgDgXaNGxGWXBg8ezMcff8zvv//OyFGjSJkyJZkzZ+a7b22flpo8eTILfv6ZGzducOHiRX5ZvJilS5ZEmYsWxYi9zPt5IT/NmYdpmtSvWxcnJyc+/mgk9Ro3I3u2bGTJbFvBX6xoEUJCQ6jbsAklSxSPuH31alWpXqsupUuXwssr+irT4sWKUrhgQWrUqY+DgwMVypdj7EejGPLmIKrUqE3+fPnIkT17jHN73G0fp0zpUuTKmYOqNWrj4ODAzOmfP/ZciP2OMT379if7y9mo06Axzi4urF+1nImffMrFS5fp/8abALw//D1qelenQ6cu3Lhxg0yZMvHl51MBGDrkLTp378nY8RNp37YN6dKl4+rVa3Ts3AUnJyfKlyvLGwP6AdCsdTuCHywYGjb0HQzDYN2GjQQE3KV1y+bs3mF7gvn9T3Pw9fGlYoXytH/tdW7fuUPHzl0AmD5tKvfu3aN3/4F4pEyJRyoPvp395LaKxLf5i5by4/yFmKZJvTo1bW35cDj1m7Uje/aXyZzJ9gS8WJFChISGUrdpG0oWj7ysWvUqlahevxllShbHyzP6J+6KFy1MoQL5qdHQ9m94hbKvMHbkcIa80Y+qdZqQP18ecmSLedX/4277OGVKlSBnjmxUrdvE1pbPJj3xscdmx5hUqTzYu30TAL9t28GK1eto1rgB7304hkuXr9D/rXcBeH/oEGrXqEbtGtUAGD1+MiWLFSV3rhxs+PU3Ppk2gzP/nKNu0zZ89cUU6tb0Zu6CxXg3aM79+/cZPcJ2Px+PHEbvN94mJCSEoYMH4OTkxIFDR9jxx2769+rOq9374OcfQGhoKGNHjcDBwYFX27WmQ9deLF+9luDgED6fPI5CBfLzx2+2N/V/mLsAH18/LYoRyy1YvoY5i5ZjmlDPuwpOTk589O4bNOzYi+xZM0csLilaMD8hISHU79CDkkUKRdy+WsWy1GzVhVLFCuHpGf1TQsUKFaBg/jzUbt0FBwcHypcuwZj3BvFWny5Ub/Ea+XPnJPvLWaLd7km3fZzSxYuQM1tWvFt0wsFwYMaEJ/8OENsdY+YsXsH/5i3m1Nl/qd+hB8u+m0HDWtVYtWELNVu+Tr7cOWhQsyrHT51l2tc/UemVkmzcuoNXShZj/Ii3GD1lOnv2HyYkNJSq5V+hVDHbJzLrd+jBib/PcvLMOV5v15wer7bh42GDadVtIADjR9h2Zli/ZTtTZn6LYRj0eb19xKWS+rwzklmTRzNi3FRu+/jSqb/tTf7Px76Pg6MD/YaOilgEPPWjYY99LG4xfPpb5Hn9vGYzc5dvxATqVimLk5Mjo9/oRuNe75E9c8aIxSVF8+ciJCSMRj3epUShyMXmVcuWoHaXtyhVKB9eqaK/EVqsQG4K5slB3S5DcHBwoFyJQnw0qBuDu7SmxmuDyZ8zG9myxHxd98fd9nFKF8lPzqyZqNlpMA4ODnzx4eM7BLHfMWbuio18u3gNp/+9SKMe7/LLjDEsWruF75esw8XZiWIFctO0ZmUMw6Btwxp4vzYI0zRpUacqqT1S8sWPv7Bqyy7Cw8PJkyMrTWpUxNHRkbd7tKdhj3cJDQuLeFyffLOATTv/wsXFmYnv2C5jFdNYAH1HfsrM0W/RoXEtOr09lpWbdxIcEsqnw/sDEBISyp8Hj/PlqDcjHsvP00ZF/Ll86z5aFCOWWbTpD+at24lpmtQpb9u1aGTPVjQf8gnZXkoXsbikSO6XCQkNo+lbkymeL/I11qolC1Jv4ARK5s+Bp0f0HauL5slGwRxZaPDGBBwMB8oVycPIXq14o30D6vQfR95smcj+UroY5/a42z5OqQI5yZE5PXX6j8PBMJj2dsyXf3sotjvGDJj0PS9nTEuTtybj7OTE8ilDqFehBKu376fegPHkzfYSdSvYXncaPmMBm/48QmhYGGcuXuPTNzux6Uvba7P/XrnJe9Pn062pNwDvdGoCQMNBE5k1zHZJt5DQUP48eoYv3ukSZQ6/bPmTFjWifup6wKTvmD60a4xfd3JyZMhrDWny1mRCw8IZ1dP2fev20Wz8A+/ZjvVq9djFziLP65ftx1iw9QgmULtkbpwcHXi/fTVaffwzL2dITaY0tucihbNnICQsnBZjFlA8V+TzjCqFs9No5FxK5M6EZ8roz62L5MhIgazpaTJqHg6GwSv5s/BBh+oMaFqeBh/MIW+WtGRLH/PuAo+77eOUzJ2JHBk9afDBHBwcDKb0jPmytQ/FdseYQbPXkjVdalqMWYCzkyO/jGjHZ8v/4PJtf9753wYA3m5VmXxZ0tJx4i+kdHPG0dGBKT1s47/ZvCJDv92Ak6MDrs5OfDOoKU6ODgxuXoEWYxYQGhYe8bg+W/YHWw7+g4uzI2M6255TPbwfgOpDv4tYFDNo1lqm9bHthr5s13Ga/ucyStd97hIYFELOl7wijq0b0wl4uNvNr1oUI5ZZus+244tpQs2CGXFydGB4w4K0m7WLl9OkiFhcUihzKkLDwmkzcxdFH9lppFKe9DT7YgfFs3mR2j360oDCWVKT/6VUNJ++w9aHnGkY3qgQ/WrkocnnO8iTwYOX08T8IZnH3fZxSmTzIlu6FDT5fDsOhsGkNsUfey7EfseYPj/tIyAohNAwkxGNCuHgYHDDP4h+c/Zx7LIfXb7dQ+/qualfNBMtSmel0bTtmEDj4llI5ebM5uPXmb75NIYBXSvnjFjc8katvLSZuYvQMDPK41p7+AqL+1WK+PsXv57miu893l1s+wD7kLr5qZIvPW/9fJBP25XgyCVfPlh2FEcHgwZFM0X8/1Mtv+21ssnrTlI0q21RDNgW3rzfOHa7cEnsGY9uLyvPzzCMgb179540a+bMmD+69x9dunZl8KBBEZdUksTj8OHDVKte/fydO3diXnkk8pwMw8iWNk2a4zcun3/8vrSP6NqzN4MG9I+yGEYSt4/HT2T0x+PGhoWFvW/vuUjSYRhG1RLFiqz8a/uvsdqHsVvfN3ijb68oi2EkcZuzYBFvvffBslu377R4+tkiT5bWy/P0mnlf5SldvMhTz+3x5ggG9uhEiSLRL5soSUuRao19T//zby3TNP+y91wkcXJ3db176td5KdLF4jIXvUZMpn+nlpQoqJ0Xk7pmfYb7bdyxt5tpmr/Yey6SOKVJnfL08ilv5ylVIOdTz+0z/n/0a12H4vli/oCQJB2lXh3me+biNT1vkThLlcL12m8TumTMlSnNU8/t/+Vq+jR8JeKSSpJ01Rn+o+++M1damab5q73nIolTKjfna5uGVMuYM/3T3x56Y/5+elXLHWUxjCRNDT7b5rv/vI/aEkfaMSaZOHnyJL379IlybPasWRQoUMBOMxKRxOrk33/Td0DUTzbOnD6NAvnzP+YWIiJPd/LUafoOfifKsZmfTaZAvsdf7lBEJCYnz/zDgPc+inJs+oQPKZAn12NuISLydH//c4GBH02LcuyLDweRP1c2O81IRJKCU+evMGjKj1GOTRvSmXzZM9tpRiKSFJy6fIshX6+PcmxKz3rkyxLzTlUiIrFx+noA7yw6FOXY5DbFyZtRlyiUxEELY+zs++++eyHjFChQgN+2bHkhY4mIfXz39ewXMk6B/PnZvGHtCxlLROzv25lPvtRZfCmQLy+bVy99IWOJiH18M3XsCxmnQJ5cbFz0Yn7PEhH7+2rsO08/KR7kz5WN9d998kLGEhH7mzWs+wsZJ1/2zKyZ9u4LGUtE7G9Gv6dffjU+5MuSjhUjO76QsUTE/j7vUOqFjJM3owdL+1d6+okiCZQupinRlCz1YgJ67tw5XN3cOHDgQJTjdevVY/DgwQD89NNPeNeogXeNGmTPkYPPP/+cGzduUKNmTapWq0bNWrX4999/Abh+/Tr16tenUuXKzJgx44U8BhGJvdLlrX/CVKNOfdJmepllK1ZGHHu9ey+q1qhN5eo12bDJtrvcn3v2UsW7FjXq1KdpqzYEBAQA0LRVG2rUqU/FqjXYum07AEePHce7dj28a9fj62/1JptIQlamSi1L7//w0ePUbNSCmo1aUKpSDVq/2g2Av0+fwbtBcyrXbsSylWsAOPH3KcpUqUXKjDnw8fEF4MbNm9Rq3JLq9ZtRu3Er/j1/wdL5ikj8KFuv9QsZ59yFS6TKU5qDR08AcPDoCao1e5WaLV+n/7DIHXDeGjmB6s1fo1qzV9l74EiU+2jYsRdDRk18IfMVkedTvnWfp5/0HE6cPU+tzm9S5/W3aNHvfXz8bL/zbNtziBqvDaZW5zdZs/UPAPzvBtL2jZHU7/YOb4z5nPDwcABaDfiAul2GUK3jQLbtOfTYsUQk4ajcfaTlYzR4YwLZGvVn1bZ9EccOnTpPrb5jqTdgPIMf7ICzec9RGg6aSMNBEyn16jCGTV8QcX5YWDhlO49gxqINls9XROJX9aHWvz46as4WGo+cS4eJi7nlFwjAzNV7KDlgJq9NXhJx3s+/H6Hp6Hk0HT2P4v2+ZPbavZbPTUTiT61Ptlo+RvPpO8g/fC1rD1+JOHbmegDNp++g0bTtrDlkOx4WbjLk54M0/WI7Q34+SFi4CUC/Ofso/MF6vtp61vK5ivW0MEbsZsKECVSpUiXKsa1bt+LkFLmRUadOnfhtyxZ+27KF3Llz07x5c9zd3Vkwfz7bfv+dd4cOZfz48QBMnDiRAf37s33bNuYvWMCtW7de6OMREfub+8N3DBrQL8qxD4a/y7Ytm1i17BdGfDgKgFIlS7D9t1/ZsnEdZUqVYvHSZQAsnj+XLRvXMX/O94weY/tU+7APPmT2l1+wZeM6Fi1ewu3bt1/kQxKRBKRYkUJsXr2UzauX0qxxA5o3aQDA+6PH8cUn49m0cjETpkwjNDSUbFmzsHn1UsqXLR1xe3c3d+Z9O5ut65bzzuABTPz0C3s9FBFJgCZ/+T8qPdKMGd/OZfyIIWxe8gM+Pn4cPn6S85eucOzv02xdNofZn4xh0oxvIs7/fdcenJwc7TF1EUmA0qfxZMmMj9n4w6c08q7ANwtXAfD+Z9+wePpHrPlmIp98s4CwsDC+XbyGulXKsu7byXil9mDDdtubSvOnfsiG76fw0+QRfPzlj08aTkSSkW8/7E3f1nWiHJv1yyY+7tuG9dOH4eN/lyNnLlCzbBHWTHuXNdPepVyRPDSpGvk8Z8HGXWTPlP5FT11EEoEDZ69y6ZY/q0a/Sq/6ZfhixW4AWlUuzNL320c5t121oqwY2ZEVIzuS8yUvGpXNb48pi0gCNqtTGXpWyx3l2Lg1JxjfshiL+1Zk2q+nCA0L59fj1/Bwc2LFwCp4uDnx6/FrAHzYpDAfNilsj6mLBXQppUToyJEj9OjZE3d3d/Lny8fs2bOZPHkya9etw8fHh1EjR9K0aVNGjRrF36dO4ePjQ1BQEB07dGDe/Pk4Ojqyds0atm3bxthx43B3d+fSpUvM/PJLypUrFzHOzZs36dGzJ35+fqRLl46ffvyR06dPRxs7Lk6ePImLiwvZskW9Fve0zz+nf79+bNy4Mcrxy5cvExoaSvbs2QHw8LBdr87V1RUHB9v6rp27djFhwgQcHByoVbMme/bsoX79+nGan0hydOToMXr17Y+7uzv58uVl1vTP+eTTz1i3YSM+vr58OGIYTRs3YvTH4/j71Gl8fH0JDgqifbs2LPh5EQ6OjqxZvoRtO3YybuJk3N3duHz5CjOmTaVc2Vcixrl58yY9+w7A39+ftGnT8uO3X3P6zNloY8dFlizRr8GdN08eANzc3CKOOTs7R/z53r17FMxv+6XJxcUFAD8/f4oUtj3ZuXz5CgUefL1A/vz8ufcv6teN+gKQiMTOkWPH6TVwCO7ubuTPk4eZ0ybzybQZrNu4GV9fPz4c9jZNGtZj9PjJnDp9Fh9fX4KCgunQpiXzFy3B0dGR1b/MY9vOPxj/ybQHnbnK9KkTKFcm8kXWm7du0WvgEPz8/EmXNg0/fDWd02f/iTb281i5Zj1b1iwD4N/zFyhWpBAAhQrm5/TZfyiYP1+023h4pMTDIyUArq4uODgYzzUHEbE5euIUfYaOwt3Nlby5c/DlhJFMmfUdG7Zsx8fPn/ff7EuTujUY8+mXnDp7Dh8/f4KCQ2jfvCELlq3B0cGBlT/NZPuf+5jwxVe4u7px+do1vhj7AWVLFYsY5+btO/R5ZyT+AXdJm8aT7z4bz5lz56ONHRcnz/yDi7Mz2TK/FHGsQL7c+PoHYJomd+/dwzN1atKl8SSluzthYWH4+vmRLo1XxPnTv51Ln9c78Ou2XXH+XopIpKOn/qHfqKm4u7qSN0dWpo8czNTvFrJh+x58/O8yom8nGteoyMdf/sjpc5fw8Q8gOCSEtg1rsHDNFhwdHFg2cyw79h1h0lfzcHNz5fK1m0z74A3KFisYMc7NO770G/kp/ncDSeuZmv+Nf5cz5y9FG/tZpU/jGfFnVxeXiNdOgkNCSeeVGgCv1Kk4/e8lzpy/zGvNbL/jlCqUlx1/HaZ+tXK4PPi9yS8gkMJ5c8bxOykijzp29iIDJn+Pu4sLebO9xLS3X2fa/LVs3H0Y34BAhnVtRsPKpRj33TJOX7iGb0AgwSGhtKldnkWbduPg4MCSSW+y89DffPLTKtxcXbhy8w6fvtWJVwpFvulzy8efAZO/x//uPdKm9uCrET05e+latLHjInP6NNGOFciRGd+792zPW+4H4emRIuJrQcEh7D95LuLyVCGhoazY+hctvF/B9+69OM1BRB7v+PkbDJq9FncXZ/JkTsOnverzxYrdbDpwFr+7QQxtU5kGr+Rj4qLtnLlyG9+7QQSFhtG6ciEW7ziOo4PBwmFt2HX8Ip8u3Ym7izNXbvszuUddyuTNEjHOLb9ABs1eh/+9INJ6uDNzQGP+uXon2tjP6p+rdyiaMyMAxXO9xPiF2wDI6JWS89dDY7zNldv+hIaF83L61HH4jonI4xy/4seQnw/i5uxIngwpmdy2BDM2n2bziev43Qvh7XoFqFc0E5PXneTsjbv43gshOCyclqWysmT/JRwNmNerAn+cvcW0Tadwc3bkqu99JrQqRukckc8nbgUEMWThQfzvh5ImpQvTO5bin5t3o40dF5k83aIdu3A7kEJZbL3I/1Iq/rl5l91nb1O7kK09dQq/xG8nb1C3SKYYby+JlxbGJELr16+nV8+edOvWLWJ72/79+/POO+/g4+ND3Xr1aNq0KQD58+Vj1KhR9OzZk4sXL/Lrpk307NmTnTt3AuDv78/6des4f/48Xbt1Y8vmzRHjTJgwgX59+1K3bl1mzJjBnDlz8PX1jTb2ozq//jrnz5+PcqxXz5507Bj1epbjxo9n3NixjHj//Yhja9eupVLFiqRMmTLa/S5atIg2raNuYR4UFMSo0aOZNXNmxN8fvtnt5eWlXR1EntGGjZvo0b0r3V7vHPHz3a9PL95+azA+Pj7Ub9ycpo1t18HNny8vI98fTq9+A7h06TIb166iV78B7Nxl24o7wN+fdSuXcf7CBbr36suv69dEjDPxk0/p27sndWvX4stZXzFn/gL8fP2ijf2o17v34sKFqJcc6dGtKx3bt4314xvx4WgG9IvcrnzFqtWMGjMWF2cXhg55E4Dg4GDqNmzCyVOn+O5r28K/3LlysXPXH5QuVZIdu3ZRqWKFWI8pIlFt+PU3enZ5ja6dOkZ2pmdX3h7UHx8fX+q3aEeThvUAyJc3NyOHvUPvgUO4ePkyG1cupvfAIezcvQcA/4AA1i5dwPkLF+nefzC/rorcSnfip1/Qp3sX6tby5suvv2Xuz7/g6+cXbexHdek9gPMXL0U51rNLJzq0aRnt3IOHj5IzR3ZSp04FQPiDrTUBvDw9uX3H54nfh6CgID6a8AlfTp0Ui++aiDzNhq076d6xNV3at4j4+e77enuG9OmKj68fjV7tTZO6NQDIlzsnH7zVj75DR3HpyjXWL/iGvkNHsWvvAQACAgJZPWc25y9dodeQD9iw8NuIcSbP+B+9O7enTvVKzPx+PvOWrsLXLyDa2I/qNng4Fy5diXKse8fWtG/RKMqxSdO/4aOhbzByUuTi4HrVK9Oy+xu8M9qJquXLkD1rZkzT5OUsmSjm3ZTAwHusnf81AOu2bKNCmZKkTOH+/N9QEQFg086/6Na6Ia+3qB/x8927fVPe7NoWH78AmvQeRuMaFQHImzMr7/frTL9RU7l07SZrvplEv1FT+ePAMQD8A++xYvZ4Lly5Tu8PprDu28gFulP+9zO92jehdqVXmDV/BfNX/YpfwN1oYz+qx/BJXLhyPcqxbq0b0q5RzWjn3vH15+uFK1ky42MAUri5cu7iFTxTebD/2Cl8/AIonDcnv+0+QLnihfh1V+SlUYJDQmjU411OnbvIV2Pfec7vqIgA/LrnCF0bV6dTo6oRP989W9RkUIcG+PgH0vztKTSsbLvMfd5sLzG8a3MGTvqeSzfusHLqOwyc9D27j5wGwP/efZZ+8hYXrt2m34RvWT1taMQ4n85bQ4/mNahVtihfLf2Vnzfuwu9uYLSxH9Vr7NdcvB719dQujavTts7TXwepXa4Y7Yd/zjCnBVQukZ9sL6WL+NqmP49Qs2wRDMP2wYAfVm2jQ71K3L13/xm/eyISG5sP/sPrtUvyao3iEa9XdK9XmoFNy+N79z6txi6kwSu2D/PkyZyWd9tUYfDstVy+5c+yD9ozePZa/jxpe30k4F4wi4e34+JNPwbOXMPykR0ixpm2/A+61y1FjRK5+Gb9PhZtO4pfYFC0sR/Vd/oqLt3yi3Ksc62StK4SuRtDwZfTM3/rYQY2Kc9vh8/hczfoqY95xR8naVah4FPPE5Fn89vJG7xWMQcdy2eP+JnuWiUn/WvmxfdeCO1m/UG9opkAyJ0hJe/UL8CQnw9y2fcei/tWZMjPB9lzzvbcIuB+KAt6VeCizz0Gzz/Akv6VIsb5YvNpulTOiXeBjHy7/R9++esifvdDo439qAHz9nPpTtQFtp0qZKdlmZef+rhMM/L+PN2d8QkMwfdeCKncnR85FvyM3y1JDLQwJhHq2rUrY8aMoeOrr1K/Xj06d+7M3Llz+eHHH3F0dIzy5nGJErYVdFmzZqV48eIRf759+zaenp6UKlkSBwcHcubMiY+PT5Rxjh0/zh+7dzNu/Hju379P0yZN6NOnT7SxH/XjDz88df4HDx4kjZcXWbNmjXJ8+owZLFq4kD///DPabRYtXszCn3+O+LtpmnTr3p1+fftSsKDtCY+rqyuhoaE4OTnh6+tLoUKFnjoXEYnUpfNrfDx+Eq++3o16dWvT+dWOzF3wMz/NmWdry6WLEecWL1YUgKxZslCsaJGIP9++cwdPT09Klixha0uOHPj4+kYZ59iJk+z+cw8TJn3C/fv3adK4Ib17dI829qN++N9Xz/XYZn39P4JDgnn9tVcjjjVt3IimjRsx6ZNPmfnVN4x4byguLi78tmk95/79l2at2lK/bh0mjf+YgW8OISwsnPz58pE5c6bnmotIctbl1fZ8PHkqr3XvS73aNejUoS3zFi7hx/kLcXR04OKlyxHnlnjQlixZMlG8SOGIP9+540Pq1KkoVbzog85kx9cn6osqx0/+ze69+5jw6TTu3w+iSYN69O7WOdrYj/p+9vRYP46FS5bTtkWziL8/uvOLr58faR/ZweG/TNOkR/836du9S4y7yojIs3u9bXPGTZtF5wFDqetdhddaN2X+0tXMWbwCRwcHLl65GnFu8UIFAMiSKSPFCuaP+PNtH188U6eiRJGCtrZky4qPn3+UcY6fOsOf+w8xafrX3A8KpnEdb3q+1jba2I/69rNxT53/oWMn8fJMTdZHdosBGDjiY1bNmUW+XDno8db7bN/9F/fuB+HnH8DR31dx+tx5Bo0Yy5p5XzHz+/nMnzWFPQeOxOl7KCLRdWpelwmz5tJl6HjqVHmFV5vWYcHqzcxdsdHWlqs3Is4tVsC2S0OWjOkomj9XxJ9v+/rjmSolJQrmxcHBgRxZM+HjHxBlnONn/uXPQ8eZ/PUC7gcH08i7Ij3aNoo29qO+GTeU2AgKDub1oeOY8HbviB1kpgzrT/9Rn5EyhRvFC+QmU4a0dClUn7fGz6Bhj6EUyJWddGlsn550cXZm4w+f8u+lq7Qe8CF1q5SN2zdTRCK82qAKk35cSbePZlO7XFE61q/Mwo1/MG/9DhwdHLj0yMKUYnlsO21nzuBF0dwvR/z5jv9dUqd0p0Te7La2ZE6Pb0BglHFOnLvMnmNnmDJnNfeDQ2hYqSTdmnlHG/tRX43oGefH9ebUH1nyyVvkffkl+oz/HzsP/k2lErbnWr9s/pM+rWoDcD8ohLU7D7B44mDmrdsR5/FE5PE61ijGJ7/spNfnK6hZIjftqxdl8fajLNh6BEcHBy4/sjClSA7b7giZ06ai8CN/vhNwn9QpXCmW6yUcHAyyZ/TENzDqYraTF2+x99Rlpi7bxf3gUOq/ko+udUpGG/tRMwc0fur8C2XPgHexnDQfM58y+bKQLcPTd4FZ/scJ/je42VPPE5Fn075sNqZu/Ju+P+2jRsEMtC2bjSV/XWLh3gs4GAaXfSIXphR5sANLJk83CmeO/LNPYAip3Jwo+rKnrSdpU+B3PyTKOH9fDWDfv3eYtuk0QSFh1Cuaic4Vc0Qb+1HTO5aK8+N6uFgXwO9+CF4pnPF0d8b/Xsgjx1zifP+ScGlhTCLk7u7O1KlTMU2TQoUL07FjR6Z8+imHDx0iICCAosUit/t+9If70T8/XA138NAhTNPk/PnzeHl5RRmnYIECNGnShBo1bJ+uDA4OJiwsLNrYTk6R/xnFZseY/fv3s2//fuo3aMDhw4c5deoUa1av5vLly7Rs1Yrbt29z/fp1vL29ad68OefPn8fJyYksWSK36XvvvfcoWqQIbdtGvqlVsUIFNm7cSP369dny228MHDgwLt9ekWTL3d2dTydPwDRNipQsQ8d2bZk67QsO7t1NQEAAxcuUjzj3aW05dOjwg7ZcwMszcgtvgIL589G4UUNqVK8GRLblv2M/2pbn2TFm1Zq1rF2/niU/z484FhQUhKurKwCeXl4E3r1LWFgYpmni5ORE6lSp8Hiwe1XOHDlYuWQxQUFBtH/tdSqU04vBInHl7u7Gp+M/wjRNipatSoc2LZk6fRYHdm0hIOAuJSp6R5z71OcwR47ZOnPhIp5eUV8kKZA/H43r16FGtSrAI535z9iPduZZdoxZs34jw98eFPH37NmycezESXLnzMGxE3+TN3eux34Pho38mCKFCtKmpV6wEYkv7m6ufDLqXUzTpHiNprRv3pDPvvqBfRuXEHA3kNK1H/k5fvQKZo/8+WFbDh8/aWvLpSt4PdgV6qECeXLRqI433pVsl58NDg4hLCws2tiPtiU2O8YcOHKcA4eP0fi1Phw9cYrT586zeu5sTNMkrZcnhmGQ1ssTX/8AHB0dSJvGK+JYwN27+Afc5cq1G7Tt+SZ3fHy5ces21Sq8QrP6tZ7zOyuSvLm7ujLp3b6Ypkmppt1p17Amn/+wmD1LviIg8B6vtOwVca7xSFAe/XNEW06exTRNLly5jlcqjyjjFMiVjYbeFaheriRg26UlLCw82thOTo4Rt4nNjjGmadL7/Sm82rQOlUpHvilVslBeVn8zEV//u/R6fzI5stoW/n85yraL5tCJM2lSs/KD34/AycmRVB4ptCOVSDxxd3VhwoAOmKbJK51H0LZ2Bb5YuJ4/vvuIgHtBVOjyQcS5T/ud6PCZC7a2XLsV5dJFAPmzZ6ZBpRJUK2374GBwSChh4eHRxn60Lc+zY4xpQtpUKW3PUVJ74HvXtlDnXlAwR89epFwR22Wu/71yg5s+/rQcOpUrN+4QGhbOK4VyU75o3lh9/0Tk6dxcnBj7ei1M06TCW9/QukphZqzaw/bJ3bh7P4TKb/8v4txH0hLlzya2zhz99zqmaXLxph+eKaJeTiRf1rTUK52XqkVzABAcGkZYeHi0sZ0cHSJuE5sdYwD6NS5Hv8blWL3nbzJ5RX3u9F8Xb/rh5OhA5rSpnnieiDw7N2dHPmpeFNM0qTpxCy1LZ2XW1jNsecebu0GheE/aGnHuY3vy4HnLsct+tp7cuUdqN+co4+R7yYM6hV+iSr70AASHhhMWbkYb+9GePM+OMdnSuHPyqj850qXg76sB5EqfknK50vLbyRtUzZ+BzcevUz532lh/nyTx0MKYRGjevHn88OOPmKZJg/r1cXJywrt6dapWq0aZ0qWjLXB5kjRp0tC0WTMuX77MjOlRPyk9YsQIevXuzZiPbdvtjvzwQ06fPh1t7EfFZseYLl260KVLF9ufu3Zl8KBBeHp6sn+fbbve3377jWXLltG8eXMAFi5cGOUySsePH+fTqVOpXLky6zdsoFzZskyaNIl3332XTp07M+bjj+nQvj3p0qX779Ai8gTzfl7IT3PmYZom9evWxcnJierVqlK9Vl1Kly6Fl5fn0+/kAa80XjRr3ZYrV67yxdQpUb42/N136N3/DcaOnwjAByOGcfrMmWhjPyq2O8Z06tqDXX/sZtmKlRw+cpQPhr9Hz779yf5yNuo0aIyziwvrVy1n6fKVzP76GxwcHPDy8uL7b2bj7+9PizbtcXBwIDQ0lHEffwTA9z/N4ac583BwcODDEcNwc9M1JUXiav6ipfw4fyGmaVKvTk1bZ6pUonr9ZpQpWRwvz9hfCzqNlyfN23fmypVrfD5lfJSvDX97EH3eeIexk6YC8MF7Qzhz9ly0sR8V2x1j9u47QP68eaJc+vHjkcPo/cbbhISEMHTwAJycnLh2/QadevTj0OFjtHy1C4P79SZf3tx8NmM2lSqUZcPmLZQtXYqJYz6M9WMWkZgtWL6GOYuWY5pQz7sKTk5OVKtYlpqtulCqWCE8PWP/AqmXZ2padhvIlWvXmfbxiChfe++NXvR7dzTjp9kutzhicB/O/Hsh2tiPis2OMZ3bNqdz2+YA9HhzBAN7dCJlihR8OKQ/LboMwMXZiUwZM1C3eiUcHByY98tKarV6nftBwYx8ewCpPFLy57pFAGzdtYcV6zdrUYxIPPh5zWbmLt+ICdStUhYnJ0eqli1B7S5vUapQvmgLXJ7EK7UHrQd+yJXrt/hsRNQP8Qzt1ZEBoz9jwuy5AAzv04kzFy5FG/tRsdkxZsP2PazZ+gdXbtzi28VraORdgTdeb80n3yxg086/cHFxZuI7vQE4eOIMQyfOxNHRgSY1K1OiYB58/AJo+8ZI2+9HYWGMGdw91o9XRB5v0aY/mLduJ6ZpUqd8MVtbShak3sAJlMyfI9oClyfxSpWSdsM+5+otHz4Z/FqUr73dqTGDPvmBST+uBOC9Ls04e+latLEfFdsdY3p8/BV/HjnNqm37OHLmIu91acqIbs1pM2waLk5OZErnSe1ytgV563cdok75yA9xFsiZha1f2X4Hmrt2Oz4BgVoUIxLPftl+jAVbj2ACtUvmxsnRgSqFs9No5FxK5M6EZ0rXWN+XV0o3Xp30C1fvBDCxW9Qd7N5qUYk3v1rHJ0t2AjC0dWX+uXon2tiPis2OMQBNR9tei82bOS3juth+t1mw9Qg//nqAM1fu0GLMAua/2xo3FyeW7TpOU11GScQSS/fZdocxTahZMCNOjg5UypOeZl/soHg2L1K7x36Zgae7M53/t4drfvcZ37JYlK8Nqp2PdxYeZOrGvwEYUjc/524GRhv7UbHdMab/nH3sOXeHtYedOHbZnyH18jOsUSHeXniQkDCTATXz4OToQO3CL7HuyFWafbGD3BlSUquQbVffkcuPsuXEdcLCTc7evMuEVsWeMqIkZMaj19GS52cYxsDevXtPmjVzZoJ/5/ThApTPPvvM3lNJlA4fPky16tXP37lzJ4e95yJJk2EY2dKmSXP8xuXzKZ9+dsLx2+/bWL5iFVM/mWjvqSR6H4+fyOiPx40NCwt7395zkaTDMIyqJYoVWfnX9l9jv9otgflt2w5WrF7HpxPG2HsqidKcBYt4670Plt26faeFveciiV9aL8/Ta+Z9lad08SL2nspze7ioZMqod+09lUSvSLXGvqf/+beWaZp/2Xsukji5u7rePfXrvBTpvGK/aDah+n3PQVZu3snkd/vaeyqJXrM+w/027tjbzTTNX+w9F0mc0qROeXr5lLfzlCqQ095TeW7b9p9g1fZ9TBzY8eknyxOVenWY75mL1/S8ReIsVQrXa79N6JIxV6Y09p5KvNp+9Dxr9vzNuC617T2VRKnO8B9995250so0zV/tPRdJnFK5OV/bNKRaxpzpE9XbQzHacfom6w5fZUyLok8/WZ6owWfbfPef91Fb4sjh6aeIiIiIiIiIiIiIiIiIiIiIiCQ+upRSMubt7Y23t7e9pyEiSYx3tap4V6tq72mISBLmXbUy3lUr23saIpLEVK9YluoVy9p7GiKSxFQrW4JqZUvYexoiksRULVWQqqV06RARsU6VItmpUiS7vachIklA5bzpqZw3vb2nIaIdY5KLkqVid6215xEWFkbn11/Hu0YNOnTsyL179wBYtGgRFSpWpGq1auzZsweAwMBAWrdpQ5WqVRkxYkS0+1q+fDlVqlalStWqvN6lC2FhYQBMnjyZ8hUqUL5CBdasWQPAhQsXqO7tTXVvb1q1bk1wcLDlj1UkuStdvpLlY2zdtp1K1WrgXbseHTt3JSQkBAA/Pz86de1B7fqNeK2L7Tr33/80h/xFSlCzbgOatGwdcR816tQnbaaXWbZiZYxjxPT1rj17U65yNWrWbcAHoz6Kcv68BQtJlzlbfD9UEfmPMlVqvbCxdu7eg5NnJnx8fAkPD6dBi/ZUq9eUavWasv/g4Sjnjv9kWpS5ffn1t1Sp05j6zdtx/caNKOeGhIRQtW4TajRsTrV6TTl6/AQABw4doXLtRlSv34x+g4da/wBFJELZeq2fftJz2vT7Tuq06UqdNl0pUq0x74yeFPG1sLAwStRsxuff/ATAjwuXUahKQ+q06UrzLv0jzqvdugsZi1Ri+bqYd8WdMus7qjTpSJUmHVm7+XcAhn40OWLc9IUqcPj4SQsfpUjyVb51H8vHuO3rR9UOA8lQrikHT5yJOD58ylfkrtmedybOjDj2+56DlGnek2xVo/Zt6ncLqdZxINU6DmTd738C8PGXP/JKi57U6/o2fUd+Gm3c67fu0LT3MGq8NphZ81c8cS79Rk2lbpchVGk/gCXrf4/Xxy+SHFXuPtLyMW77BeDdewyZ6/fl0KnzEccbDppI3QHjaDhoIrOX2J57zF27nRId36PhoIm0ee8zAEJCQ6nTfxwN3phA3QHjOP7PJQC2HzhJ7X5jqTtgHGt3Hog27qkLV6k/cAK1+o5l5e+2KxUt2fwnNfqMoe6AcQz9fF7EuQs27KJ6r4/w7j2Gn1Zvs+g7IZJ8VB/6neVj7Dh2nrojfqTxyLn0nLaCkFDb+zgj52yhcJ8ZDP9+U8S5a/acouGHc2j44Rz6zVhNWHg4IaFhNPhgDk1GzaPhh3M4ccH22srM1XsoOWAmr01eEuO4py/fpvHIudR7/ydW/fl3lK8t3n6M3N0+i/j7ldv+dPpkCc0+ms8HP26O5++ASPJW65Otlo+x8/RNGn62jebTd9Dnp78ICQsHoPXMXbSYsZPm03dQcMQ6AGZsPk2LGTtpMWMnRT5cz/ojVwFoPn0H+YevZe3hKxH3e+Z6AM2n76DRtO2sOXQl2rgD5u2nyefbaTRtO7+dvA7YLglVavTGiDHuBoVa/fAlnmnHGIk3y5YtI2uWLPz4ww989dVXfPfdd/Tu3Zux48ax+48/uHv3Lm3atuXXTZv43//+R/Vq1Rg4cCCtWrfm8OHDFCtWLOK+GjRoQLNmzQDo0rUr27Zto2rVqnz/ww8cPnQIf39/6tWvT8OGDfnuu+/o2aMHr732Gu+++y7r1q2jadOm9vo2iEg8yZs7N5s3rMXNzY3hH4zkl6XLad+2NaPGjOON/n0p+0qZKOf379OLQQP7Rzk294fv+Prbx/8S+Livf/XldEqWKB7lWGhoKIuXLCXby1mf41GJSELz+Zdf8Uop26e4DcNgxqcTyZ0rBydPnebNdz9gzZL5APj4+HLsROQbzbdu32bB4mX8vn4Fq9dvYtJn0/lk7OiIrzs7O7N59RKcnZ35bdsOpnz+Jd/O/Jzps79h4pgPqVKxPB269OLQkWMUL1r4xT5oEbFM7WqVqF3NtoC4+5sjaFY/cjHdvCWryPFylijn9+3SgTd6dIpy7Mfpk/jfvMUx3n9YWBg/LVrOvo1L8A+4S+PX+tCgZjUmffgOAHcDA6nW7DWKFSoQnw9LRF6gVClSsPTLjxn+yVdRjg/s3Ip6VcuxasuuiGPFC+Rh2/wvqNFpcMSxsLAw5izfyJ4ls/G/e4+mfYZRv1o5AD4c0IWmtWLede/TbxfSu0NTGlQrT50uQ2jTwJvUKWOey2cjBuDi7Iz/3UBqvjaYlvWqxdOjFxGrpErhxi8TBzNi5sJoX1s4fjBeqVJEOdarRU36t6kb8XdnJyfWTBuKs5MT2/afYNqCdcwa1p0PZy9i0YTBeLi70vjNydQtXxxHx8jP4n709S9MGfwauV/OSP2BE2hQqSRlCuVm04wRODo60HX0LP48eoZyRfLwxc/r2PTlCJwcHajaYzSdGmk3YpGELlemNKwY2RE3Fyc+mreVlbtP0rJyYfo2KkvtkrlZu/dUxLm1S+WmYdl8APT/cjW7jl+kSpHsrBjZAWcnR7YfPc8XK/9kRr9GtKpcmPpl8vLBT1tiHPfjBVuZ1L0uuTJ50XjkPOqXyYuTowOhYeEs/+MEWdOljjh35JwtjO9Sm5fTp47xvkQkYcuVPiVL+lfCzdmRsauOs/rQFZqXysrivhUB2H7qJr/8dRGA/jXz0r9mXgCqT/qNavkzADCrUxl+2vVvlPsdt+YE41sWI2f6lDSfsYO6RV7C6ZHnMEPq5CdXhpT4BAbTdtYfeBfICEDj4pkZ06Ko5Y9brKEdYxKxgQMHsn37dgD27t1Lz549uXbtGrVq16Za9eo0adqUoKCgKLfp0rUrBw4cAGDUqFEsW7YMgPHjx1Pd25vKVaqwe/fuOM3n9OnTlCxZEoDSpUvz+7Zt3Lx5k8yZM+Pq6kratGm5fv069+/fZ/uOHTRs2BCAxo0asWPHjij35eLiAoBpmpimSa5cuXB0dCRHjhwEBQXh5+dHmjRpAChUqBC+vr4A+Pj4kC5dujjNXyS5e+PNt9m+YycAe//aR69+A7h27Tp1GjTGu3Y9mrZqE60pXXv25sDBQwCM/nhcxM4rEyZ/Qo069alaoza7/9wTp/lkzZoFNzc3AFxdXXFwcHgwt7/47sefqFGnPnPn/xxx/lf/+5bqtery7Q8/RhzLkiXzE8eI6euGYdBv4CDqNGjMH7v/jDj+/U9z6NCubcQ8ROTZDHpnONt32Z5j7N13gN4Dh3Dt+g3qNGmNd4PmNGvXKVpjuvV9gwOHjgAwevxklq9aC8CEKZ9To2FzqtZtwu69++I8p01bfueV0iVJkdL2IrBhGOTOlQMAVxcXHByMiHOnfDGTgX17RPz9z7/24121Mg4ODjSoU5Pde6LPw9nZGQB//wCKFLJtc14wfz58/fwwTZO7gYF4eeqFGZHnMfiDcez40/bz99fBo/QdOoprN25Sr30ParV6nRZdBxAUFHVHyR5vjuDgUdsuTmM+/TJiZ5ZJ07+hdusueLfoxJ/7Dz3XvIKCgvnr0FEqlysN2HaRWrpmE60a1Y1y3jdzF1Gz5et8v2BpxLEsmTI+9n4dHR3JnjUzQUHB+AXcxcszVZSvr964lYa1qj/X3EWSm7fGzWDnPtvzjb+O/k2/UVO5dvMODXsMpc7rb9FqwAcE/Wdn2l4jJkfsoPLxlz+y4lfbaxqTv5lP3S5DqNlpMH8eOh6n+Tg7O5E+jWe045kzpMMwjCjHvFJ7kMLdLcoxR0dHsmXOSFBwCP537+KVyiPia+NmzaHO62+xZusf0e7/jwPHqFu5LA4ODniXL8VfR04+di4uD57jBN4LokBuXWJBJCZvfzaXXYdsuxjsO/EPAyd9z/XbvjR5czL1B06g7XvTCAoOiXKbPuP/F7Gby7jvlrFqm+05zpQ5q2nwxgTq9B/HnmNniAtnJyfSeaWKdtzAoP3wz2n97mecOh/5aenvVmyl3oDxUXZucXayfcbWP/AehXPZPjQUEhJKOk8PXF2c8UqVgjMXr0W5//NXb1Ikz8u4u7pQMGcWzl66To7M6SMWz7i6OEf83pX35Ze4e+8+94JC8EgRtW0iYvPutxv544TtDeD9Z64wePZarvvcpfmYBTQeOZeOExcTFBJ1B4P+X67m8Dnbz+bERdtZvcfWpqlLd9Fk1DwafDCHvacux2k+WdKmws3F1gZXZ8eIn+dMaTyiPW9xcXIEHr7nAzky2p5jOD847n8viELZbJdayeiVEscnvAZ7/oYfhbNnwN3FmQIvp+fs1TsAzP/tMK0rF8bhwdihYeH8c82Hj+b9RtPR8/jt0Lk4PU6R5GT4ksPsPnsLgAMXfBjy80Fu+AfReuYumk/fQadv/iTowe5QD70xfz9HLtnep5287mTEziyfbzpF8+k7aPL5dvb9eydO88ns5Y6bs60TLk4O0dqy4sBlmpWK+iGkv87doXDm1Li72G6XyTP684oLtwMplMV2Tv6XUvHPzbtRvp4rQ0oAXB806qG1R67S7IsdTNt0Ckl8tGNMItahQwfmzZtHlSpVmD9/Ph07diRNmjSsX7cOJycnhg8fzsqVK2nd+slbhh85coQjR4+y9bffuHnzJh06dmTjhg1Rzqlbr160SxR9+MEH1KxZM+LvRYsWZfny5bRr146NGzdy584dMmTIwKVLl7hz5w4+Pj6cPn2aO3fucOfOHTw9bU98vLy8OH48+gtGX331FZ9OnUrevHl56aWXAKherRoFCxUiKCiIeXPnAlChQgUaNGzIlzNnkjVrVipVsv4SLyJJUfu2rZn/8yKqVK7EgoWL6NCuLWnSeLF25TKcnJwY8eEoVq5eS+uWzZ94P0eOHuPI0eNs2biOmzdv0vH1bmxYvSLKOfUaNyPkP015f/h71PSO/kbOP+fOsWHjJoYNfRuAPX/tY8LYMZQuVZKadRtQv25tmjdpTOdXO3L//n0aNWtJ5YoVKJA/f5y+D5PHjyVdunT8++95mrdpx77dOwkODmb5ylWs+GUR4ydNjtP9iiR37Vq3YMGiJVSpWJ4FvyylfZsWpPHyZO3SBbbGjB7HqrUbaNW8yRPv58ix4xw9foIta5Zx89YtXu3Wl/XLo37qsX7zdgSH/KcxQ4dQs3qVKMemz/6Ged/OYs2GTVGOm6bJ0PdHM+SNfgDcuHmTs/+co1yZ0hHn+Pj44pna9sKyk5NTtKYBnL9wkVe79+XCxUv8Mte2O1W92jVp0b4zbzuPpGqlCmTP9vITH6+IPFm7Zg1ZsGw1lcuV5ufla2jXvCFpPD1ZPWcWTk5OfDBhGqs3/UbL/yxI+a+jJ05x9OQpNi3+npu379BpwFDWzvs6yjkNO/aKuLTjQ8MH96FG5fLR7m/9b9upXbVixAs2385fwmutmxBwNzDinKb1avJa66bcDwqiaae+VCxbkgJ5cj31MVer8ArFazQlKDiYH76YGOVri1au44O3+j31PkQkUtuG3vy8eguVShdl0ZottGtYgzSeHqyYNR4nJ0c+nPYta377gxZ1n7wrytFT/3Ds1Dk2fD+Fm3d86TJ0HKu+jvoz2qTXewT/582qYX1exbt8/F7+uuorxSnZtDtBwSF8P/E9APp2bM77/Tpzy8ePRj3fpVKponiljlw0ExQSgrOz7WVCr1QpuePr/8Qx2g8eza79RxgzuMcTzxNJrtrULs/CTX9QsXh+Fv+6mza1y+OVKiVLJ7+Fk5Mjo7/6hbU7D9Lc+5Un3s+xsxc59s8l1n7+Hrd8/On20WyWf/p2lHOaDZlCSGjUtrz7elOqly701Hn++FE/0nl6sP/kOQZP+YnV04bSqEppOtSrxP3gEFoNnUqFYnnJlz0zF67dottHs7l47Rbzxg4EwN3NhXNXbuDpkYIDJ//ljn/UN5XCw82IP3t6pIjy9b+O/8PVWz68Uig3AA2rlKJKj9GEh4czunebp85dJDlqVbkQi3ccp0LBl1my4zitKhfGy8ONxcPb4uTowJj5W1n/12maVij4xPs5fv4GJy7cZOWojtzyC6Tn5ytY8n77qGON/Tni0kgPvd2qMtWK5oh2f/9e92HzwX94s0XFJ477w6YDfLl6D7kzpSGDp+1N54s3/eg5bQUXb/nx09stY/NtwHy0LSld8Qm4R1BIKGv2nmLe0FZ8utS2w95Nv0CO/nudbwY1xTOFG80+ms+WCV2ifBBKRKJqUSorS/ZdonzudCzdd4kWpbPi6e7Mgl7lcXJ0YNzq42w4eo0mJbI88X6OX/HjxFV/lg2ozK2AIPrO2cfCPlEb0W7WLoLDzCjHhtTNT5V86aPd37+3Avnt5A0G1c4XcSw0LJxdZ28xrmXUHVyWH7gUbbHMf5nmIx1xd8YnMCTG88avOU73qrbXakpm82LnsJo4GNB3zj5+//tGxK40kjhoYUwiVqlSJd586y1CQkLYvmMHkydP5vr16/Tp25fbt29z/fr1iAUlDz26ku7hD/2xY8fYvXs33jVqABAYGMh/bVi//qnzadiwIb///js1atbklTJlyJw5Mw4ODnw6ZQotWrYkS5YslCpVigwZMpAmTRp8fX1Jnz49vr6+pE2bNtr99erVi549e9K/f38WL15MuXLlWLd+PWceLK5p1Lgxf+7ezbvvvcdnU6dSu3ZtPvzwQ+bMmUOnTp1imKGIPEmlihUYMnQYISEh7Nj5B5PGj+X69Rv0HTiIO3fucP3GDV7KGPUTzDE25fgJ/tyzl5p1GwAQGHgv2ljrVy2P1Zzu3LlD5649+PbrWRE7SWXOlIlKFSsAUKZ0ac6c/YdyZW0vJKVIkYKG9etx6PDROC+MebjrVI4c2cmSJQs3b95kwcLFdO3cKdpqZBGJvUrlyzJk2Ie2xuz6k0ljRnL9xk36vTmU23d8uHHjJi9ljPqLREyNOX7ib/7cu4+ajVoAMTdm3bKfox37r5Vr1lO9SiVSpEgR7WvDR42l3CulqVHNtpBm4tQveGtg3yjneHl5cvyk7ZMBYWFhOD9o1KOyZ3uZbRtWsnvvPoaN/JgNKxbR/613WbN0Afny5KZb3zfYtvMPqlaq8NT5ikjMKr5SkndGTyIkJISde/Yz4f0hXL95mwHDPuKOjy/Xb90mY4aoO0rG2JZTZ/hz/2HqtOkKQOC9+9HGWjPvq2jHHmfxynX07/YqAPfvB7F6028s/+FLfloU+Rzo4Y5RKdzdqV+rGkeO//3UhTF/nz3Hht92cHz7Gu74+tH89f7sWGW75JuffwDnLlyieGFdRknkWVQoWYShk2YREhLKzv1HGDekJ9dv+/DGR9O44+vPjds+vJQuTdQbRemI7X9PnDnPnsMnqdfV9oZ14P2oO+EBrPxqgmWP46FT5y6yccdejq75gTt+/rTs/wHb5n9BOi9bc9J5paZ8iUKcPn+JV4pG9sLV2ZnQ0DCcnBzxDbj71J1gFnw2ktu+flRtP5COTWrj9J9PUookd+WL5uW96fMJCQ1l1+FTfNy3LTfu+DP40x+543eXGz5+ZEgbdffIR19xiGjLucvsPX6WhoNsC+0C70dfkL98ypA4zzOdp22BXKkCOQm4Z/vd6uFllVK4uVKvQgmOnLlIvuyZyfZSOjbOGM6eY2cYOXsRKz59h8lvvMobk78npbsbxfJmI1M6ryj3/+ibz35375Emle2N8H+v3OTdL+Yx/8ECG//Ae3w2by375owDoOGgSTSrXoYUbq5xfmwiSVG5Ai8z4sfNhISG8cfJi4x+rQY3/O4y5OsN+ATc44ZfIBkfLDh5KGpbbHE5eekmf52+TNPR8wAIDIq6uA7glxHtYjUnn4D79PliFdP7NYzYFeZxXq9dks61SvDO/zayYvdJ2lYtwsvpU7N2zGvsPXWZ0XN/Y+kH7Z94HwDGo20JDMLLw53vNx2go3exKL/veaZ0JUdGL3Jk9AIgS7pU3PIPjFiUIyLRlc2Vlg+XHyUkLJw//7nNyCaFuRkQxNDFh/AJDOFmQBAZUkX999l4pDQPl5v8fS2Aff/eocUM21UK7gVHXWgH8HOfJy+me8gnMJgBc/cxrUNJXJwid5PafvomFXOni3IJJNM0+e3kDUY0fvIC4Udb4Xc/BK8UztHO+WHnOYLDTNqVzQZAStfIZRWNS2Th8EVfLYxJZLQwJpGrWaMGo0ePpnKlSjg4ODB37lzq1qlDv379GD58eJQVbwBpvLy4ePEiJUuWZP+BA5QqVYqCBQtSpUoVvv/O9knm/+4MA7HbMcYwDCZOtP2S9tlnn1Gliu3NpNq1a1O7dm0uXrzI8BEjcHJyonKlSmzYsIG+ffuydt063h8xIsp9BwUF4erqimEYeHp6kiJFCsLCwvD09MTJyYnUqVNz78Eva2FhYaRPb1s9+HChjYjETQ3vanw0djyVKpbHwcGBeQt+pm7tWvTt3ZMRH46KuSmXLlGyRHH2HzxIyRLFKVggP5UrVeC7r2cDMTclNjvGBAUF0e611/n4o1FRFrm8UqY0J//+m/z58nH02DGyZ8uGr68vnp6ehIeHs23nTmrVrBHn78HD+/L19eXChQukS5eO4ydPsnrder7+9nvO/nOOAYPfYvpnn8Z5DJHkqka1Knw0YQqVKpSzNWbhL9SpUZ2+PbsyYvS4aI3x8vLi4uXLlCxelAOHjlCqeDEK5M9H5Yrl+Hbm50DMjYnNjjGHjx5ny+/b2bh5K4ePHKdr3zdYOv8HZn3zPT4+vowf/X7Euf+cO88HY2xvZJ099y9jJk6hb48uTPz0C0zTZMPm3yhftnSU8YKDg3F2dsYwDLw8U5MihTtg++UsbRovDMMgbdq0+Pr5Pcd3VEQAvCuX4+OpM6n4SkkcHByYv3Q1tatVos/r7flgwrTobfFMzcUr1yhRpCAHjpygRJGCFMibi8plS/HN1LEABAdH/6RQbHeMuXfvPoePn6J86RIA/HPhEjdv3aFJp75cvnqN0LAwypUqRqF8efBMnYrw8HB2/LmPWlWevkguLCyc1Kk8bL8TeXhw737kAp6VG7bQpG7cnwOJJGfe5UoyduZPVCxZBAcHB35evZlalcrQu31TPpz2bfTfg1J7cOnaDUoUzMPBE6cpUTAP+XNlo1KpInw19h0AgkOid+RF7BgTFh5Oao8UODk5ktojBfcfLNDx9b+LZ6qUBIeEsP/YKUb0jfqBovIlCvHrrr+oW6Usv/95kL4dmz92jKDgYFxdXEjp7oZHSveIS6KISFTVSxdi/PcrqFA0Hw4ODizctIuarxShZ4uajP7ql+jPUVKl5NKN2xTPl51Dp85TIl928ufITMVi+Zg1rDtAtIbA8+0Y43f3HqlTunP+6k0cHW1vaPsGBOLpkYLw8HB2Hvob71cKExwSirOTo+33G48UuLva3hArkT8HKz59B9+AQPqO/x85Mkf9hHe2l9Jz4twlcmbOyIlzl8mdNSN3/O/S7aPZfPluVzKksS0OcjAccHF2xN3V9oED0zQJDQuPzbdZJNmpWiQHkxbvoHyBrDg4GCzedowaxXPSvV5pxszfGr0tHm5cvuVPsZwvcfjcdYrleol8WdJRvuDLzOjXCIDg0OhvWMdmx5igkFC6fbaM9ztUI1+WdP+9iyiCQkJxdXbCMAxSp3DF3cWJ4NAwnB1tl0bxTOlKCtfob0zHJFv61Jy4eJOcGb04efEWuTOlYfbavWzcd4Yffz3Iues+vPO/DUzuXpcMnim4E3CPFK7OXLntT9pU7rEaQyQ5q5I3PVPW/025XGlxcDD4Zd8lqhfISNfKORm3+jj/yQxeKZy57HOfolk9OXLJl2JZU5Mvowflcqfl8w6233WCQ6P/ux6bHWOCQsPo9eNfDGtYkLwZPaKcu3z/ZVqVibob9+5/blMim1e0SyD9V7Y07py86k+OdCn4+2oAudJHXTC34eg1fj1+ne+6lo045ncvhNTutk7tOnOLajHsbCMJmxbGJHIdO3akVOnS/LHLtjVcrVq16NS5M+vWrydVqlRk/M/uDl26dKFT5858+913uD74BaZ48eIULlSI6t7eODg4ULFCBcaNGxfldrHZMebq1au079ABJycnKpQvz6BBgwAYPHgwhw4fJnXq1Hw5YwYA3bt3p1PnzsybP58qlStTrFgxAHr06ME333zDl19+yfIVKwgPDydf3rw0a9YMR0dHcufKReUqVQgODuadt22fwho+bBj9BwzAyckJNzc3Fsyf/xzfUZHkrUO7tpSpUJmdWzcDULOGN69378m6jRtJ5ZGKjBmirn59vdNrvN69J9/98BOuLg+aUqwohQsWpEad+jg4OFChfDnGfjQqyu1is2PMtz/8xMFDhxg9xvYGVY9uXenYvi3jxoyiT/83uHfvHq1btiBTppcY+dHHbNz0KwANG9SndKmSAHTq2oNdf+xm2YqVHD5ylA+Gv8fEyVNo1bI5efPkifHrHV/vhr+fH6GhoYwbMxoHBwe+/PyziHmVLl9Ji2JE4qhDm5a8UrU2OzatBqBm9ap06T2A9b9uIZWHBxkzRP1l4vWO7ejSewDf/7QA1wc7shQvWphCBfJTo2FzW2PKvsLYkcOj3C42O8YMf2cww98ZbJtHoxZ8N/NzAgLuMmjoCMqXLUPNRi3I/nJWvp89PeIySABlqtTig3dtn8hs3bwx1eo1JWWKFPzw1XQAJn76Ba2aNSYsPIzeb7wd8UbRtEm2lo0aPpSmbTvh4uJC5pcyUq+W3sQWeV7tmzWkXIO2bFtuu9RqzSrl6TpoGBt+20EqjxRkSB91d8rObZvRddBwfvh5Ka4PXngtVqgABfPnoXbrLjg4OFC+dAnGvDcoyu1iu2PM2s2/U69G5EK8Qvlys3P1AgB+XLgMHz9/KpQpyehPprPpd9vvcQ1qVqVUscIAdHnjPXb9dYBU61Jy5MTfjBjcl8kzvqFFw7oUypebXNlfxrtFJ4KDQ3irT9eIcRatXMe4YW8+y7dORB5o27AmFdv25be5toW33uVL0WPYRDbu2EuqFO5kTOsV5fzXmtWlx/BJ/Lh0Pa7ODzpSIDcF8+SgbpchODg4UK5EIT4a1C3K7WK7Y0yjHu9y/Oy/nDx3gc7N69G9TSOmfreQRWt/4+YdXy5evcH8qR9y6OQZhk3+in8uXKFRj3cZ+UYXyhUvRK6XM1Oz02CCQ0IZ3NV2OZL3PpnNiTPnCQsPo1vrhmRMl4arN28za95yRr3Rlbe6taPH8IlMmD2Ptg28I3aYiWkubQaOJCg4hOCQUN7t2VE7a4o8RptaFajScxS/fmn7QGD10oXpNfZrNv15BI8UbqRPkyrK+a82qEyvsV8zZ812XB9c2qxonmwUzJGFBm9MwMFwoFyRPIzs1SrK7WK7Y0zTtyZz4txl/j5/hU4NqvB642o0HjwJd1cXwk2TCQM6APDFz+vZvPcoAPUqFKdk/hycOn+FgZN/wNHB9vvN5EEdAfh07mp+/fMoLi5OjO9v213i0Knz7Dp8it4tazGyZ0sGTv6BkNAw3uzYACcnR6bOXcPlG7d5c+pPQOQinta1ylOr31hM06S59yukTqk3r0Vi0rpKYbzf/Y71H9sWuVYrloO+01ex+eA/eLi5kCF11J1xO1QvRt/pq5i75XDEji5FcmSkQNb0NBk1DwfD4JX8WfigQ9RL3Mdmx5i5Ww5z5Nx1Ji7aDkDnWiVpXaUwX6zYzdKdx7npF8ilW/78MKQF327Yz9q9pwgPN8mdOQ0Ny+bj7NU7vDl7XURbJnStDcCCrUf48dcDnLlyhxZjFjD/3dacunyLP05cpGf9MrzfoRpvzl5HSFg4bzSzXd5lSo96EfOqPvQ7Jne3XU73w47evDZ5CcGhYbzRtHzEWCLyeC1LZ6X2p7+zepDttY2q+dIzYO5+tpy4joerE+k9ou4Y065sNgbM3c+CP89H7OhSOEtq8r+UiubTd9g6kzMNwxtFXbQbmx1j5u++wJFLfkxe/zes/5tOFbLTsszLhISFs/ffO0xpWyLK+cv3X6ZpyaiXUeo/Zx97zt1h7WEnjl32Z0i9/AxrVIi3Fx4kJMxkQM08ODk6cOSSL7vP3qZ71Vy89fMBsqZxp/XMXbg4GvzcpyLL9l9i7u7zuDg6UDhLahoUy/TM31uxL+O/q0fl+RiGMbB3796TZs2c6WbvuYi1Dh8+TLXq1c/fuXMn+kU1ReKBYRjZ0qZJc/zG5fPa2zGZ+nj8REZ/PG5sWFjY+08/WyR2DMOoWqJYkZV/bf/V095zEfuYs2ARb733wbJbt++0sPdcJPFL6+V5es28r/KULl7E3lORBKRItca+p//5t5Zpmn/Zey6SOLm7ut499eu8FA8XZ4gANOsz3G/jjr3dTNP8xd5zkcQpTeqUp5dPeTtPqQI57T0VSUBKvTrM98zFa3reInGWKoXrtd8mdMmYK1Oap58syUad4T/67jtzpZVpmr/aey6SOKVyc762aUi1jDnT6+0hidTgs22++8/7qC1xpKWR8c8MD4u+7ZwkPeHh2s5TLGeGm6Y+epeMhYeHY2oFq8Q/U/+GJW9qi8QzMzxc/zlJVKb+nZHnZej5ikSnf28kHuh5i0SjX43keRm213DtPQ1JYPTfhMQDtUWi0XPZ56OFMfHv8qFDh0L1hDrpO3r0KA4ODpftPQ9J0q77+/u73Lhxw97zEDvZf+DgPdM01RmJb5fPX7zkEhgYaO95iJ0cPX7SvBt476y95yFJg2EYl479fdre05AExD/gLleu33AD9BxG4szVxfnm8TP/2nsakoCEhITy97kLDqgt8hwcDOPSiXOX7D0NSUD8A+9x9ZaPnrfIc3FydLh24uJNe09DEpD7waH8e93XGbVFnoOTo3Ht5FV/e09DEpD7IWGcvx2otjwHXUopnhmG4ZEqVaqdrVq2zN+9e3dXd3ddCzWpCQ8P58SJE/Tt1y/w7t27TUzT3GzvOUnSlTJlyglZMmcaOH3a1BRp02g7zuQiKCiIX5YtD/nmf99dCrh7t6xpmvrtWuKNYRhGKo+UPxctUrjRR++/myJ1qlRPv5EkCaFhYWzdtjP844lTfALv3StnmuYZe89JEj/DMKqlcHdfO+3j4SkK58+Lg4M2u0vOfP0DGD7u07t/nzm32D/gbhd7z0cSLycnx3YeKdy/mzn6LfdsWV5CZUneAu/dZ+p3i+5t/+vQbv+79+qYphlq7zlJ4mQYRrUUbi5rpwx+LUXBnFn1vCWZ87t7jw9nLbp76vzVxf6B97rYez6SeBmG0SClm/MvU3vVd8/1Uhq1JZkLuBfMpMXbAw+evbYp4H5wc+3YK3FlGEaDlK6Ov3zSpoR7zvQpUVqSt4CgUD5Z/3fg4Yu+mwKCQtWWONLCGAsYhuGZOnXqGU5OTqVN03Sx93ziiXN4eHgWBweHZ/7IlmmaaQBHwzCSyhu7pmEYV27fvj1Ki2LEaoZhGClSpHjH3c2tXbgZ7mnv+cQ780FbHOPQlvAHbXFIMm15hBEaHhZ2xNfPr79pmtfsPRtJegzDcPRImXK8i4tLPdM0k9yFak1MZzPiecuz/dZomuEPnrc4JMG2EG6a5mkfX9/Bpmn+be/JSNJhGEa1NF6eH5mmmdV41h+6RMSER9ryjLc1zTQmODoknd+JYmQYRkBQcPDqu4H3PjBNU9fBkefi7OTUKnWqlEPCw8MzJtmwYGtLeLiZxcHB+PdZH2f4g9dbkkFb7gWHhG4PCLw32DTNIHvPRxI3wzCqpUmV8iMTMytJ+HkLJs7hpq0tz3xTkwe/E5HU2xIQFBy6OvB+kJ63yHMzDKN+Gg+3EaZJZnvPxUomprNpksXBiEtbktz7RDEyDAKDQ8N+vXs/5B0t5pXnZRhG/TQpnEeEm2ROuk9aHvxOZJpZHIw4/E7Eg9+JSNptwSAwJDT817vBYWrLc9DCGIkVwzBGAC+ZpvlGHG5bFFgF5NIKNhF5lNoiIlZQW0TECmqLiFhBbRERK6gtImIFtUVErKC2yIviYO8JSKLRElgSx9seBYKBUvE3HRFJItQWEbGC2iIiVlBbRMQKaouIWEFtERErqC0iYgW1RV4ILYyRpzIMIyeQDdgel9s/WKG3BGgVj9MSkURObRERK6gtImIFtUVErKC2iIgV1BYRsYLaIiJWUFvkRdLCGImNFsDy57xm2RJsK/5ERB5SW0TECmqLiFhBbRERK6gtImIFtUVErKC2iIgV1BZ5YbQwRmKjFXHfwuqhvYCHYRiF4mE+IpI0qC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLvDBaGCNPZBhGZqAIsPl57sc0zXC0Yk9EHlBbRMQKaouIWEFtERErqC0iYgW1RUSsoLaIiBXUFnnRtDBGnqYZsMY0zaB4uC9FSUQeUltExApqi4hYQW0RESuoLSJiBbVFRKygtoiIFdQWeaG0MEaepiXPv4XVQ9uBbIZh5Iyn+xORxEttERErqC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQW+SF0sIYeSzDMNICFYB18XF/pmmGAcuBFvFxfyKSOKktImIFtUVErKC2iIgV1BYRsYLaIiJWUFtExApqi9iDFsbIkzQGfjVN82483qe2shIRtUVErKC2iIgV1BYRsYLaIiJWUFtExApqi4hYQW2RF04LY+RJ4nMLq4c2A0UNw8gUz/crIomH2iIiVlBbRMQKaouIWEFtERErqC0iYgW1RUSsoLbIC6eFMRIjwzA8gBrAyvi8X9M0g4A1QPP4vF8RSRzUFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtImIFtUXsRQtj5HHqA7tM0/Sx4L61lZVI8qW2iIgV1BYRsYLaIiJWUFtExApqi4hYQW0RESuoLWIXWhgjj9OK+N/C6qF1QHnDMNJadP8iknCpLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbRMQKaovYhRbGSDSGYbgBDYDlVty/aZp3gV+Bxlbcv4gkTGqLiFhBbRERK6gtImIFtUVErKC2iIgV1BYRsYLaIvakhTESk1rAIdM0r1k4hrayEkl+1BYRsYLaIiJWUFtExApqi4hYQW0RESuoLSJiBbVF7EYLYyQmLbFuC6uHVgE1DMPwsHgcEUk41BYRsYLaIiJWUFtExApqi4hYQW0RESuoLSJiBbVF7EYLYyQKwzCcgKbAUivHMU3TB9gF1LdyHBFJGNQWEbGC2iIiVlBbRMQKaouIWEFtERErqC0iYgW1RexNC2Pkv6oC/5qm+e8LGGsJ0OoFjCMi9qe2iIgV1BYRsYLaIiJWUFtExApqi4hYQW0RESuoLWJXWhgj/9US+OUFjbUcaGAYhtsLGk9E7EdtERErqC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQW8SutDBGIhiG4QC0wPpruwFgmuY14BBQ60WMJyL2obaIiBXUFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtkhBoYYw8qizga5rmyRc45hJsKwRFJOlSW0TECmqLiFhBbRERK6gtImIFtUVErKC2iIgV1BaxOy2MkUe14gWt1HvEUqCpYRhOL3hcEXlx1BYRsYLaIiJWUFtExApqi4hYQW0RESuoLSJiBbVF7E4LYwQAwzAMbKvmXmiUTNP8FzgHVH2R44rIi6G2iIgV1BYRsYLaIiJWUFtExApqi4hYQW0RESuoLZJQaGGMPFQMcAQO2GFsbWUlknSpLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbRMQKaoskCFoYIw+1BJaYpmnaYewlQAvDMPTfo0jSo7aIiBXUFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtkiDoPwJ56IVvYfWQaZonAV+gnD3GFxFLqS0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLJAhaGCMYhpEPyADssuM0tJWVSBKjtoiIFdQWEbGC2iIiVlBbRMQKaouIWEFtERErqC2SkGhhjAC0AJaaphluxzksAVoahmHYcQ4iEr/UFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtImIFtUUSDC2MEbDjFlaPOAA4AsXsPA8RiT9qi4hYQW0RESuoLSJiBbVFRKygtoiIFdQWEbGC2iIJhhbGJHOGYbwM5AO22nMepmmaaCsrkSRDbRERK6gtImIFtUVErKC2iIgV1BYRsYLaIiJWUFskodHCGGkBrDRNM8TeEwF+QVESSSrUFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtImIFtUUSFC2MkYSwhdVDfwAZDMPIZ++JiMhzU1tExApqi4hYQW0RESuoLSJiBbVFRKygtoiIFdQWSVC0MCYZMwwjA1Aa2GjvuQCYphkOLMW2glBEEim1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLiFhBbZGESAtjkremwHrTNO/ZeyKPWAK0svckROS5qC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLJDhaGJO8tcR2TbWEZCuQ1zCMbPaeiIjEmdoiIlZQW0TECmqLiFhBbRERK6gtImIFtUVErKC2SIKjhTHJlGEYnkBVYI295/Io0zRDgJVAcztPRUTiQG0RESuoLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbJKHSwpjkqyGw1TRNf3tPJAZLsK0kFJHER20RESuoLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbJEHSwpjkqyW2H/6EaCNQ2jCMDPaeiIg8M7VFRKygtoiIFdQWEbGC2iIiVlBbRMQKaouIWEFtkQRJC2OSIcMwUgB1sW0XleCYpnkPWA80tfdcRCT21BYRsYLaIiJWUFtExApqi4hYQW0RESuoLSJiBbVFEjItjEme6gJ7TdO8ae+JPMEvaCsrkcRGbRERK6gtImIFtUVErKC2iIgV1BYRsYLaIiJWUFskwdLCmOQpIW9h9dAaoKphGJ72noiIxJraIiJWUFtExApqi4hYQW0RESuoLSJiBbVFRKygtkiCpYUxyYxhGC5AY2CZnafyRKZp+gNbgUb2nouIPJ3aIiJWUFtExApqi4hYQW0RESuoLSJiBbVFRKygtkhCp4UxyY83cMI0zUv2nkgsLEFbWYkkFt6oLSIS/7xRW0Qk/nmjtohI/PNGbRGR+OeN2iIi8c8btUVE4p83aoskYFoYk/wkhi2sHloJ1DEMI4W9JyIiT6W2iIgV1BYRsYLaIiJWUFtExApqi4hYQW0RESuoLZKgaWFMMmIYhiPQHFhq56nEimmaN4G9QF17z0VEHk9tERErqC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQWyQx0MKY5KUicNU0zTP2nsgz0FZWIgmf2iIiVlBbRMQKaouIWEFtERErqC0iYgW1RUSsoLZIgqeFMclLYtrC6qFlQGPDMFzsPREReSy1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLiFhBbZEETwtjkgnDMAwSYZRM07wEnAS87TwVEYmB2iIiVlBbRMQKaouIWEFtERErqC0iYgW1RUSsoLZIYqGFMclHaSAYOGrvicTBL2grK5GESm0RESuoLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbJFHQwpjkoyWwxDRN094TiYOlQHPDMBztPRERiUZtERErqC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQWyRR0MKY5KMltlVviY5pmmeAq0Ale89FRKJRW0TECmqLiFhBbRERK6gtImIFtUVErKC2iIgV1BZJFLQwJhkwDKMQ4AHstfdcnsMStJWVSIKitoiIFdQWEbGC2iIiVlBbRMQKaouIWEFtERErqC2SmGhhTPKQmLewemgJ0NIwDMPeExGRCGqLiFhBbRERK6gtImIFtUVErKC2iIgV1BYRsYLaIomGFsYkDy2x/VAnZkeBIKC0vSciIhHUFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtImIFtUUSDS2MSeIMw8gJZAO223kqz+XBSkNtZSWSQKgtImIFtUVErKC2iIgV1BYRsYLaIiJWUFtExApqiyQ2WhiT9LUElpumGWbvicQDRUkk4VBbRMQKaouIWEFtERErqC0iYgW1RUSsoLaIiBXUFklUtDAm6UsKW1g9tAfwMAyjkL0nIiJqi4hYQm0RESuoLSJiBbVFRKygtoiIFdQWEbGC2iKJihbGJGGGYWQGigCb7T2X+PDIVlat7D0XkeRMbRERK6gtImIFtUVErKC2iIgV1BYRsYLaIiJWUFskMdLCmKStGbDaNM0ge08kHmkrKxH7U1tExApqi4hYQW0RESuoLSJiBbVFRKygtoiIFdQWSXS0MCZpS0pbWD20HXjZMIxc9p6ISDKmtoiIFdQWEbGC2iIiVlBbRMQKaouIWEFtERErqC2S6GhhTBJlGEZaoDyw3t5ziU+maYYBy4EW9p6LSHKktoiIFdQWEbGC2iIiVlBbRMQKaouIWEFtERErqC2SWGlhTNLVGPjVNM279p6IBbSVlYj9qC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLJEpaGJN0JcUtrB7aDBQxDCOzvScikgypLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbRMQKaoskSloYkwQZhuEB1ABW2XsuVjBNMwhYAzSz91xEkhO1RUSsoLaIiBXUFhGxgtoiIlZQW0TECmqLiFhBbZHETAtjkqYGwC7TNH3sPRELaSsrkRdPbRERK6gtImIFtUVErKC2iIgV1BYRsYLaIiJWUFsk0dLCmKQpKW9h9dA6oLxhGGntPRGRZERtERErqC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQWyTR0sKYJMYwDDdsq/WW2XkqljJN8y7wK9DE3nMRSQ7UFhGxgtoiIlZQW0TECmqLiFhBbRERK6gtImIFtUUSOy2MSXpqAQdN07xu74m8ANrKSuTFUVtExApqi4hYQW0RESuoLSJiBbVFRKygtoiIFdQWSdS0MCbpSQ5bWD20CqhhGIaHvScikgyoLSJiBbVFRKygtoiIFdQWEbGC2iIiVlBbRMQKaoskaloYk4QYhuEENAWW2nsuL4Jpmj7ATmzbdomIRdQWEbGC2iIiVlBbRMQKaouIWEFtERErqC0iYgW1RZICLYxJWqoC50zTPG/vibxA2spKxHpqi4hYQW0RESuoLSJiBbVFRKygtoiIFdQWEbGC2iKJnhbGJC3JaQurh5YDDQzDcLP3RESSMLVFRKygtoiIFdQWEbGC2iIiVlBbRMQKaouIWEFtkURPC2OSCMMwHIAWJLMomaZ5DTgE1LL3XESSIrVFbRGxgtqitohYQW1RW0SsoLaoLSJWUFvUFhErqC1qi4gV1Ba1JanQwpikoxzga5rmSXtPxA6WAK3sPQmRJEptERErqC0iYgW1RUSsoLaIiBXUFhGxgtoiIlZQWyRJ0MKYpKMl8Iu9J2EnS4CmhmE42XsiIkmQ2qK2iFhBbVFbRKygtqgtIlZQW9QWESuoLWqLiBXUFrVFxApqi9qSJGhhTBJgGIaBLUpL7T0XezBN8zzwD1DN3nMRSUrUFrVFxApqi9oiYgW1RW0RsYLaoraIWEFtUVtErKC2qC0iVlBb1JakRAtjkoZi2P6/PGDnedjTEmxhFpH4o7aoLSJWUFvUFhErqC1qi4gV1Ba1RcQKaovaImIFtUVtEbGC2qK2JBlaGJM0tASWmKZp2nsidrQEaGEYhv6bFok/aovaImIFtUVtEbGC2qK2iFhBbVFbRKygtqgtIlZQW9QWESuoLWpLkqH/A5OGlth+KJMt0zRPAj5AOTtPRSQpUVvUFhErqC1qi4gV1Ba1RcQKaovaImIFtUVtEbGC2qK2iFhBbVFbkgwtjEnkDMPIB2QA/rD3XBIAbWUlEk/UlijUFpF4orZEobaIxBO1JQq1RSSeqC1RqC0i8URtiUJtEYknaksUaotIPFFbolBbkgAtjEn8WgBLTdMMt/dEEoAlQEvDMAx7T0QkCVBbIqktIvFHbYmktojEH7UlktoiEn/Ulkhqi0j8UVsiqS0i8UdtiaS2iMQftSWS2pIEaGFM4teKZL6F1SMOAI5AcTvPQyQpUFsiHUBtEYkvakukA6gtIvFFbYl0ALVFJL6oLZEOoLaIxBe1JdIB1BaR+KK2RDqA2iISX9SWSAdQWxI9LYxJxAzDyAbkAbbaey4JgWmaJvAL2spK5LmoLVGpLSLxQ22JSm0RiR9qS1Rqi0j8UFuiUltE4ofaEpXaIhI/1Jao1BaR+KG2RKW2JA1aGJO4NQdWmqYZYu+JJCC6xpvI82uO2vJfaovI82uO2vJfaovI82uO2vJfaovI82uO2vJfaovI82uO2vJfaovI82uO2vJfaovI82uO2vJfaksip4UxiVtLtIXVf/0BpDcMI7+9JyKSiKkt0aktIs9PbYlObRF5fmpLdGqLyPNTW6JTW0Sen9oSndoi8vzUlujUFpHnp7ZEp7YkcloYk0gZhpEBKAVstPdcEhLTNMOBpUALe89FJDFSW2Kmtog8H7UlZmqLyPNRW2Kmtog8H7UlZmqLyPNRW2Kmtog8H7UlZmqLyPNRW2KmtiR+WhiTeDUF1pumed/eE0mAtJWVSNypLY+ntojEndryeGqLSNypLY+ntojEndryeGqLSNypLY+ntojEndryeGqLSNypLY+ntiRiWhiTeGkLq8fbCuQ1DCObvScikgipLY+ntojEndryeGqLSNypLY+ntojEndryeGqLSNypLY+ntojEndryeGqLSNypLY+ntiRiWhiTCBmG4QlUBdbYey4JkWmaIcBKoLmdpyKSqKgtT6a2iMSN2vJkaotI3KgtT6a2iMSN2vJkaotI3KgtT6a2iMSN2vJkaotI3KgtT6a2JG5aGJM4NQK2mqbpb++JJGBLgFb2noRIIqO2PJ3aIvLs1JanU1tEnp3a8nRqi8izU1ueTm0ReXZqy9OpLSLPTm15OrVF5NmpLU+ntiRSWhiTOGkLq6fbAJQ0DCOjvScikoioLU+ntog8O7Xl6dQWkWentjyd2iLy7NSWp1NbRJ6d2vJ0aovIs1Nbnk5tEXl2asvTqS2JlBbGJDKGYaQA6gAr7D2XhMw0zfvAeqCpvecikhioLbGjtog8G7UldtQWkWejtsSO2iLybNSW2FFbRJ6N2hI7aovIs1FbYkdtEXk2akvsqC2JlxbGJD51gT2mad6y90QSgSXYVjaKyNOpLbGntojEntoSe2qLSOypLbGntojEntoSe2qLSOypLbGntojEntoSe2qLSOypLbGntiRCWhiT+GgLq9hbA1QxDMPT3hMRSQTUlthTW0RiT22JPbVFJPbUlthTW0RiT22JPbVFJPbUlthTW0RiT22JPbVFJPbUlthTWxIhLYxJRAzDcAEaA8vsPJVEwTRNf2Ar0MjecxFJyNSWZ6O2iMSO2vJs1BaR2FFbno3aIhI7asuzUVtEYkdteTZqi0jsqC3PRm0RiR215dmoLYmTFsYkLt7ACdM0L9t7IomItrISeTpv1JZnpbaIPJ03asuzUltEns4bteVZqS0iT+eN2vKs1BaRp/NGbXlWaovI03mjtjwrtUXk6bxRW56V2pLIaGFM4qItrJ7dSqCOYRgp7D0RkQRMbXl2aovI06ktz05tEXk6teXZqS0iT6e2PDu1ReTp1JZnp7aIPJ3a8uzUFpGnU1uendqSyGhhTCJhGIYj0BxYauepJCqmad4E9gL17D0XkYRIbYkbtUXkydSWuFFbRJ5MbYkbtUXkydSWuFFbRJ5MbYkbtUXkydSWuFFbRJ5MbYkbtSXx0cKYxKMScNU0zTP2nkgipK2sRB5PbYk7tUXk8dSWuFNbRB5PbYk7tUXk8dSWuFNbRB5PbYk7tUXk8dSWuFNbRB5PbYk7tSUR0cKYxENbWMXdUqCRYRgu9p6ISAKktsSd2iLyeGpL3KktIo+ntsSd2iLyeGpL3KktIo+ntsSd2iLyeGpL3KktIo+ntsSd2pKIaGFMImAYhoGiFGemaV4GTgA17D0XkYREbXk+aotIzNSW56O2iMRMbXk+aotIzNSW56O2iMRMbXk+aotIzNSW56O2iMRMbXk+akviooUxiUNp4D5w1N4TScS0lZVIdGrL81NbRKJTW56f2iISndry/NQWkejUluentohEp7Y8P7VFJDq15fmpLSLRqS3PT21JJLQwJnFoCSwxTdO090QSsaVAc8MwHO09EZEERG15fmqLSHRqy/NTW0SiU1uen9oiEp3a8vzUFpHo1Jbnp7aIRKe2PD+1RSQ6teX5qS2JhBbGJA7awuo5maZ5BrgCVLL3XEQSELXlOaktIjFSW56T2iISI7XlOaktIjFSW56T2iISI7XlOaktIjFSW56T2iISI7XlOaktiYcWxiRwhmEUAjyAvfaeSxKgraxEHlBb4pXaIvKA2hKv1BaRB9SWeKW2iDygtsQrtUXkAbUlXqktIg+oLfFKbRF5QG2JV2pLIqCFMQmftrCKP0uAloZhGPaeiEgCoLbEH7VFJJLaEn/UFpFIakv8UVtEIqkt8UdtEYmktsQftUUkktoSf9QWkUhqS/xRWxIBLYxJ+FqhLaziy1EgCChj74mIJABqS/xRW0QiqS3xR20RiaS2xB+1RSSS2hJ/1BaRSGpL/FFbRCKpLfFHbRGJpLbEH7UlEdDCmATMMIxcwMvAdnvPJSl4sOLxF7SVlSRzakv8UltEbNSW+KW2iNioLfFLbRGxUVvil9oiYqO2xC+1RcRGbYlfaouIjdoSv9SWxEELYxK2FsBy0zTD7D2RJGQJ0EpbWUkyp7bEP7VFRG2xgtoiorZYQW0RUVusoLaIqC1WUFtE1BYrqC0iaosV1JYETgtjEraWaAur+LYXSAEUsvdEROxIbYl/aouI2mIFtUVEbbGC2iKitlhBbRFRW6ygtoioLVZQW0TUFiuoLQmcFsYkUIZhZAYKA7/aey5JyYOtrJagrawkmVJbrKG2SHKntlhDbZHkTm2xhtoiyZ3aYg21RZI7tcUaaoskd2qLNdQWSe7UFmuoLQmfFsYkXM2ANaZpBtt7IkmQoiTJmdpiHbVFkjO1xTpqiyRnaot11BZJztQW66gtkpypLdZRWyQ5U1uso7ZIcqa2WEdtScC0MCbh0hZW1tkOvGwYRi57T0TEDtQW66gtkpypLdZRWyQ5U1uso7ZIcqa2WEdtkeRMbbGO2iLJmdpiHbVFkjO1xTpqSwKmhTEJkGEYaYHywHp7zyUpMk0zDFgOtLD3XEReJLXFWmqLJFdqi7XUFkmu1BZrqS2SXKkt1lJbJLlSW6yltkhypbZYS22R5EptsZbakrBpYUzC1AT41TTNu/aeSBK2BGhl70mIvGBqi/XUFkmO1BbrqS2SHKkt1lNbJDlSW6yntkhypLZYT22R5EhtsZ7aIsmR2mI9tSWB0sKYhElbWFnvV6CwYRiZ7T0RkRdIbbGe2iLJkdpiPbVFkiO1xXpqiyRHaov11BZJjtQW66ktkhypLdZTWyQ5Ulusp7YkUFoYk8AYhuEB1ABW2XsuSZlpmsHAaqC5naci8kKoLS+G2iLJjdryYqgtktyoLS+G2iLJjdryYqgtktyoLS+G2iLJjdryYqgtktyoLS+G2pJwaWFMwtMA2Gmapo+9J5IMLMG2MlIkOVBbXhy1RZITteXFUVskOVFbXhy1RZITteXFUVskOVFbXhy1RZITteXFUVskOVFbXhy1JQHSwpiER1tYvTjrgXKGYaS190REXgC15cVRWyQ5UVteHLVFkhO15cVRWyQ5UVteHLVFkhO15cVRWyQ5UVteHLVFkhO15cVRWxIgLYxJQAzDcMO2Wm+ZnaeSLJimeRfbdd6a2HsuIlZSW14stUWSC7XlxVJbJLlQW14stUWSC7XlxVJbJLlQW14stUWSC7XlxVJbJLlQW14stSVh0sKYhKUWcNA0zev2nkgyoq2sJDlQW148tUWSA7XlxVNbJDlQW148tUWSA7XlxVNbJDlQW148tUWSA7XlxVNbJDlQW148tSWB0cKYhEVbWL14q4AahmF42HsiIhZSW148tUWSA7XlxVNbJDlQW148tUWSA7XlxVNbJDlQW148tUWSA7XlxVNbJDlQW148tSWB0cKYBMIwDCegKbDU3nNJTkzT9AF2Ag3tPBURS6gt9qG2SFKnttiH2iJJndpiH2qLJHVqi32oLZLUqS32obZIUqe22IfaIkmd2mIfakvCo4UxCUc14JxpmuftPZFk6Be0lZUkXWqL/agtkpSpLfajtkhSprbYj9oiSZnaYj9qiyRlaov9qC2SlKkt9qO2SFKmttiP2pKAaGFMwqEtrOxnOVDfMAw3e09ExAJqi/2oLZKUqS32o7ZIUqa22I/aIkmZ2mI/aoskZWqL/agtkpSpLfajtkhSprbYj9qSgGhhTAJgGIYD0AJFyS5M07wOHARq23suIvFJbbEvtUWSKrXFvtQWSarUFvtSWySpUlvsS22RpEptsS+1RZIqtcW+1BZJqtQW+1JbEhYtjEkYygE+pmmetPdEkrElaCsrSXrUFvtTWyQpUlvsT22RpEhtsT+1RZIitcX+1BZJitQW+1NbJClSW+xPbZGkSG2xP7UlgdDCmIRBW1jZ31KgqWEYTvaeiEg8UlvsT22RpEhtsT+1RZIitcX+1BZJitQW+1NbJClSW+xPbZGkSG2xP7VFkiK1xf7UlgRCC2PszDAMA1uUfrH3XJIz0zTPA/8A1ew9F5H4oLYkDGqLJDVqS8KgtkhSo7YkDGqLJDVqS8KgtkhSo7YkDGqLJDVqS8KgtkhSo7YkDGpLwqGFMfZXDNv/DwftPRHRVlaSpKgtCYfaIkmJ2pJwqC2SlKgtCYfaIkmJ2pJwqC2SlKgtCYfaIkmJ2pJwqC2SlKgtCYfakgBoYYz9tQKWmKZp2nsiYouSYRj6uZCkQG1JONSW/7N3lwFRbH0cx7+7NJJiYAAGgt1dKCKi2C12d3d3InZ3d2B397UVu7Bbuhf2eTGwuA+LovcKC57P8+K5zs6ZObt7+O3s7H/OCGmJyBbtIbJFSEtEtmgPkS1CWiKyRXuIbBHSEpEt2kNki5CWiGzRHiJbhLREZIv2ENmiBcSLn/LEvd20hFKpfAT4AWVSui+C8B8Q2aIlRLYIaYzIFi0hskVIY0S2aAmRLUIaI7JFS4hsEdIYkS1aQmSLkMaIbNESIluENEZki5YQ2aIdRGFMCpLJZA5ABuBySvdFUNmJmMpKSOVEtmglkS1CqieyRSuJbBFSPZEtWklki5DqiWzRSiJbhFRPZItWEtkipHoiW7SSyBYh1RPZopVEtqQwURiTshoAu5VKZUxKd0RQiZvKSpbSHRGEf0Fki/YR2SKkBSJbtI/IFiEtENmifUS2CGmByBbtI7JFSAtEtmgfkS1CWiCyRfuIbBHSApEt2kdkSwoThTEpS0xhpX1uAzKgcEp3RBD+BZEt2kdki5AWiGzRPiJbhLRAZIv2EdkipAUiW7SPyBYhLRDZon1EtghpgcgW7SOyRUgLRLZoH5EtKUwUxqQQmUxmA9gDZ1K6L0I8pVKpJLZiL6X7Igi/Q2SLdhLZIqR2Ilu0k8gWIbUT2aKdRLYIqZ3IFu0kskVI7US2aCeRLUJqJ7JFO4lsEVI7kS3aSWRLyhOFMSmnPrBPqVRGpXRHhAREKAmpWX1EtmgrkS1CalYfkS3aSmSLkJrVR2SLthLZIqRm9RHZoq1EtgipWX1EtmgrkS1CalYfkS3aSmSLkJrVR2SLthLZkoJEYUzKaQjsTOlOCBpdBjLIZDKHlO6IIPwGkS3aS2SLkJqJbNFeIluE1Exki/YS2SKkZiJbtJfIFiE1E9mivUS2CKmZyBbtJbJFSM1EtmgvkS0pSBTGpACZTJYRKAYcS+m+CAkplcoYYDfQIKX7Igi/QmSLdhPZIqRWIlu0m8gWIbUS2aLdRLYIqZXIFu0mskVIrUS2aDeRLUJqJbJFu4lsEVIrkS3aTWRLyhKFMSmjHnBEqVSGp3RHhETtAhqldCcE4ReJbNF+IluE1Ehki/YT2SKkRiJbtJ/IFiE1Etmi/US2CKmRyBbtJ7JFSI1Etmg/kS1CaiSyRfuJbEkhojAmZTREGvSC9joD5JLJZLYp3RFB+AUiW7SfyBYhNRLZov1EtgipkcgW7SeyRUiNRLZoP5EtQmokskX7iWwRUiORLdpPZIuQGols0X4iW1KIKIxJZjKZzByoCBxM6b4IiVMqlVHAPqB+CndFEJJEZEvqILJFSG1EtqQOIluE1EZkS+ogskVIbUS2pA4iW4TURmRL6iCyRUhtRLakDiJbhNRGZEvqILIl5YjCmOTnDpxRKpVBKd0R4ad2IVVWCkJqILIl9RDZIqQmIltSD5EtQmoisiX1ENkipCYiW1IPkS1CaiKyJfUQ2SKkJiJbUg+RLUJqIrIl9RDZkgJEYUzyE1NYpR7HgKIymSxTSndEEJJAZEvqIbJFSE1EtqQeIluE1ERkS+ohskVITUS2pB4iW4TURGRL6iGyRUhNRLakHiJbhNREZEvqIbIlBYjCmGQkk8mMgepI0yMJWk6pVIYDR4C6Kd0XQfgRkS2pi8gWIbUQ2ZK6iGwRUguRLamLyBYhtRDZkrqIbBFSC5EtqYvIFiG1ENmSuohsEVILkS2pi8iWlCEKY5KXK3BNqVR+SemOCEkmprISUgORLamPyBYhNRDZkvqIbBFSA5EtqY/IFiE1ENmS+ohsEVIDkS2pj8gWITUQ2ZL6iGwRUgORLamPyJZkJgpjkldDYGdKd0L4JQeBijKZzDylOyIIPyCyJfUR2SKkBiJbUh+RLUJqILIl9RHZIqQGIltSH5EtQmogsiX1EdkipAYiW1IfkS1CaiCyJfUR2ZLMRGFMMpHJZPpAbcA7hbsi/AKlUhkEnEF67wRB64hsSZ1EtgjaTmRL6iSyRdB2IltSJ5EtgrYT2ZI6iWwRtJ3IltRJZIug7US2pE4iWwRtJ7IldRLZkvxEYUzyqQo8VCqV71K6I8Iv24mYykrQXiJbUi+RLYI2E9mSeolsEbSZyJbUS2SLoM1EtqReIlsEbSayJfUS2SJoM5EtqZfIFkGbiWxJvUS2JCNRGJN8GiLdK0xIffYBLjKZzDilOyIIGohsSb1EtgjaTGRL6iWyRdBmIltSL5EtgjYT2ZJ6iWwRtJnIltRLZIugzUS2pF4iWwRtJrIl9RLZkoxEYUwykMlkOkB9YHcKd0X4DUql8itwFaiR0n0RhO+JbEndRLYI2kpkS+omskXQViJbUjeRLYK2EtmSuolsEbSVyJbUTWSLoK1EtqRuIlsEbSWyJXUT2ZK8RGFM8igPvFcqlc9SuiPCb9uFmMpK0D4iW1I/kS2CNhLZkvqJbBG0kciW1E9ki6CNRLakfiJbBG0ksiX1E9kiaCORLamfyBZBG4lsSf1EtiQTURiTPMQUVqmfN+Auk8n0U7ojgvAdkS2pnzciWwTtI7Il9fNGZIugfUS2pH7eiGwRtI/IltTPG5EtgvYR2ZL6eSOyRdA+IltSP29EtgjaR2RL6ueNyJZkIQpj/jCZTCZDhFKqp1Qq3wEPgaop3RdBAJEtaYXIFkHbiGxJG0S2CNpGZEvaILJF0DYiW9IGkS2CthHZkjaIbBG0jciWtEFki6BtRLakDSJbko8ojPnzigMRwL2U7ojwr4mprARtIrIl7RDZImgTkS1ph8gWQZuIbEk7RLYI2kRkS9ohskXQJiJb0g6RLYI2EdmSdohsEbSJyJa0Q2RLMhCFMX9eI2CnUqlUpnRHhH9tF1BfJpPppHRHBAGRLWmJyBZBm4hsSTtEtgjaRGRL2iGyRdAmIlvSDpEtgjYR2ZJ2iGwRtInIlrRDZIugTUS2pB0iW5KBKIz5g2KnsGqEmMIqTVAqlc+Bd0CFlO6L8HcT2ZK2iGwRtIXIlrRFZIugLUS2pC0iWwRtIbIlbRHZImgLkS1pi8gWQVuIbElbRLYI2kJkS9oisiV5iMKYPysfYAxcS+mOCP8ZMZWVoA1EtqQ9IlsEbSCyJe0R2SJoA5EtaY/IFkEbiGxJe0S2CNpAZEvaI7JF0AYiW9IekS2CNhDZkvaIbPnDRGHMn9UQ2CWmsEpTdgENYysxBSGliGxJe0S2CNpAZEvaI7JF0AYiW9IekS2CNhDZkvaIbBG0gciWtEdki6ANRLakPSJbBG0gsiXtEdnyh4nCmD+rIWIKq7TmPhAGlEjpjgh/NZEtaY/IFkEbiGxJe0S2CNpAZEvaI7JF0AYiW9IekS2CNhDZkvaIbBG0gciWtEdki6ANRLakPSJb/jBRGPOHyGSynEB24HxK90X478RWXoqprIQUI7IlbRLZIqQ0kS1pk8gWIaWJbEmbRLYIKU1kS9okskVIaSJb0iaRLUJKE9mSNolsEVKayJa0SWTLnycKY/6cBsAepVIZndIdEf5zu4BGYiorIYWIbEm7RLYIKUlkS9olskVISSJb0i6RLUJKEtmSdolsEVKSyJa0S2SLkJJEtqRdIluElCSyJe0S2fIHicKYP0dMYZV2XQOMgXwp3RHhrySyJe0S2SKkJJEtaZfIFiEliWxJu0S2CClJZEvaJbJFSEkiW9IukS1CShLZknaJbBFSksiWtEtkyx8kCmP+AJlMlgUoAJxM6b4I/73vprJqlNJ9Ef4uIlvSNpEtQkoR2ZK2iWwRUorIlrRNZIuQUkS2pG0iW4SUIrIlbRPZIqQUkS1pm8gWIaWIbEnbRLb8WaIw5s+oDxxQKpURKd0R4Y/ZibjHm5D86iOyJa0T2SKkhPqIbEnrRLYIKaE+IlvSOpEtQkqoj8iWtE5ki5AS6iOyJa0T2SKkhPqIbEnrRLYIKaE+IlvSOpEtf4gojPkzxBRWad8FIKtMJsuV0h0R/ioiW9I+kS1CShDZkvaJbBFSgsiWtE9ki5ASRLakfSJbhJQgsiXtE9kipASRLWmfyBYhJYhsSftEtvwhojDmPyaTydIDpYEjKd0X4c9RKpXRwB6gQUr3Rfg7iGz5O4hsEZKbyJa/g8gWIbmJbPk7iGwRkpvIlr+DyBYhuYls+TuIbBGSm8iWv4PIFiG5iWz5O4hs+XNEYcx/RCaTyWUymT5QBzihVCpDUrpPwh+3i9iprGQymUEK90VIo0S2/JVEtgh/nMiWv5LIFuGPE9nyVxLZIvxxIlv+SiJbhD9OZMtfSWSL8MeJbPkriWwR/jiRLX8lkS1/gCiM+e+0ALyIncJKJpPppHB/hD9IJpPJgZNAfplM5gwcTuEuCWmXyJa/iMgWIRmJbPmLiGwRkpHIlr+IyBYhGYls+YuIbBGSkciWv4jIFiEZiWz5i4hsEZKRyJa/iMiWP0cUxvx33gPFgKqADbAjZbsj/GFuwFngKNAa+JCy3RHSMJEtfxeRLUJyEdnydxHZIiQXkS1/F5EtQnIR2fJ3EdkiJBeRLX8XkS1CchHZ8ncR2SIkF5EtfxeRLX+IKIz57zwECgJvgM5An5TtjvCHHQKuA4WBakjvvyD8CSJb/i4iW4TkIrLl7yKyRUguIlv+LiJbhOQisuXvIrJFSC4iW/4uIluE5CKy5e8iskVILiJb/i4iW/4QURjz33kPpAMyAc5KpfJ1CvdH+IOUSqUS6A1cQqrOfJuyPRLSMJEtfxGRLUIyEtnyFxHZIiQjkS1/EZEtQjIS2fIXEdkiJCORLX8RkS1CMhLZ8hcR2SIkI5EtfxGRLX+Obkp3IK1QKpVKmUy2B5iiVCp9U7o/wp+nVCpjZDJZJ8ASuJjS/RHSJpEtfx+RLUJyENny9xHZIiQHkS1/H5EtQnIQ2fL3EdkiJAeRLX8fkS1CchDZ8vcR2SIkB5Etfx+RLX+GTCo6EgRBEARBEARBEARBEARBEARBEARBEARBEIS0RdxKSRAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQUiT/tWtlGQyWTpzc/M1QPno6GjD/6ZLgjbR0dEJBY4EBAR0VyqVUf9mWzKZzNnS0nJOVFRUVkD23/RQ0BYyGTG6unov/fz8uiiVyhv/blsyXTMzs/kymcw9OlqR7r/qo6A9dHX1AqOjFZuDgoJHKv/l1GUymayspYXF4iiFIjtKpSj4TGNkMlm0rq7ucz9///ZKpfLBv9yWgZmZ6XIZOEdHxxj9V30UtIeurm5wTEzMnsCgoH5KpTLmV9vLZDILczOz9UplTMmYmBj9P9FHQfvo6OiEAWcDAoM6KJXK8KS2MzQw6GJsZDg4UqFILw5s/w5KQF9P71NAQOCI6JiY3UltJ5PJMlmYmW6MjokppIyJ0fuDXRS0iFxHHiFDdjkgKLitUqkMSmo7QwP9LkaGhoOjFIr0f7J/gnbR19P9FBAY/KvZYmFumm59TIyyZIxSHLf8LXTk8jDgbGBw6K8dt+jrdTEyNBDZ8pfR19X9FBAc+svHLebpjDbGKGMKxcQoxXHLX0Iul0fIZFwODAn/peMWXR15C1Njw7FRiuiMf7J/glZR6unqvPcPDhuoVCqP/mhFmUwmNzHSnyGXyZpEx8SYJFcHBS2kBF1duX+UImZFSHjkVE2ryGSywuZGeiujY5Q5lGJSh7+aDBRyuexxYFhU65/dNkomk2UyM9TZGKOkkFIpjlv+FnKZLEIGlwMjon/puAX+xa2UZDKZnqmp6fnatWsXHjVqlKGJifhcS4sCAgIYMGBA6JUrV04GBQXV/d0fsGUyWeV06dIdWr1qpXGJEsXR0dH5r7sqpDCFQsHp02fo07dvUGhoWAWlUnn3d7Yjk8lkpqamO4oVLeI2b7aXsYW5xX/cU0EbfP7ymXYdu4S8fPVqZVBQUN/f3Y5MJithbGx0ZvH8OenKly2Drq7IlrQmKkrBoSPHlMNHj/UPDQ0rpVQqn/3OdmQymdzU1ORYpQrlyk0ZN9rIzNT0v+6qoAW++fnRo9+g0AePHu8MDAxq8yttZTKZsalJuqvNGtXP3bdbJwNjY1E79bcICg5m3JSZYSfOnL8aFBzsrFQqo3/WxtDAoJu5manX5uXzjG2zZ0UmE6Uxf4OYmBgePnlGq279w4JDQlpER8fs+VkbmUxmaWJsfL1zq8bZ2zerr2dkaJAcXRW0QEhYGDMXr4nYc/jkvaCQ0PJKpTLiZ20MDfS7mZmaeG2aM97YJqu1yJa/hDImhofPX9JmwPiw4JDQFtExScoWYxNjo6tNa1bO3atlPQNjkS1/jaDQMCYu2hh26sqtq0EhYUk7btHX62ZmYuy1bmIvY1vrDOJKtb9EjFLJI993tB+3KCw4NDyp2WKZzlD/eofaFbK3qVFWz9BA1Nz9LULDI5iz7UTEvgt37gWHRSTpuEVXR97c1Nhw1erBzY1yZbUSxy1/iZiYGHxefKDr7O2hIeGRdZRK5cnE1jU10l+Ry9qyxdwuNYzTm4hzLH8zpVLJx4BQuszfH/opIGRGaETU+O8fl8lk+Yz0dS5NaFDErLJDJpmujqiL+ZtFKqLZf/tt9OwjD76GRkYXVyqVbzWtJ5PJLNPpy6+3LmWdvUXxTHpGumLc/C1Co6JZeO5dxKEH3+4FR0Yn6bglzr8pjCllZ2d38tmzZyaiyCFti4iIIEOGDOHBwcF5lErlm9/ZhpWV1Z7JkybW7dq1y3/dPUHLjBk7Dk/PmXPDw8P7/U57mUyW0djI6PXn928MjIzEAXNa9vXrV6xtciiio6MNk3IyTxMzM9OVI4YM6jBkYL//uHeCtundf3D0kuUrxkdHx0z8nfYymSyPVXrLW2+e3DPW0xPF42lZSEgIGWzzKKKiotL/SsW4TCarXih/3p3Xzx41FSf0/j4KhYIcBUuFfPz8paxSqfT52foW5mavD2xZlb108SLJ0T1By+w+cITug0Zf+/rNr9TP1pXJZE0qlSmx6tiWZSYiW/4+MTExFHRuEPTM93UtpVJ5/mfrW5iZvt67Ymb20kXyJ0f3BC3jffQMPcd4XvvqF5CUbKleME+OnZe3zhPHLX8hhSKaPG7tQj599U/acYtpute7vQZnL1Ugd3J0T9Aye85cpc/01de+BgQl6bilQqHcq/bP6CWOW/5CMTExlOw0Jej5uy9JOm5Jb2bss3xAswLViudJju4JWmbD8WuMWX346Leg0BqaHpfJZIY6clnw02W9dMyMRQGvIPH96E/5IatDwiMVajMt6OvqTOtWNc+QUXULiQ8fQaXrmivh3jdeD1YqlQs0PS6TyZqUzWG2ake7/OK45S8UE6Ok0vxbQb7fwpN03BLn35RPWefMmTNaFMWkfQYGBlhbW0cAmX93GzKZLFvu3OIL+N/APndujI2N7f7FJqwzZswYIYpi0j4rKysMDAyiAYvf3Ya+nr5trlw5/7tOCVrLIU9uHWNjY5t/sQnrbFmzRomimLQvXbp0WFqYhwOZfrGptX3unDLxRervpKuri032bAqSeLwbERGZPpfdv4kkITXLndOO6OjopGaMtWNuO12RLX8nuVxOLtvsSpKaLZGR6XPZZv3DvRK0VW677ERHxyQ5W3LbZhXHLX8pXV0dbKwzJvm4JTwyKn3ObL96aCykFbmzZSY6JunZkid7JnHc8peSy+XkyJIhycctUYqYjDmziLuz/a1yZrECGVl+sEpGUyODCFEUI3zPLpM5EVHR6WQymdoPy8b6OnY5MpiIDx9BjUNmU0OZ7IefSdb2VobiuOUvJZfLsLM0SPJxi6rdv9mptg22KlWq4O/vn9LdSFSbNm2oUKEC5cqV4+hR6faLCoWC5s2bU7lyZSpXrszz588B2L59O2XLlqVSpUpcvXoVgDVr1mBvb0+VKlWoXbu2artOTk5YWFjg7e2dYJ8PHjygYsWKVK5cGXd3d9Xrc+vWLcqVK0elSpXo1q0bAN++faN06dKYmJhw69Ytte38F++1No2Xqs7VtHqsxKlRoyb9+g8AYNu27ZQtV55KlZ3o26+/ap258+ZRoWIlXKq7qsaPUqlk9JixVHetQVXnanz58oXXr19ToWIlqjpXo5pLdd69e6e2r8QeP3bsOGXKlqN8hYpMmjwFgNOnz2Bjm4OqztWo6lyN4OBg1XZkMtm/f6+1Z6gAULV6Da0eL5GRkfTs0w+XGrVwqVELgIcPH1GsVBmMzCzV+l63QSOquLhStmJlzpw9B8CWbdvJW7AIxUqVUdvuyDFjqVS1Gk2aexAaGqr22Jmz5yhXyQmnatXxaN2WqKgoQHqtKlWtRtXqNViwaDEA8xYsomzFypSvXIUZM2epbUcGvzdt2Xcb0KJowbmGu1aPlfZdulO6QhWca7gzetwktcc2bd2OVVappu3z5y8413DHuYY7ZSs5U7JcZbV1u/bsS4OmHgCcOXee8k4uVKleE4+2HVVjIU5ij2/f5U15JxecXGpy9doNAGbOnqfar7WdPXv3H1RtRyaTIfuX77Y2fQ4BONeqh79/QEp3I1GtO3bDuVY9nGvVwySTDX5+/igUCjzadaaKWx2quNXh+QtfAC5duUpFl1pUdKnFpSvSccvpcxcoXLoimXM4qrZ599591TaLlXOicct2avt88OgxlV3dqeJWhzqNW6heH0192bB5m2pZzvxFmb94mWo7v/tea9sYqVa3Cf4B2jtG5ixejn3RcjRq1VG17J/rN6nkVh/nOo2p79Ge4OAQAFp37U0WhyLMXbJCte6SVeuo4t6QCq51GTFeusX02QuXqOBal6q1G9Gqc09VZgQGBtGmax+q12tG6669NfYnOjqawuWcVft49/4Dbg09cK7TmAnT4z9/LGwdqVa3CdXqNuH85X9Uy3/1/dem8eLSoBX+AYEp3Y1EzV26mjwlq9KoXXe15bv2H8G1URuqN2zN8TMXAPA+eJRK7k1xru/B42cvABgxyZNK7k2pWKsJG3dIdwH45udPebdGWOYqyi2f+6pt1mjcBpcGrXCu70HmvAkvjHZp0IoqdZvj0qAVi1auByAwKJjaLTri0qAVtZq1xy82e+q37kq1+i2pULMxZy+qj5Vfef+1aawAVG/WGf+AX7oFc7LqMGA0VRq1p3KDthw7ewmAHfuPUrFeG6o27sCAcZ6qddv2HUm24s7MW7lRtWzIpFlUb9aZ6s06k6FgJe4+eEx0dDQdBoymerPOtO49nLDwcACOn7tMhXqtqdygLVPnr+D/dRo4lnJ1WlK9WWfGzlwIwNVbPjg1bIdL00406NiX4JDQRPsCv5EtWvRlyLV1H/wDtXesTJi3kuqtelOhcRcWrd8JQFBwKE16jqBGm770GedFTEwMAJv3HqVC4y5UbNKFtTsPALBw3Q4qNe2KU7PueK3YpNpu9Va9sS5Vi73Hz6mWdRw6maoteuDUrDvHz//D/+s8bAoVGnXGtXUfxs1ZDsDZKzfJ7dQI19Z9cG3dh+CQUD5/81f9u2KTLpRrGP8Z+qvvvLZli1un4fgHBf98xRQycdEGanQcRqWW/Vm8eR8Aj168pmyzPqQv01Ct7ws37cW57WBqdR3JizcfAPj0zZ+6Pcbg3HYwS7ceUK07bsE6XNoPoeWgqYSGSdlSq+tI3DoNx7XDMLI7tdDYn+joaEo07MGCjdLn2qJNe3FqPZCqbQYxa81O1Xoj56zGtcMwGvUZzxe/+OPCX/ocQru+N9fsNQX/oJCU7kaiOo5fTM1eU6jZawoZnTviFyj1dc/pq7j3mUqt3lM5eVWaqKfJkFm49ZpM1c7jOH/zIQDD529Stc/q2gWfp68AGL90O9W7T6TVqPmEhkuzvZ+86kOVzuNw7jqeGWsS3ukoMkrBAK+11O47jdp9pwGw+fAF1fbzNezH4u3SOeYizQaplnufShvHuADug+fjHxz68xVTyOR1B6k1eD5Ve3uxdM9ZAK4/eolr/znUGjyfZmOXExwmvd/F2k/CffB83AfPZ8+5WwBMXX+Icl2n4T54Pr1nb1Hb9pX7L7Bw66d6/qOX7yGvxxiGLdmVaH+io2Mo02Uqi3afBiAwJJxGI5fgPng+DUYsxj8oNNG+AMh/4e2XoV2ncGuPXEFAcFhKdyNRi/ZcoHBnT1pO2aBaFh0dQ98Fu3Ebtoy+C3YTHR3Dl4AQao9cQe2RK6g2aBFO/aWJEj77B9No7Gpchyxl+YHLAJy69VS1bsnusxi5UjqPFhgaTpdZ26g7aiWdvbYl6Ms/D1/hOmQprkOW8s/DV2qPeW0/TaV+8wG45/tBtf0KfebRemr8ca4s9n8/IpP9y/O+/7G6E7cQEBKe0t1I1OKD1yjaZxmtvLwTPLbjwgNydZqv+ve28/epNmo9LqM2sPH0XQA2nfGhZP8V1J24hRae8Tnx8M0Xmk7fQb1JW5m/T/p86L7oIDXHbaLGmI2cuuMLwNZz96g7cQt1J26hcO+lLD18Q60Pj99+xWn4WrK2na32OnZdcACHrgtZcui6atmqY7dwH78Z1zEbGb/5rGq59F1a47jQqo+fBvNOExAamdLdSFSv9f9Qe/Ypas06yekHH1TL9996Q8P5Z2gw7wxnHn4EoPvaK+Qfvpelp56o1lMqlUw74EPjBWdpMO80X4Olz6mRO2/hPusktWad5ObLbwD02XAVV88TNJh3mqn71Scq3HntFQ5DEx6/XHjyiaKjD9Bg3mkazDtNSIQi0b6M3X1btV7uwd7ce+uvekwmk37++dFroVUDB2i8+h4BYYqU7kai+u1+Ss2ld2i8+h7TT6jn/+47n8k/VcqIryFRNF59j8ar7+G+7A41ltwBwOvUa5wX3qLx6nsM2vMMgNd+4RScflW1/ouv0mfx2Wf+uC+7Q53ld5lzJuHNaPrsekK9FT7UWX6XM0/9Adjr84Xay+5Sf6UPYw6+UFs/OCKagtOvcvjBN9Wy33n/dX+5RQqJiYlBLv8z9wf7/23/bF+/25cxY8Zgb2+Pn58fLi4uuLq6cvHiRUxMTDh79iyHDh1iwYIFeHp6MnnyZK5cuUJISAhNmjThxIkTAPTq1Yt+/fqpbXfz5s0sW7ZMwx4hY8aMHDhwAHNzc5YuXcqSJUsYNmwY8+bNw9PTk4oVK9KsWTPu3LlDvnz5OHjwIIMGDfrl56ZN0sJYAThz5iy6uvF/oqVLl+LC+XPo6Ojg4dGKy5cvkzNnTnbv9ub8ubM8efKEESNGsWXLJry992BhYcGxo0dU7aOjozl39gxyuZw1a9aybPkKxo0do3o8a9asGh+fNn06O3dsJ3v27JQrX4HevXoC0KhRQ+bMVi9ySI3SwnhZuHgpzlWrsHDeHNUyG5vsnD5+lPqNm6qtu2PrZvT19fH1fUn7zl04dewILs5VaVi/HmUqVFKtd9fHh0ePHnPu1AnmL1zMytVr6d0z/scs+9y5OHXsCIaGhgwfNYadu71p3rQJAPt278TCwkK1rntNN/r06oFSqaSyswutW7YgS5YfXVCgndLCWAFYtmgeRYsUVlumUCjYscsbm+zZAMiYMQMnj0gne1ev28Dbt/GFdM+ev+Djp0+qgw77XLk4eWQ/hoaGjBgznp3ee2nepJFqfU2PN2lYn6nTZ3Lp7AlCQkJp1qotxw7uZVD/Pgzq3weAwiXLUb1a1d96jtogLYyX9SuXAPDC9yVd+wzA0tKCsxcuYmKSjtOH93Ho6HEWLluJ19SJDBsznl2b1wLQpFV7zhzZT9FCBbl8+iiVqtdSbbNQgfycPCh9YRo3eTr2/zfjU8YMVuzbvhlzczOWrVrL0lVrGDqgr8a+tGrRlFYtpIxzrlWPerVrkZqkhTHSolF96rhVZ8jo+DucFStckHOHvQGYMH0WO/ceoK1HU6aPG8kxp0r4B8YXb3Ro1ZxuHdoAUhGQ76vX5M6ZgxN7t2FoaMjICdPYte8gzRrWY/x0L3p37UCp4kUT7c/Gbbuws82u+vf0OQsZ0KsLrs5VaN2lF/cfPiZ/XofYfWz/5eebUtLCWGnesA61a1RjyLipqmUfPn1mx96DHN6+RrVNhULBtDlLOLVnE099XzJ6yiy2rpxPh5ZNmTJqMJGRkZRyqU/zBrUxNUnH3o3LGTp+utq+juxYB8Dp85fZtHOvxv54r1+GhbmZ6t97Dh2jfOkSjOjfg6VrNrFxxx56dWrDtpXzpeOmV2/o1HcYx3dv0Lg9bZIWxsuIPp2xz2GLX0AgNVt2o3rlcpQsUpAzu1ajo6ND697DuXLjDmWKF2bqiH5UO1tGrXhjxijpwoKQ0DAqN2xLoXwO7D50gqyZM7Fq1kRWbNrJ2u176da6KZ6LVrF1yUyyZ8lMpfpt6NG2GeZmpmr9WTJtDEUKxBd5Fi3gyJldawCYOHsJuw4ep02Tuhr7os3SwlgZ1q0NY/p0RKFQULJuOzo3r8fKbXupUakMnZrXY8ysZRw9dwU3p3LMWbWF01sWo6ujQ7mGHWnbyJ2aVcrRs01jlEol1Vr2wqOuK1kyZWCt11hWbVPPjxE92pLbLjt+AUG4t++PS8XSCfqzaNIQiuRTv51EgxpOzBzRR/Vvk3TGHF0/D4B1Ow/y9uPnX37eKSEtjJehnZsxukcrFHjgIr4AAOdMSURBVIpoSjftRafGNclunZEjK6bSrH/8RQMfv/qx98RFTqyZwdNX7xg7fy3rpg9l1uqddGtWG7dKJXHtOIzGNSrx/vM3Hr94w/HVM1i8eR9rvY/RvUUdDi6dDMCZq3fYcuC0xv5sPnAa26zxk3i4VSpFD4+6KJVKqncYSgv3qnz4/I03H75wdNU0jl+6wey1u5jcr/0vP/fklBbGysqx0rkP33ef6T19JZZm6fj41Z9dJ6+wb85QtW1unNwHfT1dXr7/TLfJyzm0YARTe0sXkYSERVCt2wQK2tty79lrHr96z7HFo1my4yjr9p+hW2NXvNbvY+PkPmTLlJ6qXcbTtXF1zE2MVdtftus4TiXyM2tgW9WyFm4VaOFWAZCKjGpXKg5AOiNDDi0Y8cvPNyWlhfEyuIUrI9voooiOpny36XRwr0Dh3Nk5OrsfIBW+7Dl3i5auZUhnpM8Bz4RF/iPb1qJ2+cIJli/efYZieeJnqezZsArVS+fn4KW7ifZn68lr2GaOn8XlwKU7lC2Qi8Eerqzcf54tJ67Srb5Ton3RVmlhrDR2KkLN0nkZtfqQatnR648wNTbg8LQujFp1kKPXH1GzdD72T+4EwMbj13n3VSqKnLvrLJ3cy1KjpCO1RqygUaXCVC1qT9Wi9gB0n7MD97LS7TinbTpBtzrlKZ4nO5qMXXuYjSNaAtBm+iYOTe0CQEBwGA9ffVKtVyCHtaovUzcdl2aJ0VIxMUrkv1LZ9S+2/bN9/W5fGlXIh1sJe0ZvOK22XBEdw54rj8hmFf89ZeGBqxwe74GuXE7VketpWaUQAJ1ci9GtZgm19hM2n2V5r9qYpzNULRvcsBy5rC3xDw6n4ZTtVC2cg2aVCtCsUgFAKiJyL2mvtp1sVqbsG92cVl671ZaPa+mE0x07AkMjVMtaVS1Eh+pFVdt69TkA24zmv/ya/AlpYawMdMtPzowm+IdG0mTBWarks+ZTYDh7br5hR8/KatscW78wpx9+JCA0/mLWQ3feYW6kz45e8RfDvvkWyqP3gRwY4MzjD4FM3e/D6k7lAZjVogQFs1uo9UERHcO+W2/IammMJrWLZmNSo6JqyzT1ZXwD6RblIREK3GefokA29f1ok7QwdgA86+amYJZ0assU0Ur23/tKVnNpli+rdHrsaC/lwdabn3gXEF8oNsTZFrd86jPGlbY1ZVWLvGrL5p97y/JmjmQ1N6D28rt0KGONmWH8b979nbKT08oI/zAFzdfex8negmLZTNjTqSA6chk9tj/m+usgSthI2bfs4juKZlW7C9tv+c8KY3x8fOjUqRNGRkY4ODiwdOlSTp06xYABA8iRIwffvn1j7ty5+Pv74+3tzZw5c/D19aVfv354e3vj6enJoUOH8Pf3Z9y4cdStW5dx48bx4sULvn79yqhRozh16hSHDx9GoVAwa9YsypQpw6ZNm/Dy8lIVnCRm6tSpCdoWLlwYZ2dn3rx5Q8GCBdX2tXv3bi5cuICOjg5Lly4lb968auvv2LHjl18je3vpg8TQMP4DKEeOHKorYf39/bGysuLLly9kyZIFAwMDDAwM+PTpE+GxV7QtXbqUnTt30r59ezp06ABIBQ2JyZAhg+q/DQwMVAdt+fLlIyAgAKVSSUhICBYWFujp6amt/6f4+PjQuUtXjIyMyJMnD0uXLObUqdMMHDSIHHY5+Ob3jTmzZ+HvH4D3nj3MmT0LX19f+vcfyO7dO/Gc6cXhw4fx9/dn7Jgx1K1bh3HjJ+D74gVfv35j5MjhnDp9hiNHjqBQKPCa6Rk7VjYza/Zs7HP/ZKxMm56gbZGixahatSpv37ylQMECavva7b2HixcvoqOjw5LFi8ibN6/a+tu3b/2t12nevPn06NGdY8ePA9JYiWNgoI9cLsfX15d8+fIhk8lwcHDg+g2pinfPnj1YZciAczUXSpYsyfRpU/n+tmdBwUEULFBAbX+JPZ43b14CAgLIlCkTOjo66Ovrx+5jLzdu3MDNzY0Rw4f91nNMCp979+jcrYc0XuztWbpoAadOn2HgkKHksLPjm58fc7w8pfGydx9zvDzx9X1J/0GD2b1jG55eszl89Kg0XkaNpG6d2oybOAlf35d8/fqVkcOHcerMGY4cPSa95zOmUaZ0aTZt2cqsOXOxz50bPz//RPs3dYZngrZFSpSmahUn3r59S4EC+dX2tXvPXi5euiSNlwXzyZvXUW397Vs2JbqvxBw4eIiSJUuwYNFi6ri7M6BfH9KlS6dx3bj3LzAokAL5pS9Lmv7uz1+4SE036RaxtWvVZMToMWqFMdmyZVP9d9x4BKlCs16jJpiamOA1YzqOjg7kzp1L9Zient4f+yLrc+8+XXr0wcjIkDz29ixZMIdTZ84yaOhI7Oxs8fPzY7bnNPwDAtiz7wCzPafh+/Il/QcPZ/e2TcycPY/DR4/h7x/AmJHDqFu7FuMnTeXFy5d8/erHyGGDOH3mHEeOHUehiGbmtMmUKV2STVu3M3vuAnLnzoXfD2aLmeY5K0HboqXLU9WpMm/evqNg/nxq+/Leu5+Ll66goyNn8fw55HV0UFt/+6Z1v/wayZDRo88A0qUzZuK40ZQtLV1Jv2b9Jlo0a8LU6TMTtNm2YzdzveJ/dJw6w4tB/fvgNUe6SiFbtvjPIAN9/QTvr6bHv3z5irW1dfzn3OcvhIeHqz4fL/9zlUIFC/Anb6nmc/8BXXr1x8jIEAf73Cye68Wps+cZPGI0dra2fPPzY/b0yfgHBLJ3/0FmTZ+M78tXDBg2il2b1zFz7gIOHztBQEAAY4YPoU4tN8ZPmYHvy5d8/ebHiMEDOH3uPEeOn0ShUDBzykTKlCrB5m07mb1gEblz5fzhbDHTvOYkaFusnBNVK1fkzbt3FMiXT21f3vsPcvHyFXR0dFg814u8DnnU1t+2fvVvv1bbdnnTpEE9AHLY2qqOWwICArFKb0lYmFQFniljRkCafjk8PBwLix9/4d138BCnDu1TW5bBKv4ky/fZoqkvcd69/4BCocDWRvMJn9/l8+AhXfsOkTIldy4Wz5rG6XMXGTR6AjlssvPN359ZU8YTEBDInoNHmDVlHL6vXjNwxDh2bliJ1/wlHD5+Cv/AQMYM6U+dmq5MmD6LFy9f883Pj+ED+nDm/EWOnDyNQhGN58QxlClZjM07djN70XLsc9qpZq3QZPrsBQnaFqtUnaqVKvD23XsK5HNU29eeA4e5+M81dHTkLPKaRl4He7X1t65Z+suvUeZMGQl7pX611fe3KwsLC8cxj3T8mzWLdYL2cZ9JCoUCc1NTMqRPj4lJ/OfX92Pg2s07hIdHMHTsJDq1aYlHkwZq24qKimL3/oM0qutOQJD0o/SzF74UKSgdzxQrXJBzl66QP68DL1+9oWrtRuTOmYPZU8ZjavrvvlT5PHhMt4EjMTI0JE/uHCzynMjp85cZPG4qdjbZ8PMLwGvSSAICgth7+DheE0fi++oNA8dMZueaxXgtXMGRk2fxDwxk9KDe1KlRjQme8/B99YZvfv4M79+D0xcuc/TkORTR0XiOH07p4kXYvGsfc5asIncOW/x+MLPQ9HlLErQtXrUOVSuW5c27DxTIm0dtX94Hj3Hp6nV05Dos9JxA3jy51dbfunJ+ovtKTOaMGQgLU7865MiJsxgZGuLevAOWFuYsmD6ej5+/kNchF0ZGhhTK58jr2MJM+5zSjGZxxxFxxxQZrBKfun373oM0qZewYE4mk9GwbTdM06VjxvjhONrnwiF3Th48fgqAf2AgNrGfXarjpuBgCuTNk2Bbv+Peo6d0GzoBI0ND7HPasmjqKE5fvMqQSbOwy54VP/8AvMYOxj8wiL1HT+E1djC+r98xaMJMdiyfhdfStRw9fQH/wGBG9etKnepOTJy9BN/X7/jq78/wXp04c+kaR89cRBEdzYxRAyhdrBBb9hxizvL15Lazwe8HswvNWLgqQdsSbk2pUq4Ubz98ooBDbrV97TlyikvXb6Mjl7Ngykjy2udUW3/LYs9E95UY+xy2ABga6KuW5bDRfLyRNXPGRLdz4PhZajlLhd/PfF9TJL8DAMUK5mP2snV0a90UR/ucBAYFE2mVPva7jvotF2Uy6DVyMsbGRkwY1JMyxQur51x4BI65c/y0L7/j3uPndB89AyMDA/LkyM6CCYM5c/kGQ6cvxDabNX7+gcwc2YeAwGD2njjHzBF9ePnmPYOmzmf7winMWrmZo2cvExAUzMhe7antXJFJ81fh++Y93/wDGdq9DWev3OTouSsooqOZPqwXpYvkZ8u+Y8xbvZVcdtl+WOTjuXRDgral6rbDqWxx3n74TIE8OdX2tff4WS7d8JHGyoRBOOayU1t/87yJie4rMXHvV0RkFDmyZ0FPT5fnr97SqkFNAIrmd+D8tdu4OZXDPocNwaFhGOjrYZJOOnmby1b6TiOTydDT1f1uXCX8fpTbTjrO+H5cfk8mk9F7nBfpjAwZ168zZYpKnz/7jp/n5r3H1KhUhiHdWqu12XHoJF4j+/7y89bk3tOX9JwwHyMDfeztsjJ/VC/OXL3DMK+V2GXNhF9AEDOGdCEgKIR9py7jObgzL999ZIjncrbOHsXstbs4euG6NF66euBepQyTl2zC9+1HvgUEMrRTM85cvcvxi9dRRMcwbWBHShVyZOuh08xb701umyz4BSY+W4znyu0J2pZu2hunUoV59/EL+e3t1Pa199RlLt+6j45czrxRPXHMaaO2/saZw3/5NdKP/duNiIrCLmtm9PR00dNLeFr01btP5M1li0wmI49dNm4+kK6EvHL7ARP7tEUul1OldBGu33vCy7cfqVGxJAA1K5di7Lx1dG9RR7WtnUfO0ahGxQT7iIpSsOfERRpUr0hg7Ox6uWyki0fix6OMZ6/fU9hRKiQvmjc3kxb/+vmC/3f/+Rt6TlspjRUba+YNac/ZG/cZPn8TttYZ8QsKZkbfVgQEhbL/3HWm923Fy/efGTpvI1um9mPOpgMcu3yHgOBQhndogHvF4kxZuQvf95/5FhjMkDb1OHvzAcev3EERHcPUXh6UKpCbbUcvMn/LYXJlz/TD2WJmrt+XoG3ZtiNxKp6Pt5/9yJ8zm9q+9p29zuW7j9HRkTN3cHsc7bKqrb9h0u//8L/zxGUaOEsz6x69fAdDA33qD/DE0iwdswe1I72ZCfqxYygoJIz8udS/jxy6cBO38kUBuHTnMa7lpB9+3MoXY9zSbXRr7IqjXVYCg0PJaGmGjo5ctb04hy/eonjenCzZcYxaFYvRu3lN1WPvv/ihiI7GxlrKrLCISGr2mkIGC1Nm9m9NZiuL337uce77vqfPnC0Y6uthny0jc/o24+ztJ4xc5o1t5vT4BYUyrVsDAoLDOHDpLtO6NeTlh68MX7qbTWM7MW/7SY5de0BAcBjDWrlRq1xBpq4/xMuP3/ALDGFQC1fO3X7C8esPiY6OYXKXepTMm4Ptp66zYOcpcmXNgP8PZgCZteVYgrblu02nctE8vPsSQD47a7V97b94hyv3XiDXkTOnT1McbDKrrb9u1K8XnsW9ZxFRCuysrdDTVbs7COGRUTjYSDP8h0dE4T54PhnMTZjRoxGZ00uF2tM3HmHhrtP0bVINtzLS58fpG48o7mDLZ//4z2JrK3OevPlEYqIU0ew9f5t6lYoSGCK9bvbZMvHolTRrQEBwGNkzWf6wL7/r/suP9F2wG0N9XXJny8CcHvU5d+c5I1cdxDaTBX7BYUzr5E5ASDgHrjxgaid3Xn30Y/jKA2wc0Yp5u85x/MZjAkLCGNq8GrXK5GPa5hO8/OjHt6BQBjWtwrm7Lzhx4zGK6Bgmd6hFSUcbtp+5zcI958llbfXjsbLjTIK2FfrMo3Lh3LFjJbPavvZfvs+VB6/QkcuY3aM+Dtkzqq2/dpjHL79GmSxMeBWhPsvy5QcvqV5CKsCuUTIvJ24+oWbpfKrHd5+/y7TO0p0D/nn4irFtaiCXy3EqnIsbT9/gUlw6vo2IUnDr6VsW9ZUuVLvx9C3hUQpGrz5EW9dSNK1SVLXNsNg+ZLSQvgfLZTLCI6Mw1Ndjvvd5utUpR79F3gn6f/CfBxyY0vmXn3ecB68/03f5UYz0dcltbcmsTq6cu/eK0RtOY5PRDP/gcKa0cSYgNJyD154ypY0zrz4HMGLdKTYMrM/8ff9w/PYLAkMjGNKoPDVL2DN9xwVefg7ALzicAfXLcv7+a07efoEiJoaJrapS0j4LOy48YNGBa+S0tsA/JCLR/s3ecyVB20pD11CpgC3vvgWRL3sGtX0duPaEfx69Q0cuw6tjdRyyWamtv6ZfvUT3lZhM5ul4FZnwu/3msz40Lp+PWXsuq5bltrYkJDwKfV0dTAzjj0/XnLjNvn8e4+FUkJZVCvHykz8Rimh6LjlMSHgkE1pWoVCOTOSylrLAQF8nwf7e+wWjiFaSPYN6LqQz1HwcnMUy4TkV/dgsVETHYGpsQHrTpJ/jffAugAGbr2Oop0PuTCbMbF6C848/MXb3HWysjPEPiWRSo6IEhEVy6M47JjUqyquvIYzedZu1ncuz8MQjTtz/QGBYFINq5setUFY8D97j1bdQvoVE0N81HxeefObUgw8oYpSMb1CYEjms2HntFUtOPiZHRhP8Q6MS7d/cow8TtK0y7RgV82TkvX8YebOYqe3r0J23/PPiKzoyGZ7Ni5Mns5na+is7lkvyaxMnZ0bpNTf47jPnxP0PGOnp0GzxOSyM9ZnRtDiW6fSxNk/42h+6+4706fRpMO8MxewsGV23EJbp9DHW1yE6RklAWBSW6aQCCZkMBm+9gbGBDsPdC1Iyp3TudsuVlzQsYcucow809vHw3Xfcee2Hc35r+rlKuaapL3GO+ryneoGE5w5/xcOPoQza+wxDXTm5rAyZUTc3F14EMP6wLzYWBviHKRhfMyeB4QoOP/zGhJo5ee0XztjDvqxqkZfF599y8qk/geHRDKySHde86fE69ZpXfhH4hUXRt3J2Lr4I5PRTPxQxMNbNjuLZTdl95zNLL74nR3pD/H8wW8z8s28TtHVZdJvyOc14HxhJ3kzGavs6/OAbV18HoSOD6XVyY5/RSG395c0cE91XYmTAsP3PMdaTM7SararoZNutT9QvnJF5ZxPO7LLX5wsTasZf3Drr9GuWXXpH9wrZqO4oZcmNN8E0WOlD0WwmjKxuh66OjDwZjAiKiCZSEYOOTIaejnohT04raTwY6MYvt7GMr5/Q15WrZrLzC43i2dcwimXXosKYI0eO0KVLFzp06KCaqnb48OEcO3YMc3NzChdOWPX8vZ49ezJ48GD8/f1xdXWlbt26AGTOnJm1a9fi4+ODj48PZ86c4cuXL7Ro0YLDhw8zffp0rly5QmRkpFrhwPc0tT127BhBQUF06dKF/PnzM27cONW+bty4wbNnzzh//jw+Pj4MHTqUPXv2qK3/vU2bNiWYscXW1pZ16zT/aDlixAj69JGuGLK2tiYwMJD8+fMTFhbGlStXyJAhA2/fvsXPzw9/f3+ePn2Kn58f9evXp02bNoSHh1OzZk0qVKiAo2PSBr6fnx+LFy/mwAFpBgA3Nzfq1q2Lnp4elStXxtbWNknb+S8cOXqMzp060aFDe9VYGTFyJEePHMbc3JwiRYv/sH3PHt0ZPGgg/v7+1HCrSd260kmHTJkzs2bNanx8fLjn48PpUyf58uULHh6tOHToADM8Pbl86SKRkZHkzGWvcdua2h49epigoGC6dO4kjZXxE1T7unHjBs+fPefc2TP4+PgwbNgIvL13qa3/vU2bNrN8hfoU3bY2Nqxdu0Zt2aFDhylXvpzG4oarV6/y/v0HSpcuzdevX7lx4wbh4eHcvHmTN2+k0Prw4SMOjo6cPHGcrt26c/DgIdzda/HPP//Qp28//Pz8OXzoQIJta3q8YYMGuNV0R1dXl44dO2BkZETJkiV49PA+crmcli1bc/z4CVxcqv3wfftdR44ep3PHDnRo1zZ+vIwew9GD+6XxUiLhlXrf69m9K4MH9pfGi3sd6taRvkxkypSJNSuX43PvHvfu3ef08aPSe966HYf272HGzFlcPn9GGi8O+TRuW1Pbo4f2S1nRqQP58+Vj3MRJqn3duHmT58+fc+7UCXzu3WPYyFF479yutv73Nm3ZyvKVq9SW2drYsHaV+hh68/YtHdq3ZcrE8dRt0Igari6qopf/FxkZSfWa7jx6/IQ1KzTPNAXg5++PQx7pByALC3O+fdNcTPbihS9Hjx1nxNAhAGzfvBErKyuu37hB9959OHn0sGpd7z17yWFnS+bMv3TLvyQ7evwEnTq0pUPb1qqxMnLMBI7s98bc3IyipSv8sH2Prp0Y1L8P/v7+uNVpSN3Y2ScyZ8rEmuVL8Ll3H5/7Dzh19CBfvnzFo11HDu3ZieesOVw6c4LIyEhy5dP8Waep7dH93gQFBdO5Qzvy58vL+ElTVfu6cfMWz56/4OyJw/jcu8+wUWPx3r5Zbf3vbdq6nRWr1qgts7HJztoV6j90e06dhJVVel6+ekX9Ji24cfk8kZGR7Nl3gL07tyQojPn69Rt+fn44xP6wfe/+A0xM0pE9W8KCzBe+vhw9fpLhQwZqfA2+f1xXV5d379/h5+ePf4A/T589x8/PnyyxP5xv27GLpo0aaNzOf+XoiVN0bt+a9q1bxo+XcZM4vGcH5mZmFCvn9MP2PTp3YFDfXvj7B+BWvwl1arkBUrasXroQn/sPuHf/IacO7eXL16+07NCVg7u24jlnPhdPHiYyMorcBTV/3mlqe2TPDoKCg+nUvg358zoyfsoM1b5u3LrN8xcvOHv0AD73HzB8zAR2b1mvtv73Nm/byfI16scottmzs2bZQo392b1nP/t3SVM6W2fORGBQMIVKVSAsPJyLJw/j5x+AuVn8l2ULc3O++flrLISIc/uuDzns7DD7v6vy4/j5+bNkxRr27VA/+f99X+Ls2L2HxvXrJrqv33Xs5Bk6tfWgfcvm8WNk4jQO79yEuZkpxSu5/rB9945tGdi7G/4BAdRs1JI6NaX1M2fKwOpFs/F58BCfh484uW8HX75+o1XnXhzYvh7PeYu5eHQvkZFR2BfT/OVYU9vDuzYRHBxCpzYe5M/rwITps1T7unH7Ls99X3Lm4C58HjxkxPgp7Nq4Sm39723esZsV69Rfe5ts2VizeE6SXrt9h44ybpoX+np6DO7b/YfrTvKcw5qNW6lWpRLp0sVfZfLi5SuOnjzDsP69ALh28zZTx42geOGCVKvblBrVqmCV3lK1/sr1m2nVrLHq1k0ABfI5cvLseZo1rMepcxepWFY6Znh0/TxW6S2Zv3QVnvMWMWHkkCQ9r8QcO32OTq2a0c6jsWqsjJrixaGtq6Wx4lznh+27t2/JwJ6d8A8IpFaz9tSpIR1TZcqYgVXzZ+Dz4DH3Hj7hhPdGvnz9RuvuA9i/eSUzFyzjwsEdREZFkaeU5hm2NLU9tG0NwcEhdGzVjPyO9kzwnKfa180793ju+4rTe7fg8+AxIybNZNfaxWrrf2/zrn2sXK9eBG6TLQurF/y8GOLD5898+vyFA1tWsW3PQWbMW0q9WtUxN43PBaVSfYblBSvW0bB2jZ8W2SoUCs5dusrcKWMSPLZlxTys0lty47YPvYaM5diu9Tja5+LiP9cp6uSOjo6cCweliyAiIyNxa9qOx09fsHLe9ATb+h1Hz16io0dD2jWtrxovo2fM5+CGRZibmlDCrdkP23dv05SBXdviHxCEe5se1KkufV5lypielbMmcO/RU+49fsbxbSv48s2P1n1GsH/tAmYuXsN573VERkXhULG2xm1rantow2KCgkPp5NGIfHlyMXH2EtW+bvo84PmrN5zasYp7j54ycto8dq6Yrbb+97bsOcTKTepT/9tks2bVLM0FEaNnLKBnO/VbkFy7fY/3nz5TqmjBH75OANv3H2V0v64A5HfMzb5jp2lSpwYnzl1WFQfVd3Omdpue6Oro0L55A4y+u4gFYNrI/lhZWvDyzTsaderP1UNbkMlk7Dt2hgmzFqOvr8eg7u1+2pffcez8P3RsWoe2jdzjx8rsZexf5YW5iQml6v14v908GjCgYwv8A4Oo3XEgtZ2lH+czZUjPiukjuff4OfeePOfYhvl88fOn7cAJ7F3uyawVmzi7bQmRUQryVmuqcdua2h5YNYugkFA6Nq1LPvscTJq/SrWvm/ce8fzVO05uWsi9x88ZNXMJ2xdNVVv/e1v2HWPVNvXiWZusmVk5fWSCvvQdP4u9x8/SpYV07Jg/T05OX7pO6SL5OXnxqmq92tUqULZBR2JiYpg8qJvaNvYeP4ddNmsyZ0i82C7OmNnL6NG6UYLlU4f0wMrSnJdvP9Ckx3CueK+ieEFH7h7eiFwuo+2giZy8eA3n8lIRxVe/AL4FBJInp02Cbf2O4xdv0L5hDdrWr64aL2Pnr2Pf4gmYm6SjTLMfFwd0bVqL/m2l2wnV7T4G9ypSMUAmKwuWT+zPvacvuf/sJUdWTuOLXwDths9kz8JxzFq9kzPrvYiMUpDfvaPGbWtqu3/JRIJDQunQsAb5ctsyeckm1b5uPnjKi9fvOb56BveevmT03LVsmzNKbf3vbT10mtU7j6gty26dkRWTBiToS78pi9h76jJdmiQ+02AumyzcfPCU8IhIbj98ztuPXwCpoCaukMbcNB1+gUH4BwVjH1tgZW5qwrfviskUimgu3LjHrGHdEuxjze6jeNR2Jjgs4Y+4+05dwjZrJjJbWZIvty0b9h6nf9uGnLx8C/8fFB8l1fErd2lftwptajvFj5Ul29kzeyjmJkaUbZvw7+x7XRq60M/DHf+gEOoP8MS9ovSdJlN6c5aN6sr952948PwNhxeM5It/EB3GLWK312BmbzzAqWVjiVREU7BxwvcG0Nh275yhBIeG0b5uVfLmzMaUlbtU+7r1yJcX7z5xbPFo7j9/w5jFW9k6rb/a+t/bdvQiq/eeVltmk9mKZaO7auzP3jPX2DlTmlX747cAPn8LxHvWYHaeuILX+n1M7tmCyCgFdfpN58mr9ywd2UWt/c4TVxjRQcomv6AQ8thI34/MTYxVt2eq61SS+gM90dXRoW1tJ4z+r/ju7advtHGvzLiuTWgydDYupQuRL7YAZ/fJf2hQNf6c2PElo7EyN+XA+RuMXLiFFWMSjr1fdeL6Q9rWLEfrGmVV42XC6v14T+mOWTojKnT/8fFRpzoV6dPEGf/gUBqOWEKtctLndyYLU5YMasl93/c8ePmBg569+RoQTMdp69g5qRtztp3gxNz+REZFU7jtBI3b1tTWe2oPgsMiaFezPHntrJm6/pBqX7eevObF+68cntWX+77vGbtyH5vHdVJb/3vbT11nzcGLasuyZ7Jk6eBWCfoycMF29l+4S8fa8eedDl7yYcr6g+jr6tKvqXR8f3R2P9KbpePgJR9GL9/DsqGt6VqvMsNb1+RbYAj1hi+ibIGcWJgYs2TPWVYNb8uRf+795F2Kt+7wJVq4lFLdugkgj00mLi9/Trmu05DL5ZyY2z/RvvwbJ28+oW2NkrRyKRk/VtYfZfeE9pgZG1Kx74+L6zu5l6FPw0oEBIfRcNxqapWRzpFmtDBhcb/G3H/5kQcvP3JgSme+BobQaeZWdoxtx9xdZznu2Y1IRTRFOie82AvQ2Hb3hA4Eh0XS1rUUeW0zMW3zCdW+bj97i+/7bxye1oX7Lz8ybu1hNo1srbb+97afuc3ao1fVlmXPYM6S/k1++roFBIdhZiz9+GxuYqh227BvgaH4BYdin00qfouIUqgKr8zTGeEXFP8ZcuLGY6oWtVfN7nzzyRvGt61BkdxZqTNyJS7FHUhvJn3f9g8Ow8w4/pjXPJ0hfkFh6OlG8uLDN0o4JDw2ufviPXaZLNXa/aqTd3xp61yYllUKERMjfc+buPUcO4c3xszYgErD1v6wfUfXYvSuU5qAkHAaTd1BzRLSd9NM5ulY1L0WD15/5uHrL+wb05yvgaF0XnCA7cMaMW/fPxyd0JJIRTTF+i7XuG1NbXeNaEJweCRtnAuTN3sGpu+4oNrX7Rcf8f3oz8FxLXjw+jPjt5xl48AGaut/b8eFB6w7eVttWTYrMxb3+PnMxxFRCg5ee8qmQQ3UCmNqlrCnyoh1xMQoGdtCmvXDvaQ9zSsVIDxKQbPpOyntkA3/4HDuv/rMJc8OBISG02PxIQ6Mjf+ONWnreTq7FVPb597Lj6hXRv080e/w3HWRjad9qFLIjnQGej9vEOv0w4+0Lp8Tj3I5VWNl8j4ftvWshJmRHlWnHfth+/aVctOzmiMBoZE0XXQOt0LSeeyMpgbMb1WKB+8CePg+AO++VfgaHEG3tVfY0r0SC44/4tBAZ6IUMZQcf1DjtjW13d6zMsHhUbQunwvHLGZ4Hryn2ted1374fglhX7+qPHgXwMQ9d1nXpYLa+t/bee0VGy4+V1uWzdKYBa01/wY2Zf9dOjlJfwufAsP5HBTO1u6V8L75mnnHHjK2vubfKj4FhpM7kwm7+zgxaMt1jt//gEt+a7JZGlNh8hFCIxRs7ymNq7H1C5M+nQGvv4XQZtlFTg51IVIRw6G7b9nQpYLGwpiitum5OMoNuQy6r/2HM48+4uT449+E9tx8zeCamn/TSqrTT/1pVSIzzYtnUo2dqcdfsaVNfkwNdXBZdOeH7duVtqZ7xWwEhCnwWH8f17zS98OMJnrMbWjPw4+hPPoUys4OBfkWEkWPHU/Y2DofC8+/Y3/nQkRFx1B2zg2N29bUdkvb/ARHRNOqRGYcMhnjdeq1al933wXj6xeOd8eCPPwYyuRjL1ntkVdt/e/tvvOZjdfVi2ezmuszr6H6RV6ja9iR3liPN/4RtNv0kGPdCxMZreTww2+s9ciboDDmW2gU/mEKcmeQiljal7FmYFUbvoVG0XztfUrbmpLJVJ8LfYqRzkCH8Yd92XbrEx4lMlMzvxUe6x+gK5fRongmjPQSFuIBTDv+mg5l1Y/Dbr0N5lNQJMWyS+cIF194R5dyWTn+OPFJL5LqPyuMad++PRMnTsTDwwM3NzfatGlDRESEaiaCokWLAur3e/r+ROfGjRtZu3YtOjo6vH79WrW8bNmyANy/f58rV65QpUoVAEJDQ/n8+TNZs2bF0NAQQ0PDRItENLUFMDU1VStciNvXkydPKFVKuoq+YMGCvHv3TuP6cTw8PPDwSFqV8JIlS4iMjKRtW2kKzDVr1lCgQAF2797NyZMnGT58OCtXrmTWrFk0aNCArFmzUqxYMTJmzKi6rY6xsTHu7u7cuXMnSYUxERERNG/eHC8vL9X70b17d44cOUKePHlo164d586do1KlSj/Z0n+jfbu2TJw0mZYtW1Ojhitt2rRWHytFpCsoEh8rm1i3fn3sWIn/Iy1bRjpxc//+A678c5WqztKXDtVYyfL9WNH8wa6pLYCpqYn6WInd15MnTylZSjqxVbBgQd69f6dx/TgeHi3w8NB8f+nvLVy4iG3btvDPP+oH1b6+vvTrP4Ddu6T7TVtZWdGnd2/catYib968lCkjfUBaWFhQzVn6gaS6iwv37t/H3b0WpUuX5vKli2zduo3JU6ayYrl6YYSmx/v268+N61extLTE3b0OL1u9xM7OTtWmUaOG3Lx1648VxrRv25qJU6bRsk07arhWp02rlv83XqQP90THy+YtrNuwURovb74fL9Lf+P0HD6X3vLo0O0r8eLGOHy8Omq8Q1tQWYrPiuyKXuH09efqMkiWlqQwLFijAu/fvNa4fx6N5Mzya//jHEZAKV6pVrSJduebkxL37DxItjNHX1+fMiWP4+r6kbsPGuNXQ/MOupYUFAbFXnwcEBJL+ux8f4/j5+dG6fQdWL1+muqLaKna2hxLFixMUFH9S8PqNG8xbuIj93onfB/nfate6FZOmzaBlu07UqF6NNi1bxI4VqU9FCktTSiY6VrZsZ/3GzejoyHn95q1qeZnYv/H7Dx/xz9VrONdwByA0NIzPn7+QxTpL/FjJk8hY0dAWYrPiuyKXuH09efacUiWkE4wFC+Tn/fsPGteP49GsCR7Nfv6F2yr2yno7W1uyZsnKly9f2bJ9B+3btNR4P8ad3ntpUC/+B92pnrOYMXkCkVHq91j18/OnTYeurFq2SDUWfvb4zGlTaNS8JVmyZKFYkcJkzCj9TSuVSo6dOMXUieN++nz+jXYtWzBphhetOnSlhoszrT2aERkZoZqxpEgh6YTd9y/L9+Nl07adrNu0BR0dHd68jR8vZUtJf+MPHj7in2vXca4lXSESGhrG5y9fyGKdWTVe4gqO/p+mtgCmJiZqRS5x+3r67Dkli0tfYgvmzxc/Xv5v/TgtmjaiRdOEP+ho8vjJM9Knt1S9Lms3biF/Xkd2blrLyTPnGDluEvNmTiPgu9vjBAQGkt7S4ofb3bbLm6YN62t8LCIiAo/2nfGcMl5tBpn/70ucHd572bJ2ZZKez69o69GUyTPn0rpLL+lWPM0bExEZqZqhokghKWcTHSM7drN+yw50dOS8efdetbxM7N/2g0dPuHr9JtXqSn+70hj5Stbvx4h9bo1909QWwMQknVqRS9y+nj5/Qcli0vFVwXx5effho8b147Ro3IAWjX+/OK1OTVfq1HTFc+4ilqxcx4hBiV8NP2pwP4b170XjNp25cOUqFcuWxs/fn7bd+rJywSxVZmTJnInypaWMLFG0MM9e+KoKY8LDwzlw5Dh7t6xl3eb4WyQN7deTXoNGsHbTdrJny4J1ZukEZly7Zg3r0qm35mK+X9G2eSOmzF5E6+4DcK1aidZNG6iPlQLSZ3xinz+bd+1l/bbd6Mh1ePMu/t7QZUpI79mDx0+5euM2Lg2kk/ChYWF8/vqNrJkzYWhogKGhAQ651W9LFkdTW4h9778rconb15PnvpQsKn1eFsznwPvvx4pjwsxq0bAOLRr+uPAnMRZmZlQuXwa5XI5L5fJs2u5N2xaNVDP+AGoFMAePneLMxStsW7ngp9s+df4ylcqVUrstaZy49794kYIExRZSzVy4nDbNGtKhZVPWbNqB16IVjBzQE319fU56b8L31RsatOlGDefKCbb3q9o2qcuUectp02cErk7ladWoNhGRUWSI7VeR/FJuq42X727Bvtn7EBt27kdHLufNu4+q5WWKSe/bgyfP+efWXao3k67mDA0P5/NXP7Jkzhg/XnLFH8t/T1NbAFMTY7Uil7h9PX3xipKFpauaCzja8/7TZ43rx2lerybN69VMsFyTZRukoq/WjePHl+/rdwwc78n2ZT+/nWtgUDC+r99SOHaWmJpVK3L+yg1cm3eheOF8ZMkkze4yYJwnVw5sxtLclLrt++Dx5h122eMLgK1iP8/ssmclq3UmvnzzJ6OVJXWqO1GnuhMzF69h6frtDO/dKUnP61e0aViLqYvX0nbgBFwrlaZlfTciI6PIENunwrGzGCU2VrbsO8YG78PoyOW8/RB/gqx0Eenz68EzX67eeYBra+mindDwcD5/8ydLpgwYGhhgaGBAnhyaL6DR1BbANJ2xWpFL3L6evnxDiULSMWwBh1y8+/RV4/pxmtepTvM61ZP0Os0dO4BpQ3tSzaMnrRq40a6xOwMmzaVmu3445rIjg6U5QcGhzFq+ibuHNwLg2qYP9V2dMDYy5IbPIxau28HupT8vflu+ZQ9RUVGqGWm+Z2UpzZRnl82arJkz8MUvgIzpLVSPN6jhxK0HT1SFMd5Hz1Cv+r/PlDit67kwbfkW2g33pHr5ErSs4yxlS2y/CjnEzuL5XZvvP4u2HjrDxn0npGyJLQQBKF1IyqSHz19xzecxbp2kmVpCwyP47BdIlozpMTTQx9BAnzx26kUIcTS1Bem2Ut8XucTt69mr9xQvII3vAvZ2vP/8VeP6cZrVrEKzmlWS9DrNGdGDqQM64tJhKK3qViO7dcKZnqwszOjhUZd6PcbgmNOGUgWlHDHQ00OhiEZXV4fA4FAcc9oQGBSqmvElMDiE9N8VfZ++epsKxQug+/+zR0REcvDsP+yaP5YN+06oPXbz/lMWbdrHznljVM/fuWwxanUZSalCjthk+fczU7Vyr8SMNXvoMG4RLmUK41GzIpFRUWSwkPpe2F76jFA/bolvv/XoRTYdOi8d48b+LQOUKiAdtz588ZZr959Rs9cUQJrF5It/IFkyWMaOFbC31VxAr6ktgImxkVqRS9y+nr35QPG80jFQ/lzZ+fDFX+P6cZq6lqepa/kkvU5PXr0nvZmJ6nWxMDGmYrG8yOVyqpYqyJYjFwBptpAjC0fy8v1nmg6dTfWy0jmqwJAwXr7/TKE80pi1NE1HQOwMHoEhoViaSRfCDZ6zgfOrJmJpmo5Gg7149eELttbxP6hamBhTpWQB5HI5lYvl48GLt/GFMaf+Yd3EXqp1rcylvrpXLM701d5Jep4/08q1NDM2HaXTtHVUK5mXFi6liYhSYGUuXa1bKFf8zFtxvi9r3n7qOpuP/YNcR87bz/6q5SXzSuPs0asPXHv4EvfBUtFEWEQUXwKCyWJlhqG+Hob6euTJrnnca2oLYGJkoFbkErev5+8+Uzz2B//8ObLwIfb2NP+/fpwmVUvQpGqJBMs18erVhEmd6+E2cB4erqXJntGSWuUKUqtcQeZsO86KfRcY7OFK+tj3vVa5gszYJBX0xS1Lb5aO0vly8PztFz58C6RiYXuME5mdQZPwyCgOX7nHtgld2HTsH9XyedtP4lG9NG1qlmP9kcvM236SIS1raOzLv9GyWnE8t56ik9dWXIo50Ny5mDRWYvdTMGf8rFhxvj9u2X7mNptP3kRHLuPtl/gZM0o5Su/Zo9efuP74NbVHShcLhkVE8iUwBOv0pvFjJZvmmfA1tQUwMdJXK3KJ29ezd18pFnsLovx2mfnwLUjj+nGaOBWhiVORJL9W3zM3MVLdfiYwJByL726ltveSD7XLxs/4bqAn3bJLV0eHwNBwHGzi/zZ2nb9L19rxF9ZkTm9KmXzS2C9qn5UXH76qCmMsTIwIDI2f+TUwNAJLUyMmbThG7/oJZzkDaeaaBhV/fOH7z3g4FWTm7st0WbAf58I5aV65AJFR0VjF9quQnfTaJva9eceFB2w5ew8duYx33+K/M5awl8bWo7dfuf7sPXUnShdThUYo+BIYhrVlOgz1dTHU18U+S8Lz24m1BTAx1Fcrconb1/MPfhTLJeVGPpuMfPAL1rh+nMYV8tG4guYLb39mzYk7eDgVVHtdgsIimbfvH/7xkoqS607cSp3SDqpbJRkb6FG9WC7uv/pMXpsMFMqRCQsTQyxMDAmPip/NYvXxW0QqomlRWf2igz1XHrOy7+99z//e4Ibl6V+vLG1meXPl0VvK5k3aTM/Ny+Rg1pH7dFt7Bed81jQtbUekIgYrE6mILO5WOzI0f/bsvPaKbf+8REcm451/fAFZiRzS+cTHHwK58fIbDeadBiA0MpqvwRFYmxtiqKcTO1ON5gv5NLUFMDHUUytyidvX88/BFLWVxl2+rOZ8DAzXuH6cRiVtaVQyaZMYrD3/jCiFkmZlcgBgbqRHefuMyOUynBwzs+Pqq0TbmhnpUclB+ptzcszMo/eB6MllBIZFcWlUDV58DmbY9pts61mZ9LEzx9ikT0cWCyO+Bkey+8YrPMrm1Ph7AkA6g/hzMbWLZsPnjf8PC2OCwqJ49TXkX99GqVmxjMw585aeOx5Txd6SJkUzEqmIIX06qTCrgLWUN2rncr9rv+vOF7bf/oyODLVbBxWPnaXk8edQbr4NovFqqWg1LCqaryFRWJvqY6gnx1BPTi4rzbPiaGoLYGKgo1bkErev59/CVbcNypvZmI9BkRrXj9OgcEYaFP75d4X0xtJrkd3CgCxm+nwLVeB99wvNi2XS+H4evP+NmvmsErRPb6xHCRtTXnwLp2g2E+Le8roFrdh+Szo3NObgC452K4y5oS6tNz7gjX8E2S0M1La/7uoHoqJjaFo0/vP1tV84Yw69YFVz6RzCp6BIXvtHUCSbiXYVxhgZGTF79myUSiX58uXDw8MDfX19vn79irm5ObdvSxWRlpaWqlktbt68qWrv5eXF3bt3CQ4OpmDB+CCOOxmaN29eKlasyJo1awDp6j0dHR3evXtHREQEkZGRPH78WGPfNLX9ftv/vy97e3u2bdsGSDOIxN2qKLErE5M6Y8z+/fs5ePAgu3fH34MvOjpa9QN/hgwZVD9Eu7i44OLiwps3bxgxYgS6uroEBARgbm5OTEwM586dw8XFRWN/vqdUKmnfvj1t27alYsWKasvTp0+PTCbDyspKtd/kYGRkxOxZXiiVSvIXKISHRwv1sXJHqtqztLTgbeyP0zdv3lK1nzV7Dndu3yQ4OJhChYuqlsePFUcqVijP6tXSTBuqsfL++7HyRGPfNLX9ftv/vy97+9xs3y5dUerj40PWLD8bKz+fMSYoKIh379/RqFETvvl949Onz1RxcsLJqTIeLVuxcsVyMmWKD4mWLT1o2dKDGzdusHHTZgAqVa7IrVu3KVOmDDdu3qR4sWJERERgYCCFjoWFBcbG6uGZ2OO6ujqYmZmhq6uLiYkJQUFBqrEIcObsWVyq/ZmiGIgdLzNnSOOlcDE8mjf7v/Ei3VfX0tKCt7E/Tt+8fUvVftacedy5cVUaL8VLqpbLZbHjxdFBes9jZ0+JHy8f4sfLk6ca+6apLZDg3n5x+7LPnYvtO6SiJp9798iaJYvG9eMkdcaYShUrcuv2HWq4VufmrVtUcdJc5BYdHY1SqURXVxczM1O121X8vwrlyzFl2gw6tm/HoSNHKF9OfdaCiIgImnm0ZvKE8WqFZoGBgZiZmfHy5SvVj1G+vi/p2acf3ju2JRh3/yUjI0NmzZiKUqmkQLHSeDRrEjtWvmFubsaduz6AVPTzJvbWDDdvxVcJz563gNtXLxIcHELhkvHPV5UtDnmoUL4sq5ctBuLHyvsP7+PHytNExoqGthA/Nv5/X/a5crF9p/RZ4XPvvmomlf9fP05SZ4yJ+9sNCAjg9Zs3WFml58HDxxw4fJTlq9by3PclvfoNYsEc6SqbHbt2s2TBXFV7X9+XdOzWi/DwMB4+fsLSFatp19qDZq3bMWn8aI1FZBERERofd3GugotzFd68ecvIcRNU4+X8xUuUKF5UlUd/ipGRIbOmTUKpVFKwZHlaNG2Ent5348VHOki1tLDgTWyB7K078ffxnj1/EbcunyU4OIQiZeP/5uLeQ0eHPFQoV4ZVS6QfcOPHy8fY8RLFk6fPNPZNU1tp2/+XLbH7yp0rF9t37wGk2WZU4yWRbPmVGWO27fKmaaP6qn9HR0erfuzPYJWegMBA1S2vvnz9qlrH0PDHVxEdPHyMEYP6J1iuVCrp2L0PbTyaU7Fc2R/2BeDV6zfo6ur+cHaa32VkaIjX5HEolUoKla1Ki8b10dfT4+s3P8zNTLnjI10RYWFhwdvYwpdbd+Kv5puzcBk3zx8jOCSEohXij9ni3hfHPPaUL1OKVQtnA999/nw/Rp6pXyUSR1Nbadv/nynSvnLnzMEO7/2ANNtMVuvMGteP829mjPn+eMLc3IyQ0NCfrqurq4tJOmOMjYyIiIigRYceTBo1BMc88YVBJYsV4dGTZzjY5+Lew0fYZo//sePFy9d8/vKV2k1b8/b9B6IV0ZQuUYxypUqwaeViYmJiaNu9L24uVQkJCcXQ0AAdHR3OXrxM7pw5fvqcfsbI0JCZE0ZIY6WSGy0a1lEfK/ceAmBhYaYqfLnlc1/VfvaSVdw8tZ/gkFCKVXFXLVflSZ5clC9dQjVjiWqsfPxEREQkkVGRPHnuq7FvmtpK29acJ/Y57dixT7rnvc+Dx2RRjZVE8uRfzBhTsWwpps5ZBMDNu/fJaWdDnlw5ePTkOeHhETx/+ZpsWaW/7eu37jJz4XL2bVyRpFsybt9zEI9GmmeSCgwKxszUhJev36p+rIyOjlEVzFhZWfLg8VP14yZTE9WtV/4tI0MDZo4ZhFKppHC1RjSv5yaNFz9/zE1NuPNA+k5raW6qKma4HTuGAOYs38CNI1sJDg2juGt8Uaws9hjBMXcOKpQsxgqv8QBERkahoyPn/cfPseMliicvNJ8g09QWEh5/xO0rdw4bdhyQrta79+ipqtgkseOVpM4Yc+DEWQ6fPs/2pV6qZX4BgbTpM5ylnmPJlIRZPfYdO62aTUfqs4wpw6UivXkrN1K+pFRQqqujg5lJOimHjI0IDlHPrIDAIMzNTAkIDOL1uw9YWZoTERGJQewV/eZmJoSEqd9S7r9iZGiA5/DeKJVKitZqTbPaLujp6fLVLwBz03TcfSQdd1qYm/L2g3Ti6db9+O+5c1dv5dreNQSHhlGiTlvVclW25LKjfPFCLJ82AvhurHz6QkRkJJGRCp76xl+09D1Nbb/f9v/vK7dtdnYeOgVIs81kzWSlcf04SZ0xJiIyEgN9qSjDyMgQI0OpoGfRRGkmsMFT51PHpRJyuQx9PT2MDKXPJ6USFNHRvHzznr4TZrF94RSMjX5y7HLqIkfOXGLrgskaHw8ICsbc1ISAoGBev/+ElYWZahnA+au3qFou/vvozsOnWDhh8A/3+SuMDPSZMagzSqWS4g2706ymE/p6unz1D8TcJB0+j18AYGFmwrvYwpfbD+OPM+at380/2xYQHBZOqcY9Vcvj8t8hR3bKFc3HsgnS8VtkVBQ6cjnvP38jIjKKyKgonr56p7FvmtqCdOuG76mOW2yysOvoOUCabSZLRiuN68dJ6owxEZFRGOjrYWigj7GhQaK3xQJoXqsKzWtV4eaDp2w9eAaA0oXzcuLyTVwrlODs1Tt0a16bLBnT47lyG20buHL0/HXKFo3/0WvnkfM0d6+SYNu+bz/yxS+A+r3G8e7TV6KjoylV0BHrjJb0m7qYrbNHqY3HPq3r06d1ffaduoR1xp/n388YGegzrU9LlEolJVoOo2n1cujr6vI1IAjzdMbcfSZ9RliYGvP2s3Ti+fYTX1X7+VsOc2XdZIJDIyjTZoRqeVz2O9hloWxhB9XsKZFRCmmsfPGTxopCwdPX8YXA39PUVtq25nMsubJlZtdJqQDg/vM3WGew0Lh+nF+ZMWbXySs0rFZG9e8KRRyZsXav9Ho89iVH1kxER8fEHivoYJrOiHRG8d9hD5y7gXul+BlCyxbKg+e6vbSt7cSxy3coW0j6bqyrI8csnRG6ujqkMzIgOFT9M6V8UUfuPHmJS5nC3H7sS6Xi0g8Erz98QVdHhywZpOOXiNgcNtDX4/qD52TJqPnH319lqK/H1K4NUCqVlO48lSZVS6Cvq8O3wBDM0hni80L6u7cwMeZdbDHDnafxF6Ut2HmKi0uGEhIWQblu8QWIcX/vebJnpmyBnCwe1BL4brx8DSQiUiGNl7efNfZNU9vvt/3/+8qVNSO7z94CpNlmrK3MNa4fJ6kzxkREKjDQ18VQXw9jA32M9PVUy0Ca2SMkPJKISKl/Bvq63Hj0iiyx+w8ICcM8nRGRUQpuPXnNsFZunLzxkLO3n3DqxiPuvXhP95mb2Dzux0W4Lz985Yt/MI1HLeX91wAU0dGUdLQjOiaG9ObS+T8rMxMevfqYaF/+DUN9PaZ0ckepVFKm5xwaOxWOHSuhmKUz4N4L6TuzuYlR/Fh5Hn8ByULv81yY14eQ8EjK944/DxX395wne0bK5rdjUd/GQPxY+fAtiIgoBZFR0Tx9F1/Y+T1NbUHT+dvYsZLFCu8L0jnE+y8/Yp3eVOP6cf7NjDFl8tpx8tYTnIrk5tiNx5TNF1/A7n3ehzk966v+XcrRllO3nuJS3IFzd5/TxV06dxkWEcU93w+Ucoz/Mb24fXaevPmMfbYMPHj1iewZLVSPGcXO3PE1duaq6JgYDPX18P3wjUkbpGP7lx/8mLHlJEOaOwNw5OpDBjap8tPn8yOG+rpMbl0VpVJJ2UGraVwhH3q6cr4FSbPm+LySvvtYpDNUFb7c8Y0v7l544Brnp7clJDyKCkPXqJarxkhWK8o4ZmNhN6mAOVIRjY5cxge/EGmMKGJ49kHzD6qa2kLiYyRnZgu8Lz8CpNlmrGNvJZTYGPk3M8Y8fvuVYzefs+7kHXw/BTB49XHGtaiMnq4ORrE5o0SJIjqGwNAIzIwNiIlRcvnhG5wK2pHb2pKAkAgiohSERkShG3v8feTGM47fesG6Aeq3fHrzJRBdHZnG2yP9iogoBQZ6uujqyElnqK8ad0lhqKfDxIZFUSqVVJx8lIYlbNDTlfEtJAIzQz3uv/UHwNxYj/exhS8+b/xV7ZecfMLp4dUJiVDgNPWoannc4YF9ZlPK5MrAvFbSxcyRihhprASEExEVTVR0DM8/aZ6lT1NbgP9/6+P2lTODCXtvSp+LD94FkNnMUOP6cZI6Y8xRn3ccv/+BNZ3iC37L2mdg9hHp3MHd137YWSX+20+53Bm49zaAEjmsuPPGj8LZLYlWKrFMp49MJsMinT7BsQVigWFRmBnpERgWxRu/UNKn0+fJhyCO3/vA+gvPefklhGHbbjKtafzMQ3FtAC49/UJlx4RFhd87fPedamaff8NQT874mjlQKpU4LbhFg0IZ0NeR8y00CjMDXe5/lL7vmxvq8j5QOj/m8z5+5umll95xokcRQiJjqLbwlmp53N++fQYjStmaMaeBdOGYauwERRKhiCEqWsnzr5rPD2hqC+pFOt/vK2d6Q/b7SOfaH34MJbOpvsb14yR1xpjAcAVmhroEhit4GxCBpZEuTz6HceKxHxuvf+SVXwQj9j9nSm3pwop9974yo06uBO0jFTHcfRfCwCoGBIUrMDWU8uiybyA50kvjXEcuw8RAB10dGen0dQiOiFbry7FHfpx84s/K5vEX9vqHKeix4wmz6ucmg4k0hh5+CuVtQAQt19/H91s4Rx/5kS+zMXbpf28Ws/+sMGbTpk2sXbsWpVJJzZo10dXVZcqUKVSvXh07OztVcUmhQoWIiorCxcWFYsXi/1CqVKlCpUqVKFGiBBYWFgm2X7hwYfLnz4+TkxNyuZxy5coxZcoUBg8eTPny5XF0dFSbxSIpbRNTokQJcubMSYUKFZDL5SxdujTRdSHpM8Z07NgRW1tbqlWrhr6+PkePHqVVq1Y0a9YMb29vIiMjWbBA+hGsX79+3LlzBzMzMxYtkk4Ye3l5cfSoFOTu7u4ULy59wWrVqhUXL15k9+7d3LlzhzFjxjBt2jQaN27MkydP2LdvH+/evWPZsmXUrVuXAQMGMGHCBGrXro2+vj5ZsmShRg1pxgsXFxfu37/Pw4cP6dChA126dNHwTP6dTZs2s279epRKJW5uNdDV1WXypEm41nDDztaOrFmlYoG4sVLdtYZqxiEAJ6fKVHaqQvHixRMdK/ny56dKVWfkcjlly5ZlyuRJDBo4kAoVK+Ho4Iidneaqy8TaJqZEiRLkyJmDipUqI5fLWbJ40Q+fe1JmjDE1NeXG9WsAnD59Bu89e6hfvx5Dhw3nzZu39OgpXQ0yetQonJ2r0qJFSz59/kQWa2sWLZJ+1Gzfrh0dOnRiy9atZM+WjYkTxnP+/AXGjB2Ljo4OBvoGrIgt5ujXfwCTJk7g+vUbGh8fMngwTlWqoqOjQ4kSJShYsCBLly5j5apV6OvrU7hwYerX//V7ZibVpi1bWbdhozRearhK42XCeFxr1Y6d9SJ2vBQsKI0XN3eKFo2v0neqXInKzi4UL1YMC3OLBNsvXKgQ+fLmpYqLq/SelynNlIkTGDSgHxWcquLo4ICdrebprRNrm5gSxYuTI0cOKlaRxteShT+eRjSpM8YMGdif9p26MHnadEqVLEnJEiX4+PEjrdp24PaduzRo0ox+vXvhVLkS9Rs3RS6Xo1AomDpJ+hHi6LHjeHrN5tnzF1R3c2f5kkUULlSInDlzUtnZhYwZMrButTQbQ7+Bg5k0fizrN27i1p07jJso/X107tiB5k2b4OzqhrGxMTExMcyeKf0oNmzkKL5986NFa+mE/MJ5czTOkPNvbdoqzfiiVIKbqwu6urpMGj+GGrXrY2tro/rhvFDBAkRFReHqXk814xCAU6WKOLnUpHixolhYJDwpULhQQfLnzUtV11rS+126NJMnjGFgvz5UrOqKg0Me7GwSGyua2yamRPGi5MxhRyVn6XYRi+fP/uFzT+qMMR5tOxEUFIRCoWDKhLHI5XIWzYu/6rp4mYqqopiPHz8REhJKru9+ND5/SvoM8n35kv6Dh9O1U3sWL1vJ7Tt3GT9pKgCdOrTDo1kT+g8exsSxo1i/aWuij9/1uYepqSkL58T/8LVtx26aNPyzt1EC2Lx9J+s2bUWpVFKjejVpvIwdiVv9xtja2KiKSwoVyE9UlALXuo0oGjvrEIBTpQo41ahDiaKFsTDXMF4KFiBfXkeq1qwb+56XZPLYUQzs05NK1WvhYG+Pna3mKyUSa5uYEsWKkMPOjkrVpfG1eK5XouvCr80Ys2f/AY7tiy/obdmsCS3adWLPgUNERkYxb6b0vk4ZP5r6zaSpl6dPGgtIt0saPHIsz1744lq3ERNHj6BMqRJcu3ELhzy51W4XOH3WXBrVq8OTZ8/Zf/gI7z58YPmaddSp5Ub/Xt019gVg+x+6jRLA5p17WL9luzRGXKpIY2TUUNwaeWCXPZuqYKBQ/rxERUVRo0ELihaOv5qrcsVyVHFvRPEihTSPkQL5yO/ogHOdxtL7XLI4k0YPY2CvblSq2QBH+1zY2iQyRhJpm5gSRQuTw86GyjUbIJfLWOQ17YfPPakzxqzfsoMV6zbx5NlzajRowZ7Nq9lz8AhLV69HLpdjaW6uKt4ZPHoCR0+cQaFQ8PTZC+Z7TmbcVC/+uXGTqCgFlcuXoXiRQixZtY7bPvcYP13Kpk5tPGjRuAGTRg+le/9hhIWH06ieO9aZM3HkxCmCQ0JpVNedyyekW0Cu3bQN/8BAypUqwZETp/CctxgZMrp3bEvmTBm5fusO3foPxSSdMaYmJqyY/+O/l6TYsnsf67ftlo5VnJ3Q1dVl4ogB1GzWHtvYWSYACuVzJEqhwK1JW4oWjJ/Zzal8GarW86B44QJqtyWLUzh/XvI52FOtfkvkcjllShZl0oiBDOjRicp1muGQOye22TWfQEisbWKKFylITpvsONVpjlwuY+EMzbe4iZPUGWPWb9vNyg1befLMF7cmbfFev4wCefOQJ1cOqtVvia6uDivnzUBXV5fBvbtSvVFr9PR0WTxTOs7oM3w8oWHh1GslfTfZtmoB6S0tcGvSlgePn/Ho6XPatWhEp9bNiYqK4vK1myzxij+GP3LyLMEhoTRwd6V6o9YYGxkSE6PEa6L0I3uPDq3o0HsI85dJ32dXzZ9BUHAIjdp2l46bohVMHjnop88zKbbsOcyGnfukbKlSHl1dXSYM6UmtVj2wzZaFLJml4pKCefMQFaXArWU3ihaIP0lQuWwJnJt0pFihfJhruB1doXwO5M2TE5emnaT3vHghJg7pzYCubXBq1A6HXDmwzZZFY98Sa5uY4oXyk8MmG1UatZfGy5TEP6sg6TPGdBs6AZus1rh5dENPX4+D6xfhuWg1bz98os9I6XNnRN/OVC1fmiGTZnH0zEUU0dE89X3FvInSjBTb9x9lyrD42ao+fPpC697D0dHVoUyxQvTuIH1/H9S9HdWadkJHR07xwvkp4GjP7XuPuHDtJj3aNqd1nxEEBYegUCiYNLQ3crmcPUdOsWzDduRyORbmpqz0ko7/E+vL79q6X5rxRakE18plpLHSvwu1Ow7AJqs1WTJJF9gUdMiFQqGgVvv+FMkXf9KrcumiVGvVi+IFHLAwS3hiu5BjbvLa56B6K+l5lSlagAkDutC/YwuqNu9Bnpy22GbTfFVfYm0TU7ygIzmyZ6Fqix7I5XIWjP/x31NSZ4zpOdqTV+8+EhkVRbPaLmSwtOD2gycMnjIfHR05dV0qqV6TJu7VcGreHaVSSYMaTpiZpKPH6BlS0dUAqRhs7tgB5LPPQfvBE7l804e9x8/h8+gZI3q2o/uo6WTPkpma7fqjr6fL/lWzuP3gCRev36F7q0a0HTiewOBQFNHRTBzQFblczvYDJ1i94wD6eroUzmtPXRepmPrjl2+EhIaT0+bfn/yNs+3QGTbuO4kSJdUrlEBXV4dxvdpQp/tobLNkUhVUFMyTgyhFNO5dR1Ekb/wJzkolClG94zCK5cuNhWnCk+iFHHKSN5ctNToOQy6XU7pwXsb3bkO/tg1xbjeYPHbZEp3NJLG2iSmW3x67bJmp1m4IcrmMeSN7JrouJH3GmF4TF/D6/ScioxQ0relEBktzPn71o8MIL+4+fkHz/pPp1bIetauWpe3QGXzyC8A6gyVzR/QAYED7RnQaNYvpy7fSxK0yVhZmWFmYkSObNdU7DCWDpbmqGCcqSsE/dx6ycEz8bB5HL1wnJDScBtUrcG6jdHy0fu9xAoJCKFMkL22GTscvIIh2w2YAMHt4d/LltsWt03DkOnIc7LIxY3Dnnz7Pn9l27BKbDp1HqVTiWrYwuro6jO3ahHr9Z2CTOQNZrCwAKJDbhiiFgjp9p1HYIf58a6VieXHtMZlijjkwN0lYNFrQ3pa8ObLh1msycpmc0gXtGde1CX09auHSbSJ5bK3VZkRJStvEFMubE7ssGXHpPhG5TMa8we1/+Nx/ZcaYfWevs39u/PF1vlzZsbe1xq3XZHR1dFg6sgtBoWE0Hz4HuUyOIjqaCd3iz9/sPHmZid/9u6C9LTmyZsK1xyQyWJiyfLR0m6P+Ld1x6zkZuY6c4nlzkj9Xdu48ecmlO4/p2qg6/Tzc6TZlOTPW7qVEvlwUj/273fV/t1H6FhhMkyGzSGdkiK6OnDmD2iXpef7M9lM32Hz8H1CCS6l86OroMKZdbeoPX4xNZkus00vfcwrkzEKUIpp6wxZROHd8AXvFwvbUHDSPovY2mKdLeAV1wVxZyWtnTa3B85HLZJTOl4Mx7WvTp7EzrgPmkCd7JmwyaS4IS6xtYormscHO2ooaA+Yil8mY3Ufz7QLjJHXGmL7ztvL64zeiFNE0rloCK3MTdp6+wcoDF5DLZFiYGLN4kAffgkJoNmY56Yz00dXRYXZvaWyPWraHR68+EB0TQ9ua5cloYcqgFq4MaiHN8Ow+eD6LB0nHLfO2n2TnmRt8DQjm7Wd/1o/uwPFrDwgJi6BepaKcmi8d5288eoWAkDBK589J1owWdPPcyOLdZ1ACSwa1TLQv/8aOs9KML0qUuBR3QFdHh9GtXWkwdhU2GS2wTi99zylgl5mo6Gjqj15FoVzxx6QVCuak1vDlFMmdVfNYyWGNo00m3EcsRy6TUSqvLWNau9K7QSVqDF2KfbYM2HxX/JGUtokpap8Nu8yW1Bi6FLlcxuzu9X/43JM6Y8yWkzdZc/Qqz959of7oVWwZ3ZoaJR059M8Dag5fhn3WDLiWkI77P/kHExoRSQ7r+PHft1Flus3ejufW0zSuXFg1A8zRa49wKa4+E+yYNq70W+hNeGQU9SoUJLOlKcdvPCYkLJJ6FQoytk0NWkzaAMCE9tKtwTeMiC/6qtRvvqoo5uaTN+TJlpF0vzCDkSY7Lzxky7l7KJVKXIrmRFdHzqhmlWg0dTvZM5hhbSEdr+a3yUBUdAwNJm+jcI74H9Mr5rfBfcIWiuTMjLlxwovpCthmxDGbFXUmbEEul1HSPiujm1eiV+1S1By7GfuslthkSPh9+0dtE1M0lzV2mcypOW4TcpkMr44/Pm5N6owxW87eY93JOzz78I0Gk7exeXBDtW07DV+LZ3vpwqtG5fNSY+wmlEoldUs7YGZswNTt5zl19yUArkVzUSSndCzfr14ZGkzejiImhtHNpOfVd9kRsmUwpcHkbejp6rBzuJQD3pcfUbeM+uzTfZcdYW6XGnwKCKHrggP4vPxM61nedKtZklol7Rm94RQnbvuiiJGKjzzbuzB1xwVuPH1PVHQM5fPaqPqSFLuuSzO+KJVKnPNnRldHzojaBWm68BzZ0xuT2VzKiPxZzYmKjqHxgrMUym6hal8+T0bqzjlNERtLzI0SjtsC2SxwsDaj/tzTyGQySuZMz8g6hehZzYHas0+RO7Mp2dNrvjAmsbaJKWJria2VMbVnn0IuA89mP/5cSeqMMf03Xye7pTGNF5xBT0fOtp6VyZvFnNyZTKg/9zQ6OjLmt5SKd8buvs2pBx9RxMTw4nMw05oWo3nZHPTdeI3d11+RxcKYYe7SZBXbr76i3tzThEdFM8xdOsfZbe0VgsKjUEQrGVWnIHK5jBnN4ot/nacfUxXF9N90jdkeJfG+8ZqNl16gpyOnQDZzahbOmmhfALxvvmZ03cRfx6Tyjp3xRamEqvaW6OrIGOpiS4t1D8hurq8qLsmX2RhFtJJma+9T0Dr+vS6Xw5wGq+5ROEs6zAwTlk/kt06HQ0YjGq3yQSaTUcLGlOEutnSvkJV6K3zIncEwwYwoP2ubmMJZTbCxNKDeCh/kMpj+XXGKJkmdMabnjicERUSjiFEy3MUOuVzGtO+2XX3xbVVRzOfgSEIjo9UKUCYcecnjz6HExEDLEpnIYKLHsUd+eJ16jbG+nEwm+syuL13o2LNiVhqtuodcDkWympA3szE+70O4+iqQ9mWyMGjPM7KZ69Ns7X30dGRsbpOfhefe8j4wkuH7pQs7+jllp3JuCyrntgDA69RrClin++2iGADZ/9+3PckNZbI6VatWXX/y5MkklRS3a9eOfv36qRU4CKmHg4NDwJMnT6oplcrrv9M+Q4YM17Zs3lSiWjXnn67bvn0H+vbtI8ZKKrV+/Qb6Dxjo/fXr19/6ZVsmkxWys7M9/+LxQ81Hqv+nfacu9O3dU3ULLiF1MbXMEB4SGppdqVR+/fnaCWXIYHVs8fzZLo2SUJzVvkt3+vbsrlYMI6QeCxYvZdTYiSsCg4J+62ywTCarVKRQwX3XL5xK0nFLh2696NOjq1oxjJB6ZLPPH/zx0+eiSqVS87Q8GshkstYN69ZatHX10iRdFtOhZ3/6dOtE0UIFfr6ykCqUr14n4OqNW42USuWJn61rZGgY8uLmWWMrDbca/H8d+wyldxf1Yhghdbv74BHV6rd85ecfoPnKjO/IZLLenVs2mrFg8sgkfWvvNHAsvTt4UKSA489XFlKFOm17BR49c7GDUqnc+bN1jQwNQp6e3mkcd1ueH+k8bAq92jZRK4YRUjefR89wadX7lX9gUFKypXV9lwqLNnoOS9JxS5cxs+nZsh5FHH98QlVIPZxaDwy45vM4acctBvohD3fPMY671c6PdJ28jJ5Na1A4z0+HoZBK3Hv2mho9J7/yDwpJ0nFL+1rlZ8zu0zRJxy3dZ26kewMnCudO2u0xBO3XeNSSwOPXHibpuMXM2PDjmdk9M+XMYvWzVekxdwfd65SnUK7/rihUSFkX7/nSeurGu18DQzSeaJXJZDaWJoYPni7rlfi0Fd/pueQQ3dxKUCjHj2eWEFK/DC1nKpVK9JRKpWr6CAtj/S1j6xdu1rKc5ttEf6/Phqt0qZKHgt8Vwwhp06zD9/E8dH9ydIxS41U4Mpmsd+uSmWdMq5MrScct/XY/pVPZLBTMkqRYElKBlusfBJ5+6p+k45Y4/9mMMdri0aNHdO2qPgXm0qVLcXQUJxYFdY8ePaJb9x5qy5YsXiTGiqDRo0eP6dZL/YrZJQvmq91GSBAAHj1+Qvfe/dSWLZ4/R+NthgTh0ZOndO+rPnvD4rleOOaxT6EeCdrm0ZNn9BioPhvMIq9parcZEgSAR0+f03Ow+mxkCz0n4GgvfgQVEnr0zJdeI9RvCbNgykgcc+dImQ4JWuvx81f0GjtTbdmC8YNwyPXzKxmFv89j3zf0maR+e855o3rikEP8aC6oe/zqPX1nrFZbNndIexxsNc9qJvzdnrz+SL9529SWzenTlDw2SZ+BQPg7PHnzmf6L96gtm929Hnmy//wqeuHv8OTdNwauPKq2zKujK3my/vvbFQppy9OPQQzeqj5PgGezEthn/nmhsfB3e/oljGH71G+JNa1OLuwzJJwRTUh+yVYYs2bNmmTZj6OjI6dPn06WfQl/xurVq5JlP46Ojpw6+dMLawQttzr2lk9/mqOjA6eOHfn5ioLWWr1scbLsx9EhDyePHEiWfQl/zqolC5JlP4557Dl5cM/PVxS0Ttwtgv40xzy5ObF3e7LsS/gzVs6bniz7cbTPxfHdG5JlX8Kfs8JrfLLsxzF3Do5tXZ4s+xL+jOXTRiTLfhxy2XJ0/bxk2Zfw5yyb0D9Z9uOQIzuHV0xNln0Jf8bSkf/9LdU1cbDNwqEFyZNjwp+zeFDLZNlPHpvMHPBM/PaOgvZb1LdxsuwnT/aM7J/cKVn2Jfy3Fnb7+S1X/wt5sqZn7+jmybIv4c+Y16pUsuzHPrMpu/tUSZZ9CcljToPkuRDVPoMRO9qLGca1lTylO5CS/vSteqKioqhQoQJOTk5UrFiRe/fuATBmzBicnJwoVaoU8+fPB+D06dNkz56dKlWqUKVKFYKDgwHYsGEDpUqVonTp0qxaJRWMhIaG0rhxYypWrMjIkSP/6HMQ4hUr/vP7yv5bVao6Y5k+A97e8T+Szp4zh5y57GnQoJFq2cOHDylWvARGxib4+/urbSMoKIiMmaxV2/j06RNubrWoULESCxct+uPPQVBXrFSZP76P+w8eUKtOPZxd3fD0kn6obduhExWrOFO+chWOHjsOQHR0NJ2796BS1Wp07t6D6GhptsK6DRpRxcWVshUrc+bsuT/eXyFxxctU/OP7uP/gIbXqNaaaW21mzpZ+5JgzfyG58haiQVMP1Xr/XL1OxaquVHWtRd1GzVSfS+/evadhs5a41KzDoGHiMyillKhQJVn24/vyFcYZsnHrzl0AWnfshnOtejjXqodJJhv8/PzZsHmbalnO/EWZv3iZal3rnHmZu3BJsvRVSFwJpxp/dPsPHj3BqVZDqtZuRN3mbfEPCACgXfd+VK7ZgIo16nHs1Bm1Npt37CZjroKqf7fu2pssDkWYu2TFH+2r8GMlq9X9o9t/8PgpVeo2x7m+B/VadsY/IBCAuUtXk6dkVRq1665aNzo6mm4DR1KlbnO6DRypOm7ZuGMP5Wo0pLxbI9Zs2vFH+yv8WKmaf/aE8oOnz6nauAPVmnakXvs++AcEAdC270iqN+tM9WadMXcsh19AIBt37Vctsy9fiwWrNwPw7uNnmnQZSI0WXRgyadYf7a+QuDL1O/zxfVRv1RvrUrXYezz++0znYVOo0Kgzrq37MG6OVAh29spNcjs1wrV1H1xb9yE4JBSAdoMmYFOuDvPXbtO4fSH5lG3W54/vo0bHYWSt1Jx9py4leKxO99EM9lQvHNx66DTZKkuZ9/lbADU7j6B6h6HU7DKSV+8+/fH+CpqVb6dxVv3/lFuvyWR368a+swnvLF+v/wyGzpWKkh+9fEf5dqPI4NwR/6AQ1Trvv/jRYvhc3PtMZfj8TX+8v8LPVewxI1n28/LDVzLVGcidZ28A6bZTVXp74T54PpPWSBdTKaKj6TB1LTUHzaPmoHn4vv+SLH0Tkq5Sv/l/dPuPXn/Cbdgyag1fTtMJawkIDgPg6dsv1Bq+HNchS9h/SfpN6frj17gOWYr7iOU0n7SO4LCIP9o34dc4DV/7R7d//9Vn6k7cQt2JW6g0dA1tZku//Sw+eI2ifZbRyss7QZsdFx6Qq9OfHcPC73GefuyPbv/+uwAazDtNg3mnqTLtGO1XXFR7vOnCs4zaeQuA6BglAzZfp86cUwzYfJ3oGOUf7Zvwa6ovvv1Ht//kcyj1V/rQcJUPrTc8ICBMAUCkIoYR+5/TdM09mq6RPoeefg6j+uLb5Jp4WbVeapTmbqWkTfT09Dh9+rTq/z09PVmzZg2jRo1iwoQJKBQKChUqRLdu3QBo3Lgxc+bMUdvGzJkzuXTpErq6uhQvXpwOHTqwcuVKnJyc6N27N40aNeLu3bsUKlQoBZ6h8F/btHEDy5ar/yDk0aIFdevUYdCgIaplNjY2nD51kvoNGibYxqzZcyhVsqTq39NneNKzZw/c3WvhVKUqzZs1w8rq5/d+FVKPYSNGsWn9WiwsLFTLRo8Yjr19bvz8/Khe0x3X6i4cPHQYM1Mzzp06wcAhwzh46DB1aruzY+tm9PX18fV9SfvOXcTMOGncsFFj2bR2hdp4adG0CXXca6kVuhQrWpjzp6SpRcdPmsqO3Xto17olg0eMZs7Madja2CR314UUMGP2PCqUiy/wW79SKnJ54fuSrn0GYGlpQasWTWnVoikAzrXqUa92LQCmTxqHy8lT+PsHJH/HhWSVMYMVe7eswdzMjGVrNrBs9QaG9OvJqMF9sc+VEz9/f2o09KB6VScAFAoFO/ccIHu2+Knyp48byTGnSvgHBqbU0xCSQUar9OzZsBxzM1OWr9vCsnWbGdK7K80b1qF2jWoMGRc/y8ChE2cwMzHh9N4tDBk7lUMnzlDb1ZnZi1dybv82dHV1KF29Ae08kufqUyH5ZUxvifequdJ42biD5Rt3MLhHe9bOlW4B9eL1W7oPm4iluRktG9amZcPaAFRv1pm6rlUAGDZ5Nl5jB2GbTdyaI61b6zWWVdv2Jli+aNIQiuRTv6VpgxpOzByhXnwxZXAPTpS/in9Q0B/tp6Ad1kwdzKpdCb/3nrt2F10dHbVlCkU0u49dIJu1dBsOI0N91kwbTGYrS45dvMHMVduZN6pnsvRbSH6rx/Vg9Z5TCZafv/kQXZ34602zZ7Li0IIRNB82R229kQs2M6NvS2ysM/zprgpaZs62E5QtoH5L03n9mlE4d/yt5a7c9yWdoQGHZvbh2NX7LNt7jildGyR3V4UUlME8HVtHt8E8nSGrD//DqsP/0L+xExPXH8Wzax1yZbHCfcRy3ErnpXCurByd0RWAaZtPsPfiPTyqFU/hZyAkl/y2GVUz3UzbcYGcmS0AaFQhH24l7Bm94bTa+oroGPZceUQ2K3Hbn79R/qzmqtluZhy8R84MJqrHLj75rHYMc/zee0wNddnXrypjd9/m+L331CiUNbm7LKQQK2M91rXMi5mhLuuvfmT9tY/0qpSNNf98oEIuc6bUjj+WyWquz872Beiw+VEK9vjf0+rCGB8fHzp16oSRkREODg4sXboUT09PDh06hL+/P+PGjaNu3bqMGzeOx48f4+/vT0REBB4eHmzatAkdHR0OHTrEuXPnmDx5MkZGRrx9+5bFixdTunRp1X6+fPlCp06dCAwMxMrKivXr1/P06dME+/4denp6AAQGBlKwoHRVrL6+PgARERHkzJlTtY63tzfXr1+nZs2ajBghTSfq4OBAcHAwBgYGmJpKH2Lnz59nypQpANSuXZsLFy6Iwhik8dK5S1eMjIzIkycPS5csxnOmF4cPH8bf35+xY8ZQt24dxo2fwJPHT6TxEhlBi+bN2bxlCzpyHQ4e3M+5c+eZMmWqNF7evWXRwgUJxkvnzl0JDArEKr0V69at4enTpwn2/TuyZk34gZM5c2bCwsLUlqVLl05j+2/fvvH40WNKl4nv76VLl5g2dQpyuRxnZ2euXr2Gm9ufvXI8NfG5d4/O3XpI7529PUsXLcDTazaHjx6Vxs2okdStU5txEyfx5MnT2JyJpEXzpmzesg0dHR0O7vPm3PkLTJk2AyMjQ96+e8ei+XMpXSp+Wr8vX77QuVsPAoOCsEqfnnWrV/L02bME+/5VL174EhERSftOXQgODsFz+hSKFimCvX1uAAwNDVXrnr94iVqx733tWjU5cuw4dWq7qzIpMCiQAvnz/5uXM83zuXefLj36YGRkSB57e5YsmMPM2fM4fPQY/v4BjBk5jLq1azF+0lQeP32Gv38AkZERNG/amC3bdiDX0eGg9w7OXbjIlBleGBka8u7dexbOnUXpUvGzUn358pXOPXoTFBRE+vTpWbdyKU+fPU+w71/1wteXiMhI2nfpQUhICDOmTKRokcJkzpyJsJcv1daN+2wCCAsPJ6+jAwqFgufPXzB89Hjev3/PiKGDcXGu8rsvZ5rmc/8BXXr1x8jIEAf73Cye68XMuQs4fOwEAQEBjBk+hDq13Bg/ZQZPnj7DPyCAiMhIWjRpyObtu9CR63Bg1xbOXbzM1JmzpbHy/j0LZnlSumT8iY8vX7/SpVf/2GyxZO2yRTx9/iLBvn/HoydP0dfTwyZbws+mbbu8adKgntqyd+8/oFAosLWRTvRlzWL9W/v9G/k8eEjXvkOkv+/cuVg8axpe85dw+Pgp/AMDGTOkP3VqujJh+iyePHuOf0AgEf9j767Dm8i+Bo5/k7pQwd3dXYrUhQKluLu7s8gii7vL4u7uDsXd3aF4C3W3vH9MSRvCLl32t+8u5Xyepw9lcmfuJDm9mcycOTc6hqYNvdm4dScGBmr2bl7DmfOXmDhjLmZmJrx594F5U8dTsVwZbT8fPwXQpc8gQkLDSJfWlpULZ/Hk+Qu9vv+q9OmS5uI2MTZGrVa+YOfPmwcAUxMTnfarNmyhaUNvJs5IunNJ4iVl7tx/RNcBwzEzNaVAvtwsmDqW6fOXcuj4KYJCQhgxsBd13J0ZM3UOj5+9IDg4hOiYGJrWr8PG7XswMDBgz/qlnLlwhUmzF2Jqasrb9x+YN2k0FcqW0vbz8VMAXQYMJzQ0nLS2NqycN5Unz1/q9f1X6cWKSomVTBnSExn5Wqft2YtX8XBRkqk8XR057HOa2m5OFMibh7DwCExMjElj+fVjYqG4+/AJXX8Zg5mpKfnz5GTBxF+ZvmgVh33OEhQSxq99u1DH1Z6xM3/n8XNfgkJClXipW5ONuw4o8bJyLmcuXWfS/GWYmZrw9r0fc8cNo0LppIpPHwMC6frLWELDwkhra8OKGWN5+vKVXt9/Vfq0ttrfTYyNUalVOo9v3XOYhrVcdZa9/eBPXHw8ObNlUY5bXr7m18lzeffBnyG9OuJc7Z+v5vgjuvvoGd1GTMHMxIQCubMzb8wgZizbwOFTFwgODWN4z3bUdqrGuLnLefziNcGhoUTHxNKktgub9h7FQK1m15KpnL1yi8mL1mBmYszbDx+ZPbo/FUomfb/4GBhEt1+nEBoWTloba5ZPGc7Tl2/0+v4eWTPpX3RWqVT0Gj0dCzNTRvftRKXSSjnrPUfPcP3uI9yrV2Jw11Z/uL74urtPXtJjzFzMTIzJnysrc3/tycxV2zl89qoSL12aU8uhEuN/X8/jl28IDg0nOjaWJh72bDp4EgO1mp3zRnP2+j2mLN2sxIv/J2YP60754gW1/XwMDKbHmLmEhEeSzjoNS8f15+mrd3p9f48sGb9+s9CCDXvo0qQWxy7c0C5bu/sojWvaM2WpUk3I0twMS3MzAEyMjVB/MTaJJPeevabHpGXK+5UjM3MGt2PW+n0cuXCL4LAIhravR61qZZmwbDtPXr0nOCyC6Ng4GrlWYcuR8xio1WyfNpBzNx8ydfVuTE2MeecfyMyBbShfNJ+2n49BofScvIzQ8EjSWlmyZEQXnr3x0+v7e2RJb/vV5Qu2HKJTfRdOXL4DgIWZiV6buLh4nr/xY9Tvm3n3MYjBbbxwrFBcr53Qde/FO3rP2oipsRH5s2VgVp8mzNlynCNX7hMcFsmQlh54VinOxDUHePrGn+DwSKJj42joUI6tPlcxUKvZOrYL5+48ZfrGI5gaG/HuUzAzejWiXKFc2n4+BYfRa9ZGQiOiSZvGnEWDW/Ls7Ue9vr/H41cfMDI0IFt6G+0ylUpF/7lbMDc1ZkSbWlQokpucmdISm1gVMTgskrRWcmz7V917+YE+83ZgamxIvmzpmdXdmznbT3P02iOCwyP5pakznpWKMGnDMZ68/UhweBQxsXE0rFGKraduYqBWs2VkG87fe8H0LT5KvASEML2rF+UKJt0Q9ikknN7zdmjj5fd+DXn2LkCv778qXbL33MTIUPuZ4usXSLHcynfkQjky8uxdAAWzZ9C2jYyJpUB2OXb5K+6/8qfPksOYGRuSL7MtMzq6MXfPJY7efE5IRDSDG9hRs1x+Jm89y9P3gQSHRxMdF09DuyJsPXcfA7WKzb804PyD18zYeREzY0PeBYQxtb0L5fInJeF/Comgz5LDhEZGk9bSjIXdPXn+IVCv77/jwNUn7ElMkslobYFvjP4NaRtO3aGhXRFm7Lrwt/r6Wd1/G0z/DVcxNTIgX0ZLpjUtx/xjDzl27z0hkbEMrFkUjxJZmbr/Lk/9wwiJjCU6Lp765XKy/aovBioVG7pV58JTf2YdfoCpkQHvgyKZ3KQsZXMlnRf5FBZN/w1XCY2KJa2FMfNaVeS5f5he33/Hwdtv2ZVsSqglJx/Trno+Tj74AMClZx9xLqqMN67FsnDiwQdJjPkLHnyIYODup5gaqsmbzpQpXvlYeOYNx58EERIVzwCH7LgVTsv0E6949imSkKh4ouMSqFciPTtuf8RArWJtyyJcfBnCnFNvMDVS8z4khom181Ame1JiW0B4LAN3PyU0Oh5bM0Pm1C/Ai4Aovb7/qrQWSdeAjA1VfP5qc/RRIKWzWbLi4ntcC9nSxS4r5sYGf7CVH8t/OjHm0KFDdO7cmfbt25OQkABAjx49GDRoEEFBQbi5ueHlpZT7LliwIKNHj6ZTp068fv2aY8eO0alTJ86dU0pEhYaGcujQIXx9fWnXrh0nTiRl+0+aNInu3bvj5ubG/PnzWbt2LcHBwXp9J9e6dWt8fX11lnXu3JnmzZvrLPP19aVZs2b4+vqyc+dO7fLu3buzY8cOunfvDkD58uV59OgRarWa5s2bc/ToUVxcXKhbty5lypQhISGByZMnAxAYGIi1tTUANjY23L9//++8zKnGocNH6NSxI+3bt0uKl+7dGDRwAEFBQbh71MTLqw4ABQoWYPSokXTq3IXXb95w9MhhOnXuwrlzShnd0LBQDh7cj6+vL+07dOT4saPafiZNnkK3bl1xc3Nl/oIFrF27juCQEL2+k2vTpi2+r17pLOvUsSPNmzf7n74GU6ZOo1+/Puzdt1+7LDo6WnuB28bGmoCAgP9pnz+6Q4eP0qlDe9q3bZMUN926MGhAPyVuatXBq45y92mBAvkZPeJXOnXrrsTNof106tadc+eVA8zQsFAO7tuNr+8r2nfuwvHDB7X9TJo6nW5dOuPm6sL8hb+zdv0GgoND9PpOrk37jvpx06E9zZsmfTF//+EDt+7c5t7N6wQFBdOmQ0dOHU+K12EjRtGrhzLOKGOHFaAbCzExMbjWrMXDR49ZuXTx335NU7PDR4/RsX0b2rdppX3PunfpyMB+vQkKCsKjTn28EqtlFMyfj1G/DqVz9968efOWI/t307l7b85duAhAWGgYB3dvx/fVKzp06cGxg3u1/UyePpNunTvi5uLEgt+XsHbDZkJCgvX6Tq5Nxy68eqV7UbFj+7Y0b9JI+//3H/y4ffsud69fIig4iLYdu3Hy6IE/fL679+5n9NgJGBsbM7h/X/z9P3Lz9h3Wr16GjbUNzh61uXL+lPYiuEhy+NgJOrVrRbtWLZJipVN7BvbpSVBQMB7ejajj6QFAgfz5GDVsMF169eP1m3cc2bOdLr36ce7iJQBCQ8M4sGMzvq9e06F7b47t26ntZ/KMOXTt2A43Z0cWLF7Guk1bCA4J1es7ubade+D7WjdWOrVtTbPGDXSWTZo2k3GjfmXEmPF629ixay97t2/UWbZ1xy4aev+z07CkVkeOn6Rjm+a0a9FU+55169CGAb26EhQcTM0GLahTUzlxUiBfXkb+0p8ufQfz5u07Du/cSJe+gzl/6QoAoWFh7N+6Ft/Xb+jYawBHdyVNCTFl9ny6dmiNq6M9C5auZN2WHYSEhOj1nVzbbn159eaNzrKOrZvTrKH+nYyBQUEsWrGG3Rt1Swj/Om4yPTspFyOio6PZvf8QO9ev0EmMESlzxOc0HVs2oW3zhkmx0q4FA3p0JCg4BM8m7ajj7gxAgby5GTmoN10HDOf12/cc2rqargOGc/7yNQBCw8LZt3E5vq/f0qnvUI5sX6PtZ+rcxXRt2wJXh2osXL6W9dt2ERwSqtd3cu16DuLVm3c6yzq0akKz+nX02gYGBbNo1Xp2rf3j446g4GCsE28MsLa2IjCx+lQdD2cqutYlIUHD+F8H/pWX76dz+NR5OjSvT9vG3knx0roxA7q0ISg4lFqtu1PHVUk+KpAnJyP6daXbkLG8efeBQ+sX0W3IWM5fVcr2hoWFs2/1fHzfvKfzoNEc3pj03k1duJIurRrhWqMKC1dvYv3O/QSHhun1nVz7/iN49ea9zrIOzevTtG5NvbaBwSEsXruVnStm6yzfcfAYu1fqjiPb9h2hvqcLAP4Bgdy6/4g18yZiY5UGt6adubhvvRy3fMWRM5fo0LgObRrU0r5fXZvXo3+HZgSFhFK7wwBqOylTfhbInZ1fe7Wn+4gpvHnvz4GVs+g+YgrnrysXh0PDI9izdBqv3n6g87BJHFqd9L5NW7yOLs28calWkd/XbWfD7iNKrHzRd3IdfhnPq7cfdJa1b1yHpnVc9dp+aeLg7qSzteblm/c06j6UizuXU7Z4IW4fXIdaraLNwLEcP3cFJ7vy39yWSHL03DXa1Xenjber9j3r0tiTfm3qExQahle3kdRyUJLQCuTKxvCuzekxZi5v/D6xf9F4eoyZy4WbDwAIi4hk94LfePXen66jZnNgyQRtP9NXbKVTY09cqpRl0aZ9bNx3guCwCL2+k+v46wxev/fXWdaugTtNajp883kdOnOFSqUKY26WdHNJdEwse3wusHX2SG1iTPLHJvy+ntnDu6fshfsJHb14m3ZeDrSuba99vzrXd6Fv81oEhYbj3X8qtaopSf/5c2RmWIf69Jy8jLd+AeydPYSek5dx4c5jAEIjotg5YxCvPnyi24Sl7J87VNvPjLV76VTPGeeKJVi87SgbD58jJCxSr+/kOo9dxKsPn3SWtfNyoLGb3Tef1+HzN6lUvAAWpvrJMMl9DArl9tNXrPitB9aW5tTqPZEzy8fI59A3HLv6gDY1q9DKvbL2vetYpxq9GzkRFBZB/WG/41lFSTDKly0DQ1vVpPesjbz9GMTuST3oPWsjF+8/ByAsMprt47vyyi+QHjM2sHdKUjLdzM3H6Fi7Gk7lCrNk92k2H7tCcESUXt/JdZm6ltd+gTrL2nra0chR96Ll9E1HGdm2FmMTp0wCGNepLmmtLPD9EECz0Us5s2AQmWzTEBoRRaXOE4mMjuXY7H7/mxfxJ3L8+mPauJenpUv5pHipVYne9asTHBZJ/dEr8KxUBID8WdMzpJkzfebt4O2nYHaN7UCfeTu4+EC5xhMWGcO20W157R9Mjznb2DO+o7afWdtO0aFmJZzKFGDJvgts9rlBSES0Xt/JdZ25hdcfdRMW2rhVoJF9Kb22QWGRLD9wkU0jWwOQoEmaysTawpTAUGXqx/0X7zNxw1GMDQ3oW7/G33npfjrHb72gjVNJWjiUICFxqpgObmXoVaciweFRNJi4lZrl8gOQL7MtvzSsSt8lh3gbEMrO4Y3pu+QQlx69BSAsKoatQxry+lMIvRYdZNevSefqZ++5RAfX0jiWzM3Sw9fZcvaeEitf9J1ctwX7efNJt3pua6dSNKxaRK/tnZd+5MxgjZX5H38GRcfGsf/KE9YPrCeJMd/J58EHWtnloXmVPNr3rF31fPRwLkRwRAyNF5zGIzF5JF8GSwZ5FqP/hqu8C4pkW097+m+4yuXnyvR4YVFxbOpWndeBEfRZd4Udve21/cw9+oB21fLiUCQzy089YetlX0KjYvX6Tq7nmku8CYzQWdbSLi8NyufUa3v3TRA501mQxky5Pnjs3jsq5Emnk+AQFBmLVeLj1mZGBEXE/J2X7qfj8ySIluUy0bRsRu371bZiZrpVy0ZwZBzN19zDrbCSDJU3nRkDHHMwaNdT3oXEsLltMQbtesqVV0rV0rCYeNa3KsKb4Gj67XzK1nbFtP3MO/OGNhUyY5/fhpUX37P9lj8hUfF6fSfXe/tj3gbrvp8tymWkXskMem2DIuNYc/kDq1sUBuBdSAzNypozxDknbdY/wCG/DYUymv9vXrR/2X86MaZdu3aMHTuW5s2b4+HhQevWrVm3bh2rVq3CwMCAV8kuGJcqpRxQZMuWjZIlS2p/DwgIwNramjJlyqBWq8mdOzdBQUE6/dy7d48LFy4wYcIEoqKi8PLyomvXrnp9J7d69eoUPYecOXNy9uxZLl68yC+//MLRo8oF6wULFjB9+nSqVatG27ZtyZFsSoqGDRty/fp1KlWqxOTJk3n06BEADg4ONGjQAFtbW4KDg0mfPj3BwcGkTZv2q33/bNq1bcPYceNp0aIV7u5utG7dinXr1rN6zZrEeEm6CFgqWYyUTKy2kzxeSpcu/Yfxcv/efS5evMjESZOIioqiTp06dO3SWa/v5FatWvmPPneA9+/f8/LFS8qXL6+TGGNiYkJcXByGhoYEB4dQpLD+AdXPrF2bVoydMIkWrdvi7uZK65YtWLdhI6vXrlPi5nXyuEmMlaxZKVmiuPZ3bdyUKpUYN7n04+b+fS5eusTEKVOVuKldi66dOur1ndyq5brTan2NjbU1ZUqVwtbWFltbW6KiorSP/b54CTExMbRp1RIgcexQDrKDg0O0Y4exsTEnjx3hxYuXeNVviIf738taT83atmrJuElTaNG2I+6uzrRu0Yx1G7ewZt0GDAzUvHqddPE4KUayUKJ4Me3vAQFKglLpUiWVeMmVS2+qmXv3H3Lx0hUmTZ1OVFQ0dWrVpEvH9np9J7dq6bcrm9lYW1O6VElsbW2wtbXRiZev8artiVdtT6ZMn8XCxUvp36cnefPkJk/u3MrzyZaNjx8/kTGj/sHUz65ti2aMmzKdlu274O7iRKvmTVi/eRur12/EwMCA18kSDUqVUOIja5YslCxeVPt7YGAQVlZWlClVIjFWchIcrBsr9x885OLlK0yaPkuJFU93urRvq9d3cisXz//m/t+8fQdbGxuyZdWfeuLR46ekTWtL+i+m5du6czcbVy1L2QskdLRp3pjx02bTqnNP3JwcaNW0Ieu37mDNxq0YGKh5/TYp2aBkMeVzPFuWzJQoWlj7e0BgENZWVpQuUUyJl5w5CArWPbFy/+FjLl65zqSZ85R48XClc7uWen0nt3LhrBQ9h+joaFp07MGUsSN0qoIsWrGGmJhYWjdTkvQWr1xH2+ZNUKnk7urv0aZpAybMXECrbv1xc6xOq8b12LB9N2s278BAbcDrt0mJBiWLKfGRNXMmShQtpP09IEhJOCldvGhirGTXm8Lq/qMnXLx2g8mzfycqOpra7k50bt1Mr+/kVsybmqLnEB0dQ8uu/ZgyeohOrHzJxtqa4MQpTUJCQrG1sSY0LIxp85Zw96wy1Z9L/ZbUr+WOeeKd+0JXm0ZeTJizhNa9h+Fmb0fLBrXZsPMAa7ftxUCt5nWyZIOSRZQqDVkzZaBE4QLa3wOCQrBOY0mpYoWVeMmRlaAQ3alm7j9+xqXrt5kyf7kSL672dGrRUK/v5JbPSFnFoejoGFr2HMLkX/vpVJB59OwlaW2sdZYBbN9/lHXzlRtKbKzSkCdnNvLkyAZAtiwZ+RgQRMb08v35S63rezJx4SraDBiDW/WKtPD2YOOeI6zdeRADtZo37/20bUsUVi4YZM2YnuKF8ml/DwwOwdrSktJFCqBWq8mVPQvBoWE6/Tx4+oJLN+8xZdFaomJiqO1YlY5N6+r1ndyyycP5XulslRuKcmXLTNZM6fkYGEyGtDbax+u523Pj/mNJjPmLWtV1YdKSjbQdOhVXu3K0qOPEpgMnWbfnmDK2fPiobVuioFI9LmvGdBQvkFv7e2BwKFZpLChVKK8SL1kzERQartPPg2evuHz7IdOWbSEqJpZa9hXp0LCmXt/JLR3X/7uf16JN+1g75Reu3H2sXbZs6wFa13XVO27RaDR0HT2bTo09KZRHppj9Iy1rVWfKyl20H70Al0olaV6zGpsOn2P9gTPKMa5fUmJK8fzKxZys6W0pli+H9vfAkDCsLcwpVTCXEitZMhAcphsrD1+84fLdJ0xbvYeomFg8q5Whg7eTXt/JLR7R5buf16LtR1kztidX7z3703bWaczJnTUDubMq35ezZrTlU3AYGWytvrvvn0FLt4pMWX+YjpNW41y+MM1cKrLlxFU2HLmE2kDNG/8gbdvieZXP+CzprCmWJ6v298DQCKzMTSmZL5sSN5nTERyuW437oe97rtx/wfSNR4iOjaNm5eK0r2Wn13dyiwa1/Ob+3372BhtLM7ImqxYDaKvB5MyUlqzprfkUHM7ec7cokjMz60Z24OSNR/y2fC/z+v9vb6JM7Vo4l2XqphN0nL4JlzIFaepUhi0nb7Lh+HUM1CreJEtMKZ5YgSVLOiuK5Ur6PShMiZcSebOgVqvJmcmW4HDd82UPXvlx+eErZmw9SXRMHB4VC9Peo6Je38n93q8RKREdG0eHqRsZ276mtoKMOtnnTkhEFLZplIuRnpWK4FmpCLO2nWLZgYsMbOz4F1+xn1dz++JM23GBzvP24lQyD01rFGPr2ftsPHUXA7WKtwFJ33GK5coIQBZbS4rmzKD9PTAsCitzY0rkyoharSJnBmuCw6N1+nn4+hNXHr9j5q4LRMXG41E2H+1cSun1ndzC7p4pfh47zj+kXuXCf9pm5bFbNLcvLudd/oamlXIz49A9uq66iFORzDSumIttV3zZfOklBioVb4OSPlOKZbMBIIu1KUWzWmt/DwyPxcrMkBLZbZR4SWdBSGSsTj+P3ody9UUAs488ICo2AfcSWWhTNZ9e38nNa6X72fRndl57Rd0ySceqy089ZUn7ylx/mXTzvI2ZkXa/QqJisTE3TvH2BTQpk4FZJ9/QY+sjHPLb0qh0Brbf+siWm/4YqNBJTCmaWRnLM1sZUyTZ70GRcaQxMaB4ZgvUahU5bE0JiYrT6eexfyTXXocx9/QbouIScCtkS6vymfT6Tm5Ofd0phf9IdFwC3bc8YqR7Lm0FGWtTQ6rltUatVlE1jzUP/SIkMeb/g5mZGTNnzkSj0VCkSBGaN2/O9OnTuX37NmFhYdqpiQCdQT7575rE7NqbN2+i0Wjw9fXFxsZGp5/ChQtTp04dHB2VA4mYmBji4+P1+jY0THq5UlIxJiYmBiMjI1QqFTY2NpibK0ETHR2NiYkJpqammJubY2ZmRnBwsLYKzMmTJ3FxcUGtVmNsbIyZmZn2ucTFxVG1alUOHz5Mt27dOHDgAL/++tfLUqdGZmZmzJwxHY1GQ9FiJWjevBkzZs7i1s3rhIWFUaJkaW3bb8XLrVu3/jBeChUuRJ3atXF0dACSxcsXfSePl/+PijF37tzF95UvNWvW4snTp+zZs4eSJUtQuXJljhw5ioeHOz4+PvTqKXNfJ2dmZsbMaVOU965kGZo3bcKMWXO4de2yEjdlk06SqlB99Xdt3Ny+nRg3r/TjplAh6tTyxNFByQjWxs0XfevETQoqxhQokF+ZgiU6mvDwcO36e/ft58DBQ2zfsknbtmqVyhw+egxnJ0cOHDpMNbsqxMfHo9FoMDQ0xMoqDZYyJcGfMjMzZcaUiWg0GoqVqUjzJo2YOWceNy+fIywsnJLlq2jbfnOcuX1HiZdXr7Cxsdbpp3ChAtT29MDRXrn743O8fNm3TrykoGJMgfz5CNbGS4TO+l/6/FkFYG1tTUREOGZmZmTMkJ6AgEAsLMx5+/Yt6f7koubPzMzMlBmTxqHRaChe3o5mjRswc+4Cblw4RVhYOKUqV9e2/eYxzO27ibHyWnus8FmhggWoXdMdxxrKiV5trHzRd/L3OiUVY27cus21m7fwrNeYO/fu8/jpMw7u3IKFhQWbt++kcQNvnfV9X73G0NBQpsP5TmampkwfPxqNRkOJyo40a+jNrPmLuX7mCGHh4ZSu6qJt+82x5e59JV5ev8HGWveke6EC+ajt7opDdeVO2M/x8mXfOvGSgooxGo2Gjr0G0KppQ6pVTvqCvu/QUQ4ePc7W1UmJng8ePebAkWMsXb2O5y986TVoOHOn6lclEl9nZmrKtDHDlPerugfN6tdh5u/LuX5iL2HhEZRxqKVt+81YufcgMVbeYmP1ZazkpZarEw7VKgOfYyVBr+/ksZKSijEajYaOfYfQsnE9qlb68wvRdhXLcsTnLE7V7Th4/BRVK5VDrVJjbGSEWeLd/BqNhrjE8vNCn5mpCdNGDkSj0VDSuQFN63owa8larh3aRFhEJGXdkp2sT37S9Cvxcvv+IyVe3rzDxkp3nvpC+XJTy7kGDnbKNKIxMbHEJ8Tr9Z08XlJSMUaj0dBp0GhaNaxD1Qq6Fxq27j1Mo9q6ydy+b95haGBA1kwZEp+/KRnTpSUgKBgLMzPevvfXJkoIXWamJkwd2guNRkNpz1Y0qe3C7BWbuLJ7JWERkZSr00bb9o/HFuXfWw+eKLHy9gPWaZLmsgcomCcXtRztsK+sVIhQYiVBr+/ksfJ3KsYEh4ZhncaS4NAwXr3zI52NlXYZwJnLN3CsIkkxf5WZiTFTBnZCo9FQtn43mtS0Z86aHVzaPI+wyCgqNEw65/AHQwsaEseWR8/RaDS8euePTRrd76IFc2fH074i9hWUG5tiYmOJj0/Q69vQMOmO1++tGBMaHsE7/wCaDZxIYHAo/gHB1ChfnIfPX3PwzBWWbz/Eizfv6TdxITOHdmPEnFUUzZeLBm7V/3S7PzszE2Mm9W6BRqOhXIshNHatwtyNB7m4ejxhEdFUaj1M2/ZbY8vtJ75KrHz4hPUX5y0K5MqCZ9Uy1Cir3GQQExtHfEKCXt/JY+V7K8aERkTy/mMgLYbNITA0HP/AEKqVKUKdGvrTHJiZGJPBxoqAkDAsTE145x9IWivLr2xVJGdqbMTELvXQaDRU7DSRRo7lmLftBOd+/4XwyGiqdJ2sbfuHY0xi4Nx59laJG79ArC10E6kLZM+IR+Xi1CilXDT6HDdf9m1okBQ3KakYc+vJa24+eU2D4b9z78U7nr39yPYJXYmLT8Dawozg8Ehe+wWS1sqc+IQE0lor8ZzOypKQiD+/eUnoMzU2YkLHWmg0Gir1mEVD+5LM33mGs3N6Ex4Vg12vpMp13xpn7jx/r8SLfxDWFknVwwAKZsuAR4XCVC+ZF/gcLxq9vpPHS0oqxmg0GnrM2UZTp7JUKZpbuzxHRlse+PqRO7MtD1/5kTdLWqJj4zAxUo6RrC1MiYiWqg5/hamxIeNbOaLRaKg8cAUNqxZh/r4rnJnchvCoWKr+slLbNnk6SfLfP48td3390Wg0vP4YgrWFbuWWAlnT4l42H9WLKQmfMXHxxCck6PVtaJBUPeyvVIw5fP0p/b3/fHrYR28+ceT6M1Yfv8ULv2AGrTjK1HYuf7qO0GVqZMDY+qXRaDRUG3+Y+uVy8Pvxx/gMdSU8Og77iYeTGv9BwHw+3r37JkiJl8AIbWWWz/JnTINb8SxUK6gkY8XEJRCfoNHrO3m8/JWKMUfuvqevmxJHYVGxvA+Oov3S8wRGxPApLBq7AhmokDc9Jx98oEahTBy/956KeWWatr/C1EjNbzVzo9FosJ93g3ol0rPo/FuOdS9FeEwCzvNvaNv+8fVF5d97H8LRaDS8CY7BylT3uk2+9Ga4FrKlah7lnEZMXALxGo1e34YGSdtNScUYjUZD/51PaFQ6AxVzJZ0brJQrDXffR+CQ35jb78Kokjv1TK/1n06MWb9+PatWrUKj0VCzZk0MDQ1xcHCgevXqlCtXTu/C85+xtbXFy8uLt2/fMn++7p3Sw4cPp3Pnzowdq9y1NmrUKJ48eaLXd3IpqRjz/PlzOnXqhEHiAdHcuUqZ586dO/Py5UtiYmJo3rw56dOnZ9GiRSxduhRjY2NKlSqFt7c3KpWKZs2aUaVKFTQaDQ0bNsTKyooOHTrQqlUr1q9fT7Vq1SiRWPHkZ7d+/QZWr1mDRqPBw8MdQ0ND7O1rUMPegbJly/61eLGxpW7derx995Z5c+foPDZ82FC6dOnGuPHKRZyRI0bw5MkTvb6TS2nFmFatWnPu/AV27tzJrdu3GTniV1avXsOSpUt59Ogxrm7u7Nm9i+DgYFq2as3Nm7eoV78Bffv0oW5dL1xclNL5o38bQ+lSpcibNy+/DB5E69ZtGTd+PE2bNiHdF3f4/+zWb9zE6rXrlPfO3U2JmxrVqeHkQtkyZbCxtknxtmxtbKhbvyFv371j3uxZOo8NHzKYLt17Mm7iJABGDh/Gk6dP9fpOLiUVYwwNDRkyaCAuHp7ExcUxYewYADp27U7OHNlx8fDE2MiYQ/v3UMuzJrv27qWGkwsFCuTHs6YHoaGheDdsjFqtJi4ujonjUnb37s9q/SalOoxGAx5uykl7++rVsHepSdkypfUSXP6MjY0NdRs25d2798ydNU3nsWGDB9KlZx/GT1Luvh8x7BeePH2m13dyKakYY2hoyC8D++HqWZe4uDjGjxkJwOp1G1i6fBWPnjzBrVZddm/bxM49+1i0ZBlqtRobGxtWLlkIwMSxv1GvcXNiYmIYNKCv9jNO6NqwZRur129Co9Hg7uqcGCtVsXevQ7nSJbGxTnms2NpY492kJe/ev2fOtMk6jw0b2I+uffozfsp0AEYMGcjTZ8/1+k4uJRVj2rRoRpvEqkTtu/akd/cuWFgoJ+x27d3HkT07dNpv+co0SgOHjeTw0ePExcXx5Okz5s6YkuLn/LPZsG0XazZuUd4zFwcMDQ2pUa0KDrUaULZUib8cL/VatOft+w/MmTxO57Gh/XvTrd8vjJ+mnBwcMbgvT56/1Os7uZRUjDl0zIe9B4/y9v0Hlq5eT20PV/p170znPoPIkS0rbvWaYmxkxIFt65k/faJ2vXL27tqkmEEjxnD42MnEeHkuyTJ/YOOOPazZvEM5dnCyV8YWu0o41m1O2ZLFsLZK+R3IttZW1GvdlXcf/JgzcZTOY0P6dKPboBFMmLkAgF8H9OTpi5d6fSeXkooxh46fYt/hE7x778eyNZuo7e5E367tWbN5B8vWbuLx0xd4NGrDzjWL8XRxYM/BYzjWbUaBvHmo6WyPgYEBTerVonqtxmg0GurX9sAqjVxg+iMbdx1k7bY9yt+3g50ytlQuh1OjDpQpUQTrLxJc/oyNtRX1O/bl3Qd/Zo8ZovPYkJ4d6D50HBPnLgFgeJ8uPH35Sq/v5FJSMeaQzzn2HTvFuw/+LFu/nVqu9vTtqNypvevQCQ6t1z322brvCPVr6Z7wHT+kNw079SMmJo6BXdvKccsf2LRXqQ6j0YBbjUpKrFQsjXPLnpQtVhCbv3Ah19Y6DQ27DeWd30dmjtSdEuKXrq3oMXIqExcqU+4N79GOp76v9fpOLqUVY9oNGsuF63fYffQ0dx4+ZViPtrQZ8BshYRHExccztn8X1Go1W/YdY8XWfRgbGVKycH68XJTEhl8mzePImUvExcXz9OVrZo38/sojqd3mAydZt+c4GjS4Vi2HoaEB1cuVwLXDEMoUyaeX4PJnbKwsadR3LO/8A5g5pKvOY4M7NqbX2HlMWqLc7DGsc1OevXqn13dyKa0Y0374dC7evM/u42bcefSCoV2acX6jcnx06spt9py4QB3HKtRxTLrxoXKT3swc2o0Hz14xd+1OqpQqwrHz1yhXvCDj+7ZL8XP+mWw+cp71B86g0Whwq1xSiZUyhXHrPp4yhXJjbZnyu05t0ljQ+JeZvP8YxPT+ulW9B7X2oveUFUxeuQuAoe3q8fTNB72+k0tpxZiOY37n4u3H7Dl1lbtPXzGknTdnVyjH2Kev3Wfv6avUqVEOv4BgOvy2kDtPfGk2dDY9mrhTu3o5xnRrQtMhs4iNjaNfi9oYGMg0St+y5cQ1Nhy9BBpwqVAEQwMDqpXMT82BcyidP4degsufsbE0p+nopbz/FMy0HrqVMQc2c6PP7E1MXa9c3PylhTvP3n7U6zu5lFSMaeFWiRZuykXrbtPW0a2ePRamJjQasYjQ8CjiEhIY1b4OarWaxk7laT9xFfvO3SY2Lp4p3Rt8Y+viS1tPKdVhNGhwKVsQQwMDqhbPg+fQJZTKl/Uvxospzcav4X1AKFO76E4HO6CRA30X7GTq5hMA/NLUiWfvPun1nVxKKsYcvfaIQ5ce8D4glFWHL1OzYmF61K3GiJau9Jm/k7j4ePrUr4GhgQG7zt5i+cGLqFUqbCzNWNCn4Te3L5JsO/uAjaeVG89cSufB0EBNtaI5qDVmI6XyZML6T6Ym+pKNhQktpu3gfWA4k9s56zzW37sy/ZYeZtqO8wAMbmDH8/dBen0nl9KKMdefvSd/lrRYmCZV9Nh46i6rj9/i6fsA6o3fzIZB9ZneISmB3H7oKkmK+Q7bryrVYTQaDU5FM2FooMauQAa8ZvlQKoct1mYpr6piY25Mq8Xn+BAcycRGujd89HUvzMCN15hx6D4AAz2K8vxjmF7fyaW0YswN3wDyZ7TEwkT5fmVpasSxX5RYOPvYjwO33uJZMhvxCRoO3n6L16wT5M2YBpdi+tXDxR/bmVgdRqMBx/y2GBqoqJLbmnrL71Iyi4VegsufsTY1pO36h3wIjWF8rTw6j/WukY1fdj9j1knlZtf+Dtl58SlKr+/kUlIx5sSTII48DORDaCzrrvrhWsiWLnZZ6V4tG313PGH2ydeUzmZJqWyW+IfF0HPbE+69D6fDxod0qpIF98I/3k3Tqs9Zjn95RZWqjqOj45rjx4//52+58vHxYefOncyaNevf3pUfVsGCBYMfP37srNForn7P+unTp7+yccP6cs7OTt9u/C/z8TnJzl27mDVzxr+9Kz+kNWvW0q//gJ2fPn2q9+3W+lQqVYlcuXKeef7owQ9VW9bn5Cl27t7DrOkpm0ZAKNLYpo8Kj4jIrtFoPn27tb706dMdWTh3pksD77r/6137R/mcOs2uPfuYOXXSv70rP4x5Cxfx66ixS0NCQzt9z/oqlap6qRLF91w9e+I/f9ySnM/ps+zeu58ZkyVJ4K/Ilr9o2Ac//9IajeZpStdRqVSt6nt5Lti0YtEPe5X95Jnz7Np/iBkTRv/bu/JDsnOtE3z52o0GGo3m2Lfampmahj+/fso83RfTuPwoTp69yO6DR5k+9vunKPmZ3b7/EGfvFr6BQcG5vtVWpVL16tSiwZR544ebfqvtf9XJ81fYffgE00cN+rd35YdUp03PkMMnz7XXaDTbvtXWzNQk/InPNvMftbLNqYvX2X3sNNOG9f63d+WHdOfhU1xa9vINCglNydjSytul6oJ1U4f8sMctnxNQpg76rsP7n559qwHBV+48Stlxi4lx+IMds8zTWac8IfK/5HMCyuQ+305KEPruPn2Fe4/xvkGh4Sk6bmnnaTdlZu/GP+xxy2enbz5m3/nbTOpa/9/elR9Kw19/Dzl65UGKjluszE0/nJzZI2OeLD/+TZhnbj9j38X7TOxY69uNBQDn7r6g1cR1tz+FhJf82uMqlSqHraXp/SeLe6aq8uRn7vmy/8oTJrT+71/n+q9K32KaRqPBSKPRaMu/2pgbbxzlXbJJiyp5/mzVH87nBJRxDUr/27vyQ5px8B5TD9wbH5+g+eq0KSqVqler8pmmTKqT94c/bjn3PJiDDwIYUzN1/Q3801qsuR/i8yQoRcctn0mauhBCCCGEEEIIIYQQQgghhBBCCCGESJX+01Mp/a84ODjg4ODwb++G+EE4ONjj4GD/b++G+ME42NfAwb7Gv70b4gfhUKM6DjVkPnrxbQ7Vq+JQveq/vRviB2FfrQr21ap8u6H46dlXrYR91T+fl1yIz+yrlMe+Svl/ezfED6BGpTLUqFTm2w2FAGqUL0GN8jI1uPi26mWLUL1skX97N8QPpnqpAlQv9e0pBIQAqFYiL9VK5P23d0P8AKoVzUm1ojn/7d0QP4iqBTJStUDGf3s3xA/ALo81dnl+zMqxPxqpGCOEEEIIIYQQQgghhBBCCCGEEEIIIVKlVJcYU7p06f+Xfvr06YOdnR1VqlTh8uXLOo+5ubnRt29fANasWaOtWJMzZ07mzJmj09bHx4fs2bNr24SFhQGQP39+7bKtW7cCMHr0aIoXL46DgwMdO3b8559kKlWmbLl/vI+AgAAqVa5CGisbbty4ofNYfHw8xYqXZNbs2QDMmTuXylXssKtajSlTpwEQGxtLteo1cHB0onoNe+7evavXx+BfhmDv4EidOnX5+PEjADdu3MCuajVq2DvQtVv3b+6L+LYyFf75u6lPnjpNler22Du70rxVG2JjY0lISMCjlhfVHZ2p7ujM9cT3btfuPdplbTt0Ij5emYozTdoMOLq64+jqzpmz5/T6mDp9JpWr1aBytRrsP3BQ57HO3XpQr2HjP9wXkTJlK1X7x/t49fo11RzdcHKvhUvNOrx9+w6A8xcvUc3RjWqObpy/eEnbfv7Cxbh6euHkXovbd+4SGxtLdSd3HN08qeHswd179/X6WPD7Eqo5uuFepx5+fv4A3Lh5i6oOrti71KRbr34AHDl2Aif3Wji516JwyXIM+GXYP/78U5NyVR3+8T5evX5DNRdPnDzr4lK7Hm/fvQfgyHEfKju4UdW5JuOnTNdZZ8PmbaTPmV/7/7qNW+BY04sqju6cPHNWr485CxZRzcUT1zr1efb8BQADh43EybMuTp51sc2Wh1t3lM+wM+cv4ObVAOda3qzdsPkfetapTzl793+8jxe+r8hcoCTOXo1w9mrEk2fPATh/+SrVPbyp7uHN+ctXAZg+93dtu6yFSrPnwGEAFixdSXUPb2o2aI6f/0e9PpzqNCR9nmLs2pf0GRQTE0OvQcNx826Km3dTnfYbtu4gQ97i/9RTTrXKO3v9v/Rz9uIVPBq1wbV+K9Zu2aldHh8fT8nqNZmzeCUAJ89epFQNT7IUrahtc//RExy8muLk3Zy6LToRFByit/2Fy9dSo3YTPJu0w8//EwCzF62gQHlHGrTtptN2+95DuDVojWv9Vhw9qT9Oia+rULPptxv9D/QfPRX7+m2pUa8NV24qnwft+4/AoUE7atRrw5FT53Xab9x1gEwlk6p3rt+xDzuvllSt24qVm3fqbX/IhJnkrujGgN+mapet3rKbIvZeuDbphHf73gDcf/IMx4btcW7cgbrtehMUHPoPPNvUpZJ3+3+8j4CgEKo16kz6su7cvP9Yu/zC9Ts4NO2GQ9NuXLh+B4BTF69TtnZrsleuo7MN15a9yFzBk91HT2uXtR04BrdWvXFr1RvbUi4EfvF+P37+CpeWPbFv0o1dR04BcPnWPRyadsO1ZS8adB1CWHiEtn1oWATZK9fR6UPoqtyk9z/eR0BwKDVa9iejXSNuPnwGQEJCAl7dR+LSbjAu7QZz48FTAPaeuKBd1mnETOLj44mNjcO57WDcOwzBpd1g7j19CcDjl29waz8Ex9YD2X38vF6/Nx8+w7H1QFzb/0LvcfP/cF8APLsMx6PjUNzaDyG7fbN/+iX5Idm1/fUf7yMgJAyHTqPJ7NqJW49f6jwWH59A+ZZDmL9ZOSYNCY+kXv+p1Ow5gbr9phAYEg7Ags2HcO46htp9JvH8jZ/ONnpNXk7TobP0+n394RMePcfj0XM8LYbPISY2jti4OFy6jcWj53hcu43l/rPXAJy5/gDnrmNw7TaWA2ev/wOvQupQrfuUf7yPwNBwnHrPIJv3YG49fa1d7jVkPrUGzaXmwDnkbph0vmPx7tPax+4+f0tsXDzu/WfjOWguHv1nc/+Fcp4mJjaOgfO24jVkPl5D5uv122nyGmoNmkutQXPJ7DWIoNAIQiOiaP7bUmoPnkf/uZtJSEgAYNOxKzj2mo5T7xmsOXThH35FfkzV+879x/sIDI3AeeACsjf5jdvP3mqX7zx7G9dBv1Nz6GKuPVZiaP/Fe3gMWYzHkMV0m7WV+Hjlvaw1bAm5mo9l34V72vW7z96KY//51B6+lHFrj+j1++TNRzyHLsFt8O/sPa8cT4dGRNNiwlrqDF9K/4W7tLFStst0ag9fSu3hS9l19s4/9lr86OyHrvrH+zh7/xVuI9dRe8xGOs3dS2yccg5/1DofinZfyLDVx7VtQyKiaTRpK15jN9Jg4haCwqIAKN9vKV5jN+I1diO7Lz4EYPLWs1QdvAKvsRvps/iQXr8j1p7QrpOrwxzu+vprH7v06A3pmk8jODxK22+X+fuoO24TXebt+8deix+Z02T9v8n/tXOP/ak5/Th1Z/vQZeVFYhPHi9DIWLqvvkT9uSfptuqitv2yU09oMO8k9eb4cO9tMPfeBlNvjg/15vjgMOkI7ZYq14Ym77uL92wf3KcdY+nJJ3r9/n7iEeVH76fNkqRrSddeBlBrxnG8Z/vQctFZwqPjANh6+SXu047hPu0Y688//ydfjh+a68Kb/3gfb4Kj8Vp6m4Yr7tJo5V3eh8QAcOVVKF5Lb+O19DZXXinffxeeeUPDFXdpuOIuJadc5vCDAABWXnyP19LbNFt9j49hutf/mq2+x8gD+u/x1OO+NFh+B89Ft1h+QTnW2X3nI7UX38Z72R1G7tddJyw6nuKTL3PwfsD//DX4u36KqZT+13x9fbl79y7nzp3j/v37DB8+nO3btwNw8uRJDA2TXtZWrVrRqlUrQJnSydvbW297DRs2ZNasWTrLLC0t8fHx0Ws7bty4r25D/LekSZOGfXv3MGjQYL3H1q5dR+5cubT/r+XpSe9evdBoNNSwd6BVyxZkyZKFE8ePYWRkhI/PSaZNm86KFcu161y9epXXr15z0ucEhw8fYcrUaUyZPIk5c+cxZfIkqlWrRtOmzbl16xZFihT5w30R/w358+XlxJFDmJqaMvTXkWzbsZMmjRqyYO5s8ubNw8OHj+g7YCAH9u6mpoc7db2Uk8HtOnbm9JmzONjX0G7ja+Lj41m1Zi23rl0mNDQUj9peeNb0AODp02f4+fmhUqn+cF+aNm70//NCiG/KmiULp44dRK1Ws3LNOpYsX8moX4cyZPgotm9aB0Cj5q05efQA12/c5OHjxxzZv1tnG8cP7VXGllOnmTZrDisWL9Q+9ulTABu3bOPUsYPsO3CIKTNmMW3SeOYuWMTkCWOoZleFpq3acev2HVydHXF1dgSgbaeueHvV/v97IUSKZM2SmVOH96JWq1m1bgNLVqxm1LDBTJ4xm63rVpI9W1bsnDzo2aUT1tZWxMXFsXXnbnJky6bdxpa1KzA2NubFS1/ad+vF8f27tI998PNjx559nD6yj8dPnjH8t3FsWLmUaRPGABAeHk41F09KFi9GVFQUU2bMYc+W9ZiYmPy/vxbi26pWqsC2tct0lg0dPZ5ta5YC0LhtZ3z2bWdAr64M6NUVgNJVnXFxqM6ngEA2bd/Nyf3b2X/4GFPnLGDq2JE621q7eB5LV6/XWbZg2Socq1dl7tTxOsvj4uLYtmsf2bNl+V8/TfE/EBUVzdS5i9m1dgkmJsY6j63buovcOZLGkFLFi3D+4DZq1GmiXZYhXVp2rV2CtVUalqzeyOLVGxjcq4v28U8BgWzauRef3RvYf9SHafMWM+W3oTStX4fa7s4MHj1R2/a9nz9bd+/n4JaVqNWp7p6PH57vm3fce/yUk9tXcv/JM0ZNnc/mRdMZ1rsT+XPnJDA4hJotuuJaQ5kCLi4ujm37jpI9aybtNmYuXsOpHSsxNDCgUu0WtG3srdNHn44t8XCoxp4jPjrLu7VuQu8OLbT/z5DWlp3LZytxt24rS9ZtZVD3dv/Ycxcpk8bCnJ2LpzB08gKd5cOn/c7m+RMAaNZ7BMfWzaNkkfyc2bIYx2bdddqumj6K5Zt1j3dXTlM+g168fkv3EVOxtU6j8/jImYuZNaIf+XJlx6VlL2o52lG6SEF8NirHxePmLmfHoZO0ql8TgDkrN1GuROH/3RMX3yWNuRnb545i2MykcyMqlYrZw7qTJ3tmHr14zaCpS9g1/zfcqpWjtmNlADqPnMnZ6/eoUb4EB5dMwMjIkFNXbjNr1XYWj+nH6LmrmTG0K/lyZMGtwxA8a1TE0NBA28fCDXsY368ddmWK0fqXydx+9JzCeXLo7QvA/kXKMc3Jy7fYuM/nn39RxFelMTdl69QBDJ+/Qe+xjYfPkitzeu3/9566SpWSBRncti5Ldxxj46GzNHCuxO5TVzi6cARPXr1n9KLNrBrTE4Bnbz7gFxisPYeS3Nr9p2lbx4Gm7lUZsWATRy7eola1shyYOxQjQ0NOX7vPrA37WTS8MyMWbmLr1P5YmplSq88k3CqXwsBAjmX+DZZmpmwZ25lfl+zSWb57Ug8ATt18zOZjVwC4+eQ1j1/7aR/7bO+UnhgZGnD65mPmbD3OwoEtWLLnDNVLF2Baz4Zf7XfJL8r1ghfvP9Fn1iZs0pgzd9sJXMsXoV2tqoxZsZejVx7gVrEoc7cd58jMvhgaGGDfcxqt3Cv/r18GkQKWZiZsHtmGESsOaJfFxycwfYsPR6d2IyIqhrZTNrBrbAdcyhbEs1JRQEl8OX/vBdVK5GXpgCasOnxZb9tzetajRN6sX+137JrDTO1Sh7xZ0lFr2BI8KhZm1eHLuJQtSDuPioxZc5ij1x7jVr4QFmbG7B0vN1T/F+TJZMPuX5tgamzImI2n2HPpMfXtCtPNszwupfNy4GpSosL+K0+oVCgbA+tVYfmRG2w6c48uHmWxMDVi9wj9GxqGNapGrQpfnypubEvlXG14VAweo9ZTLGcG7WO/H7hK6bxJ37UmbztHF4+ylM0n517+TXkyWLKjtz2mRgaM232bvTfeUK9cDqYcuEsn+/yUyZVW2/b2q0Ce+IWyrae9zjZ29HYAYMr+u+RJbwlAP/ci/FKrGHHxCThMOkKbankxSnasUb9cTjyKZ2XUzlvaZSWy27CvvxMAU/ffZc+N1zStlJsFxx+xr58ThgYqXKYcpXmVPP/UyyG+IXMaY3a2L45arWLTdT/WXf3AAMccjD/8kuVNle+snTY9ZEeH4nSrlo1u1ZRzdE7zb1A9nzUBEbHsvPORne2Lc/RxIPPPvGGUR24Azr8IxlCtf4wL0KdGdgY5qYmL1+C84CatKmSiTDZLdnUsjoFaRfctj7j6KpRyOZTv3ovPvaV0Vst//gX5Dj/EEXevXr04c+YMAFeuXKFTp058+PABZ2dnatSoQZ06dYiOjtZZp23bttrqGKNHj2bnzp0ATJw4EXt7e6pWrcrFixf5HunSpcPCwoL4+HiCgoJIly6d9rHZs2fTo0cPvXXevn1LXFwcOXPqzz+4c+dOqlevzoQJE7TLIiMjcXBwoFGjRrx//167/LfffqNGjRrs3bv3u/Y9terVu49ujHTuwocPH3BxdcPewREvL2+9GGnXrn1SjPw2hp07lS9AEydNxsHRiWrVa3x3jBgZGZE+fXq95bGxsWzfvoOGDRtol+XLlw9QTugYGRlpT+obGRkBEBISQrHiundMP3nylFKlSwFQtmwZTp9W7lwrUqQIwcEhaDQawsPDsbGx+cN9+Zn16ttfW1XlytWrdOrWXYkXd0/snV3xqtdAP146dubGTSXjc/TYcezcpZx8nThlKg4ublRzcOLipUt8j2zZsmFqagqAiYkxarUalUpF3rx5EpeZaOPC2Fi5AKXRaNBoNOTJnRuAFy99sXd2pX3nLoSG6t4RaWBgQK6cOYiOjiYkJBRbGxvtYxOmTGFg/35/ui8/s979B3HmnHLX4JWr1+ncvTcfPvjh6umFg2tNvBo00Y+Vzt24cVM5oPxt3ER27lbG60lTZ+Do5kl1J3cuXrryXftjYGCgfU/CwsIoVqwokZGRAGTMmIGMGTOgVquIiopi1559xMcn4OrpRefuvYmKUu4GSBpbQiletKjO9i9duYpDjWqo1Wpqurtq97NI4ULJxpYIbGyS5ruMjo7m6rUbVLOr8l3PKTXpM3AIZ84rd29duXaDLr368cHPD9c69XHwqEPdxi304qV9157cuHUbgN8mTGHX3v0ATJo+C8eaXlR39eRiYqWOvyp5vISGhlG8qHJwXKRgAYJDQoiJicHAQI2xsRITq9ZtoFmj+qiTHQB/HnNCQkMpXkT3gtCLl68oWrgQKpWKggXyce26blb83gOH8fRwBeD8pSuYmZlSv1lrvBo158VL3+96TqlFn19GcOaC8plx5fpNuvQdzAc/f9y8m+JYuwHezdvpx0qPfty4rdwdNmbyDG3llckz5+FUpyE1atbj4pXvv9v04tXrONSqz6ARY4iLi0saWzKkJ2OG9KjVau04AnDh8jVKFCuCmZkZl6/dwKFaFdRqNR4ujl/dj6xZMust23/oGFeu38TZqxEzFyzWLl+1YQtNG3r/9J9Bn/UdNoazF5Xx+OqN23QdMJwP/h9xb9gaJ+/meLfqQnR0jM46HXr/wo07yl2IY6bOYdcB5S6nyXN+x9m7BfZ1mnLp2vfdyXLhynVMTU1p2LYb3i0788JXuSsyNjaWHfsO06BOTW1bG2srzM3NdNZPny4t1lbKF2UTY2PUKt33+fL1W9hXrazEk1MNLibuZ6YM6TH4IiYOHTuFmakptZq2p3nnPgQEBn3Xc0ot+o6azNnLyt/f1Vv36DZkLB/8P+HevAvOjTtQr0MfvVjpOGAUN+8qdx+Onfk7uw6dAGDK/OW4NO6IQ4N2XLp++7v2J52tDRZmZsTHxxMcHEo6WxsA8udWvhObfpFYtXrrHprW9dCJiQJ5cxEWHklkVDRpLMz1+siSMcNXL04uXb8Np0bttVVm0qe11Yk71R+c7Ent+o2dxdmrynHq1dsP6D5iCh8+BlCzbV9cWvakQdchRMfoxkinIRO01VzGzV2urZoyddFaXFv2wrFZdy7dvMf3MDIyJH1iXHwWGaV8/mVMZ0vGdLaoVSqioqOxsUqDuZmp3jayZvrj77pb9h+ngYej3nLfN+8pXigfZqYmFMmXi6e+bzAySrrBKTI6moJ5lTgNCArh0fNXVChZ5Hue4g9twKRFnLuuHHtcu/uYHmPm8uFTIJ5dhuPWfggN+4whOkb3DsPOI2dqK6iM/309e04o36WmLtuCe4chOLcdzOXbD79rf5R4sdZZplKpyJNdOcYwMTZCnTgeGCd+51G+N0PuxIS7z+9zaFgERfMrNyy9fOtH8QK5MTM1oXDenDx99Vanj0J5chASFqF8F4qMwiaNxVf3Jblth07TwP2fryj6XzFw5mrO3VTe12sPntFz8jL8AoKp3WcS7j3G02jwDL1Y6TJ+sbaay4Rl29lzSvnOM23NHjx6jsel21gu3336XftjZGhIeps0estj4+LY5XMFb8ekSnb5c2QmLFI5xg0KiyCttSUv332kcO5sqFQqCuTMwo2HL7Ttp63eQ59mnl/tt1CurISEKcfQwWERpLWy1O4PQEhEJEXzZNfuSzrrNJgYG2GTxpwnr99/dZup0aAF2zh/Rxknrj/ypfesjfgFhuI1ZD41B86hyaglRMfE6azTbdo6bTWXiWsOsPec8lk2Y+MRPAfNxb3/bK48ePFd+2NkaEA66z++cLPj5HXq25cBYN/520qlqiHz6T1rI1GJcW2UmEwXGhFN0dzKBeZDl+5y/ZEvtQbNZd62E3+6/Xo1SgPw/K0/JfIpF7BK5c/OuTvK30D+bBkJj4whMjoWS7Of50aTwYv3cP7eCwCuP35Nn3k78AsKo+6IZXgOXULTcauJjtWNle6zt2qruUzacExbmWXG1pPUGrYE918WceXhq+/aHyNDA9JZWegs+xQaQSbbNJgYGWKbxhz/4HCiYmIxTvy8+fw5lDOTLQBZ0lnpbVeFiv4Ld1N3xDIuP9Q/V+LrF0ix3JkxMzGiUI6MPHsXwLN3nyiRR4m1Unmzcu6u8jpFRcdRe/hS2k7ewIfAn6tC4i8rj3HhgTJOXH/2nr5LDuEXHI73+M3UHrOR5lO368VLj98PcPuFUhVs8taz7LusHPPO3HWROmM2UnP0eq48efdd+5M1bRpMjZU4MDE04PNX2cy2lnz59SVfFlvCo5TxJDgimrSWyjFvZEwcXmM30m7Wbj4EhWvbT91+ntpjNnLo2h9/Th669gy3Mvm0//e5/ZIyeTNjYWKkXXb96XvW+dyhzpiNbDnzfcfzP6KhW69z8WniDAy+AfTfcBW/kCgazDtJ3cRKKdGx8Trr9F57mTuvgwAlYWT/rTcAzD78AO/ZPtSeeYKrLz591/5ksTHD1Ej5HDExVPP5q+oN30A2XHiB92wftl5WxoYDt9+SkKChwbyT9N9wlagv9vPg7bd4lFCS7IwNlaCLjksgZzoLnaQYgIxWpjrngAGdNlGx8eTPqBxP5cuQhvDoOKJi4rE0+bnqbfy67zmXXiqVjm++CWPQrqf4h8XQeOVd6i+/Q5t1D4iOS9BZp++OJ9x5p/zNTj/xSls1Ze6pNzRYfoe6S+9w7fX3jdEGapX2fQuPjqdQRnMiE+MgvaUR6S2NUKsgKjZpn66+CqVIJnPMjAy48SYMu9xWqNUqnPLbcu11mLbdsgvvaVNR//wtJMVTTHwCOW1NMDJQk8PWFIPEfTFOFruBEbE8/RRJmeySGPPdmjVrxsaNGwHYsGEDzZs3x9bWlkOHDnHq1ClKlCjBnj17vrmdO3fucOfOHU6ePMmuXbv49Vf98p1ubm7aKYw+/xw/flynjbm5OTly5KBw4cI0aNCAfv2Ui8oHDhzAzs4OCwsLve1u2bKFRo30qy6UL1+eR48eceLECW7cuMHRo0cBOHfuHD4+PrRq1YqBAwcCSoLQ9evX2bFjByNGjCAoKOibz/ln0axpEzZuUqZl2LBxE82bNcPW1paDB/Zz0ucExUsUZ8+ebycT3blzh7t37uBz4jg7d2xnxIhRem3c3Wvi6OSs83P8+B9/wUlu6dJltGrV8qsnb3fu3EXuXLnIlEk5YePr60u16jXo2as3jg66GaDFihXlpM9JEhISOHLkKIGJFwE83N3o1bsPhYsUI1PmTF9NxBLQrEljNm7eAsCGTVto3qSJEi/7dnPy2BGKFy/Gnn37v7mdO3fvcvfuPXyOHmbn1s2MGDVGr427Zx3tFEeff46f8Pnq9p4/f8HhI0fx9koqD67RaBg0ZKhO8sripcsoWrIMnz59IlOmjAA8uX+Hk8eOULpkKSZPm6637Ro1qlOkZGkqVq2m3dbde/ewtLAke7LqEH+2Lz+jpo0bsmmLUhFs45atNGvSEFtbGw7s3o7PkQOUKFaMPfsPfmMrcOfuPe7cu8+Jw/vZsXk9I8aM02vjXqeedmqizz/HfU7qtbt0+SpVajgzb+FiypUpRWBgEFZWSV+sra2tCQgI5P0HP+Li4jiyfzd58+Rm+co1APi+ekV1J3d69RuEQ43qOtsODArC2lo5wWtoaEhM4oURd1dnevcfRJFS5cmcKSM5c+TQrnPw8FFcnR2/Oq79bJo0qs/mrTsA2Lh1O00bNcDWxoYDOzbjc3APxYsVYe+Br1d2Su7OvfvcvfeAEwd2s2PjGkaOm6jXxqNuI+10RZ9/jp/UL+9/6co1qji6M3/RUsomJlR6e9XGs15jipStjIerM2ZmZkRHR7Nr7wEaeOtOwxITE4ODRx086jbC08NN57H8efNw9fpNoqKiOH/xMq/f6p4s2Lx9J43rewPw4YMfj588Y9v6VQwd2I9fRoz+5uuQmjVpUJfN25UEy03bd9GsgTe2Ntbs37qWE3u3UbxIIfYeOvrN7dy5/4A7Dx5yfM9Wtq9dxqgJU/Xa1GzQXDv10eefE6d0p5vJkikjDy6fxmefMt6t2rCFwKBgrJONLTZWVjpJB1t27qaRt/IZERgUpL3gnHzs+JY3b99RolhhjuzcxIlTZ7n74CHR0dHs3n+IBl61UrSNn0GTerXZvFMpa7xpx16a1quDrbUV+zYu5/jO9RQvUpC9h49/Yytw5/4j7j54zLGd69i2cgGjJs3Ua+PZpB0u9Vrq/Jw4ozutxHv/jzx+9pwtKxYwpG83hoxRStwvX7eFlo28U/x5EBgUzKJV62nbrIHu8uAQrNOkLJ7e+/vj5/+RfRuX41XTlSlzFqWo79SqiZcHm/conzObdh+kiZeHEiur53Ns8zKKF8rPvmOnvrmduw+fcPfRU45uXsrWJTMYNX2BXhvPVt1xbdJJ5+fEOd0kcXMzU7JnzUQJ5/o07TZIp4ILwIgp8+jRVplqJDo6ht2HT1Df00WnTR1XeyrVakZJ5/p0bvn1O66/5OXmyI0jW9m7ej5rt+7l4dMX2scCg0NYvHYrbRvXTdG2UpvGtZzZsu8YAJv3HaVJLRdsrdKwZ+k0jq6dR7GCedl3XH9a1i/dffSMu4+fcWTtXLYsmMBvs5fqtandvr92OqPPPz4Xvp3sGxgcirVl0jkVGytLAoK+76ThzsOnqOtWQ295gibpJKG1lSUBQcqJzr3Hz1DJuz0nL16nQG7leHfGsvX0btv4u/r/0TXyqMHWQ8rx5eaDp2hc0x5bK0t2zx/D4eWTKJY/N/tPfvvmkLtPXnLv6UsOLZvEppnD+W3+Wr02dbqNwKPjUJ0fn0spT+DUaDQMm7Gcvm3qa5ct33aQsvW7ERAcQsZ0NgC8eueHc9vB9Jv0O/blSwJfxEMaCwKDw3S27WpXlv6Tfqe0d1cypbMlR5aMf7ovcXHxnL12F4cKpVK8/z+6hi5V2HZMubFsy5ELNHatgk0aC3ZOH8Sh+cMpli9HiqYLuvfsNfefvebgvOFsnNiXsUu26rWp228KNXtO0Pk5eTVlF/NW7TlJc4+qOscqBXNl4fytR1RsNZRtRy9Q1748ebNn5MbDF0RFx3DxzmPe+AcCcP/ZayzNTMmWMe1Xt1+hWD6W7jxGhZZDefnOn8ollLv5X73/iEu3sQyYsZoaZZUkOzMTY1689ScwJJwbD18QFBr+1W2mRg0dyrL95DUAtvpco6FjOWwszdg+visHpvWmWO4sHLz47Slg7r14x/2X79k/tRfrR3Vg3Cr983j1hi3UTlf0+efkjUcp3te4+HjO3XlKjdLKe+kXEEJcfAK7J/Ugd+Z0rDmo3Bjzyi8Q9/6zGTR/K9VLKW3f+gdRLE9W9kzuwakbj7VTLH1p95mb1KmqjEdFcmXh5A3lwvyJaw8JClWm9fOsUpwaPadSsdME2teqmuL9/9E1qF6S7aeVJKhtp2/RsEYpbCxM2Ta6LfsndqJorswcvPTgm9u59/ID919+YN+ETqwf3pLx6/SnRqk/aoV2CqLPP6dufTs5L72VOe8+hRAUFsnLDwE8f/eJoMQEuZWHLlGpxywCQiPIaPPHFwfHtqvJkaldmdurPv0W7EKj0eg8npDs/9YWpgSGRlAkZyZOJu7fiZtPCApX+jw0uQt7x3eksUNpnco2P4MGdoXZfl6Jh+3n7tPArgg2FqZsHdKQvSObUiRHhj9NJPns/it/Hrz6yJ6RTVnb35sJm8/o9zVxi3a6os8/p+5+/Qawl35BHL/1As/yX6/wAlAwa1ouPnxD1cEr2HH+AXUqFgTg4Ojm7B7RlMbVizJynQ8AndzL4jOxNav71WXilrPaaZG+tOPCA+pVKaT9/5JD1+jgVkanzfVn72lSvShbhjRkyeHrBIRG/ulrk1rUL5uDndeUBLkdV19Rv1wObMyN2dStOrv6OFAkqxWH73w7Ier+22AevAtmZx8HVnWyY9K+u3ptGs8/pZ3m6PPP6Ud+X9kavPwUzokHH6hZUrlWc+NlII0q5GRj9+osO/WEgPBo/EKiiEvQsK2nPbnSWehMa3T3TRA501mQxiwp+emXzdeoPPYg5XN//djlaw7efovT5COceexPvsTEGPcSWXGZcpSq4w/Rtlq+b2whdalbIj277iiJVDtvf8S7ZHqsTQ1Z36oo29sXp3Amc448DPzmdh58iOChXwTb2hdnRbNCTDmmn6TZbPU97dRHn3/OPAvWa3f9dSi1F99m+aX3lMxqQXBkPGlMkypeWpkaEhSZlAi4+84nvIorN5QER8ZhZaokNxkaqLRTdx1/HEj5HGkwN/rjtJGhe59RdfZ1ymbXTUC/8SYMv9AYyiQuX3j2LZ2rfL0K2n/BD5HaZWdnR79+/YiNjeXMmTNMnToVPz8/unbtSkBAAH5+ftpkgs+Sf8n5fDBx7949Ll68iIODAwARERF86fDhw9/cnyNHjhAcHMyjR4948uQJPXr04PDhw8ybN48tW7Zw6StVI7Zs2cLmzZv1lltaJh0UNWzYkOvXr+Pi4qKtQuPl5cWYMcrF9s/L0qVLR5UqVXj8+DEVKlT45v7+DOzs7Og/YCCxsbGcPXuWqVMm4+fnR7duPQgIDMDPz1+bQPDZ12PkPhcvXcbRyRn4eowcOvR9B5VRUVHs3buPvXt3s2rVap3Hrl69ypy5c9m7J6kEdM6cOTlz+hQXL15kyNBhHDmcdDG1ePHiuLg64+ziSqVKlciVmADTvUdPDh7YR4ECBWjXrj2nT5+hevWf5y6llLKrUpn+gwYr8XLuHFMnTVDipWdvAgIDlXjJ+OWYkvS7Nl7uP1DixdUd+IN42f/tpD2AwMBAWrVrz4oli7UVGgCG/jqSihUq6CRHde7YgU4d2tOjd1+2bt9By+bNtOND08YNad+pi862Hz16zKHDR3hy/y6BgYHU9q7PxbOnmTh5KlMmjifmizu3/mhffkZ2lSsxYPCwxFi5wJQJY/Hz86db734EBgbi5/+RTJky6Kyj4itjy4OHXLp8BSd35UJvRIT+F41De3akaJ8qVijH+VPH2LR1OxMmT2fOjCmEhIRoHw8JCSFtWltsbKwpk5gI4eLkyIrVygnonDlycPr4IS5eusLQEaM4vC+pXLCtjQ0PHih3+sXHx2vf/x59BnBg93YK5M9Hu87dOH32HNWr2gGwedsOenXXjbmflV2ligwYMkKJl/MXmTJuNH7+/nTvO4iAwED8/T+SKcMX8fKVz6L7Dx5y6cpVnDyVi3Zfi5eDu7akaJ8qli/L+ROH2LxtBxOnzWTxvFn0GzyMK2eOY2tjQ+0GzXjp+4rd+w7QrlVzvQvaxsbG+Bzcw4uXvng3aYmHq7P2sXTp0tK7W2dq1mtMkUIFqVi+rPaxkJBQXrx8SakSSsUza2srqlSqgKmpKVUqVaDf4GH8zOwqlmfg8N+UWLlwmcm//Yqf/0d6DBhKQFAQ/v6fyJgxBbHy8DGXr17H2UtJvv5arBzYtl5v2ZdMTEy0U1w18q7Dmo1bad7Qm+BkY0twaChpE+/q12g0HD1xmgkjhwKJY8cjpQxw8rHjW6ytrXBKrFLlUK0K9x484vjJs7Rt3kSS7ZKpUqEsA0dOUOLl0lUmjfoFv4+f6DF4JIFBwfh9/ESmDLoVE74aL4+ecPnaTVzqtQQgIlI/XvZvWvHN/bGxSkOV8mUxNTWhcvkyvHw1lqioaPYdPs6udUtYs+nbn2fR0TG07NqPKaOHkD6d7gkaW2srHjxWTlh+K55srKyoYVcJtVqNSw071m/Z+c2+U7Mq5UoxaMx0YmNjOXf5BpOG9cXvYwA9h08gMDgYv4+BZEyfTmedrx3j3n/8jEs3buPapBMAEVH6J1v3r9FPlvnS0dMXCAkN4+6JnTx58Yo+Iydp11u8disxsbG0aqgk2C1Zv422jevqxG5oWDjTfl/JnRNKTLk27Uy9ms6Ym5npd5aMTeK0OeZmZng4VePOg8cUypdbibueQ5j8az/Sp7X95v6nRlXKlmDwpHnExsZx7tptJg7ujt+nQHqNnk5gcAj+n4LImF73tdEdT5R/7z99weVb93Fr1Rv4eozsXT7ju/bR1joNwWFJF4iDQ8NJ+5XKD9/y+Pkr0tlY6VWkAXSqEoWEhpPWRkkEre1UjdpO1Zi2ZB2LN+ygbcPavHzznnIlCnPA59sJQ6lN5dJF+GX6UmJj4zh/4x4T+rXDLyCYPuPnExgchn9gkDbh5LOvff48eObLlTuP8OioHDdEROlWxQPYs3Ds39rXkXNWUb5EIewrlNQua9/Ag3b13ek3cSE7jp6lWS1HcmTJyLGVU7h8+yG/zl7JvkXjdOMhLBzbLypH9J2wgF0LxpA/Z1Y6j5zF2Wt3qVq22B/ui8/lm1QtW0xnOqbUrnKJAgyds47YuDgu3HrE+B5N8Q8Moc+0lQSGhOMfGEJGW90qCTqxkvjvg+dvuHLvKTV7KhW1I6P1k2N3zfy+acKjomM4cPY6W6cOYN2BpIucs9bvp4VnddrWcWD13pPM3rCfX9p6062RG94DplIoV1bKF80LKNVsxvVoSswXFQc+G7lwE5N7t8CxQnHGLd3GxkPnaOZRlRyZ03N04Qgu333KyIWb2DN7CNP6taLX5GVYmJtSMn8uMn/xt5SaVSqah2GLdhAbF8+Fu88Y29EL/6Aw+s3dTGBoBB+Dwshgqzvufy1eHvq+58qDl9QaNBeAyGjdc1sAOyZ0+1v7eurGY+yK58PQQPl7trY0o1R+peqPY9lCrD2sJITlyGjLoRl9uPLgBaOW7WHXpO5YW5phX7ogarWa6qXy88D3PUVy605X8uS1H2mtLLQVa1p5VGbwgm14DZlPoRyZSGtlQWhEFLM2H+PK0uEA1B48D69qpTA3Tf3n6yoVycXwZfuVWLn3kjFtPfAPDqf/wl0EhkbyMThML+Hka+fkHr7y4+qjV9QeriTyfm1s2f7b902xqVarGd/ek5YT15E5bRpK5MlKemslwbete0XauFVg4KLd7Dp3lyYOpb+6jbRWSlXEnBltyZLOik8hEdptANpqaAAhEVHYpjGnlWs5flm8l7ojllEwewZtJZvP2/KsVISpm75980RqUrFgNoavOaHEy8M3/NbcAf+QCAYsO0JQeBT+wRFktNatQJn8rIN2bHnziatP3+E1VrlRPyJaf8zfNlT/BvivCQqLouuC/czrWhPjPzkumLPnMs3si9HKsSTrfG4zb+9lBtavQto0yveemuXyM3W7csPK52Vp05hRvkAWnr4P1JsKKSQiGl//YIrnUq6HHbj6hKpFcmCerFoMQCYbCyoWVJIwSufJxPMPQdrtp2YV8qZnxI6bxMYncPHZR0bVLcnHsGgGbbpGUEQMH0OjyZBGt1KlzvfmxH8fvQ/h2ssA6s3xASAiRrd6C8DmHvpJ+l8TFBFDj9WXmNOigrYyRyZrUyrkVc71lM5py4uP4VibGVEih/J9zb5wRjZceKHdxs5rr6hbJofOdic3Lsto71J4zTpBk0q5yWarX4X1Sx4lsuJRIitzjzxgxZmndLbPz7xjDzk3QrkGVm/OSWqVzoa58Q+RXvC3VciZht8OviA2PoHLvqGMcMvFx/BYhux9RlBkHB/DY8lgofu3pTO2JAbMI/8Irr8JpeEKJYEqMlY/Xja0Lqq37GvKZE/D3s4l2HXnI3NOvWGsZ25Co5K2Fxodj41ZUuWyU0+DGOaqXEO2NjPksb9yPjA+QaOtErTi4nsWNy7I9Tdh/JGJtfMy0j0X9ZbdpXGZDGSzNuFVYBQjDzzXTuPkFxrDq6BoSmWz5OijbycM/Rt+mMh1cnLit99+o2rVqqjVatatW4ebmxvdu3dn2LBhepm0tra2vH79mtKlS3P9+nXKlClD4cKFqVatGitXrgT46t2Hbm5uestHjhyJk5OT9v/x8fGkS5cOlUpF2rRpCQ0NJTQ0lLdv31K/fn1tso6DgwPe3t74+vpiaGhI1qz6GVLBwcHau/NPnjyJi4uLtnS+iYkJly9fJltiNYfPbWNiYrh69SqjR4/+7tczNXJ0dOS3MWOxs7NTYmT9BlzdXOjerRvDhv+qFyM2tra8fv2G0qVLc+P6DcqULk3hwoWoVtWOFSuUeaK/FiPu7jWJidVdPuLXX3Fy0i/RnNzz58/x/+iPp2dt3rx9Q1xcPJUqViRLliz06NmLnTu2Y25uru3XyMgIlUqFjY0N5mb6H1j9+/Wjf79+7Ny5iyyJ0xNoNBrSpk2rxGa6dAQH62cTCoWjgwO/jRuPXRVl6od1Gzbh6uJM965dGDZipH682CTGS6lS3LhxkzKlSlG4UEElXpYq0z98NV486+jHy7ChODk6aP8fHR1Nk+atGD/mNwoVKqhdvnDRYgIDA5k0fqxOWxMTE1QqFdbW1pibmxEeHo6pqSkGBgacPH1GOz3XZ/Hx8VhbWWFoaIiVlRWRiWWCn794QYfOXYmMiuLBw0csWrKUtq1bfXVffmaODjUYM34ydlWUC2/rN23GzdmJbl06MnzkmK98/tjw+s1bSpcqyfWbtyhdqiSFCxagql1lVixeCPxBrNSpR+wXy38dOhinZElRn99/AJvE998s8eLQx49Kucb4+ARMTU2pXtWOs+cv0KRhfa7duEnePLm/GFustet+VqFcWSZPm4FGo+Hw0eNUqlgeSBxbbG1RqVSkS5uW4GDlYnlkZCS379ylckVJ0vzM0b4aYyZOxa5yRSVeNm/D1cmBbp3aM/y3cV8ZW2x4/eYdpUuW4Mat25QpVYJCBQtQtUollv8+D/h6vHjUbaQ3tvz6y0Cc7JOqACWPF2tra+2FRENDQ6zSpMHQ0BBLSwtCw8J48Ogx+w8dYcmK1Tx78ZJe/Qcza+pENBqNtv3XKuI1b9KQ5k0acu3GTdZv3qZdvnvfAep4Jk2nUql8OabPmY9Go+Hxk2d6yao/I8fqVRk7ZSZ2lcqjVqvZsHUHLo416NahDb+OnaQ/tthY8+btO0qXKMaN23coXaIYhQrkx65SBZbPVyp/fC1WajZoTkys7kniXwf2xbFG0p2GISGhWCVWfDl97iL58uZOGls+KeU+4+PjtVPtnb1wibKlS2rjq3yZUkyeNQ+NRsORE6eoVF73LqQ/Ut2uEjfv3MXNyYHrt+5Qo2oVfE6f48CRYyxdvY7nL3zpNWg4c6eOT9H2UjOHapUZO30edhXLKvGybTeu9tXo2q4Fv06Y/pV4seLN2w+ULl6UG3fuU7pEUQoVyItdxXIsmzMZ+Hq8eDZpp5cwO3xADxyrJU2XV7FsKWYsWKb8PT97QaaMGXju+wr/TwHUad6RN+8+EBcfR8Wypaj8lVjQaDR07DuElo3rUbVSeb3Hy5cuwZS5i5R48jlDpbJ/fMd9tcoVmDhLSbS4fvseeXLl+MO2PwsHuwqMm72YKuVLKbGy6wAuNSrTtVVjRkyZq/85ZG3F6/cfKFWsEDfuPaRUscIUypebquXLsHT6bwB6MQFKxZjYL5YP69MJR7uk6Sni4xNIa2OtfDexsSIsMdlh37FTHPQ5w5ZFSVUOHzx5zoHjp1m6fjvPX72h94iJTBzaF2MjI8wSxx6NRkNcnP7Joy8Fh4RibZWGhIQEzl6+jnO1Smg0GjoNGk2rhnWoWiFlY1Rq5VCpLOPnr6BKmRKo1Wo27jmCS9UKdGlej5EzFuvHiFUa3rz3p1SRAty8/4hSRQtQKG8u7MqWYMkkJdH1azFSu31/vYvHw3q0waFyuT/dPzNT5bPlY2KVsviEBExN/vq0EVsPHKdhTaevPpYjaybuP3lBnhxZuP/0BflyZiM6JgaTxEQ8mzSWhEdGce/xc169/YBXx4E89X3DvhNnKVEoH3ly/Hfvfvtfs69QkgmLN1C5VBHUajWb9vvgXKUMnRvXYtTc1frxksaStx8+UqpQXm4+eEapwnkpmDs7VUoXYfEYpXLpl8cloFSMif0iXoZ0bopDxW9XXVmyeT9BoWGM7dNWuyw6JhYTY+V7j5WlBeamJsTExmJkaKh8l06jLAPImSUD95/6kid7Zh48e0W+L95fjQZsrSyVscw6DSFhf17ZY9uhMzSt5fDN/U5tapQrysTlO6lUsoASK4fP41yhOJ3quzB60RY0fBkr5rzxC6BkgVzcfPSSkgVyUTBXFiqXLMii4Z0BvpqAUrffFL3lQ9p5Y1/uzy8kvHjnz8egUOoPmMbbj4HExcdTvmg+4uMTSJeYUJnOJg0PXihTsDRxs6OJmx03Hr5g0+Fz2m10n7CUyJgYHr18x/Kdx2nvnex8cUIC6RIT+dJZpyEkPIKY2DiMDA0S485cO8aVKpibPbOHEBwWQdfxS8iVRTcpPrWrUaoAk9cepFLRPKjVajafuIpT2cJ0rFONMSv26o8tlma8/RhMyXzZufXkNSXzZaNA9kxULpaHhQOVinRfi5d6wxbqLR/cwh370ik737X95HUaOycdr9oVz8eFu8+ob1+Wm09ekztzOt332MIMs8QLz3bF83H76Wucyxfh5pPXVCuZ/6vbr2efdFxiamzEnL5NARi6aAe17EqgVqswNjLUblej0RAXn6C3rdSqesm8TN54nEpFcqFWq9ly8iaOpfPT0bMyY9Yc/mqsvPkUQom8Wbn17B0l82alQPYMVC6aiwV9lOqDX4uV+qNWEPPFcebgJo7UKPntyggOpfPjUDo/bz4GM3bNYQwNDIiOjcPESPnMsTI31UtISC44PAprC1OCw6N47a+fmJAjoy0PfP3IndmWh6/8yJslLYYGBszuWQ+AYUv3UatSEe00QSZGhlx7/Pqr0zaldtWL5WTK9vNUKpgNtVrF1rP3cCyZiw6uZRi78fQXn0RgY2HK24BQSuTOyO0XfpTIlZECWdNRqVA25ndVzml9GRegVIyJ/WL5wPp21CiWVL0/OjaO9nP28GuT6hTI+ufVOuI1CaS1TEp4efjmk+77+fQdWdIqSWAhEdFYmZsQExfPzecf+KWBnd72Dlx9Qs1ySWPOvVcfOX3XlxO3X3DX9yPdfz/AugH1KJM3M4/fBpA/iy0PXn8ke/qfJ2aqFcjItAP3qJgnPWq1im1XfHEonIl21fMxfs9tvhhasDYz5m1QBMWz23D7dRDFs9uQP1MaKuVNz5yWynnxmDj9sbnx/FPaihyf9fcoSvWCSedFo2Pj6bTiAsNqFyd/pqTE0NI5bXnyIZR8GS158C6Y7LbmVM6fgYtPP+JdNge3XgWRK13Sudojd9/T162IznZNjAwwNVJjZmygna7pz3xeB8Da3JiI6DhUKhXGBmrMkq0fH//lX1PqVjWPFTN8XlM+ZxrUahXbb32kRj4b2lbMzMSjvnpji7WZIe9CYiiexYI778MpnsWC/OnNqJDTiln1lL/Nr8VLs9X3iP3ite1rn51qeZOmcI2OS8AkMXnK2tQQM6Ok9yYgXPmeFZ+gwTSx8ssl31BKZrXUrlM6qyXzTr9Bo9Fw8mkQZbNbEhYdz4fQGDpuepiY7BOHXW5rPIqk1evX1FCt9GmoJigyju5bHzPDOx/pLZXPuQd+EbwJjqbFmnu8CIji8MNAimQyJ1da/WmR/y0/TGJM8+bNKVOmDBcuKCUKnZ2dadWqFQcPHiRNmjRkzKh7gaVt27a0atWK5cuXa0/alyxZkqJFi2Jvb49araZKlSpMmDBBZ72UVIxxc3NjzZo11KhRg6ioKMaOHUuaNGm4fl0pC+rj48POnTvx9vYGYPPmzXrTKHXs2JGlS5eyceNGli5dirGxMaVKlcLb25t3795Ru3ZtLC0tMTQ05PfffwdgwIAB3Lt3j/j4eDp37qz3nH92zZs1pWy5Cpw/p9z54ezkSOs2bTl08DBp0ljq3Xndtk1rWrdpy4oVK3VipEjRojg4OqFWq6lcuTITxutOeZLSijGubu7cu3efBw8f0q5tWzp37sSli0r8rly5iqDgIKpUqULTps0JCAikWXPli9z8eXMxMDCgc5euGCTekTBn9iwAJk2eQsMG9cmfPz+OTs4YGBhQsGBBZs1U7sb7bfRo6njVxdjYmCyZs+Du7vaH+/Kza960MWUrVuH8aR8AnJ0caN2uI4cOH1HGlAxfjCmtW9K6XUdWrFqdFC8lSlCkcGEcXNyUeKlUkQljdadTSknFmOUrV3Hj1i1Gj1VirVOH9njVrkXvfgOoXKkijq7u5MyRg1XLl7Lg98Xs3ruXhIQE8ufPR906dbhx8yadu/XA0tKSNJaWLF+iTCMwaeo0GtarR5EihcmTJw/VHJyIiYlhYP++AJw9qUwB9uLFS/oNHESXTh1ZuGix3r40b9rku17j1KJZ44aUq1KDcz7KtCZODva06diVg0eOJn7+6N6l36Zlc9p07MKK1WuTxUpxihYujKObpxIrFSsyfsxInfVSUjHmwqXLjBozHgMDA4yNTVi6ULkzasLYUXg3UqYimDxBicGa7q7s3X8QZ4/aWFhYsG7lUp6/eEmXHr21Y8vs6cr0F5OnzaRBvbrkz5eXhvW9qeHsgbmFOauXKrE0esQwvBo0wdjYiMyZM+OeWDVk38HDeLjpTnnws2vWqAHlqzlx9pgyxZaTfXXadu7BoaPHSWNpScb0X8RLi6a07dyDlWvXY2KiXIwpWbwYRQoXwrGmV2K8lGf8KN3pH1NSMebC5SuMGjcJAwMDTIyNWTJ/NgCD+vbCwcMLAwMDypcpRfGiRZg/M2kKnnJVHZg7YwpBQcHUa9YKtVpNXFwcE35T9mHVug3ky5uHalUq07xtJ/w+fiRLpkw629i8fScTk8V42rS2NK7vjYNHHTQajU7bn1XThnWp4FCTM4eUqk2ONarRtlsfDh/3wdLSkgxfVABp3awxbbv1YeW6TZgYJ44txYpQtFBBnOo0VGKlfFnGjRiis15KKsacPn+R3ybPwMLcjCyZMrJ0rnJcMX7kUOq1aA/ApN+Ga9tv3rGHRt61tf9Pny4tDbxqY+9ZHwtzM1YuVGJtyqz51PfyJH/ePLTu0psLl6+yc99Bbt97wK+D+jKwVzc69OzPhOlzqFC2NOXLlKJ8maQLYOXs3SUpJlHT+nWo6OLNmX1KBUrH6lVo13Mwh06cJo2lhV4VkFZN6tOu5yBWbtyqvdBbsmhhihTMj7N3C9RqNZXKl2bcsAE666WkYkxaWxsa1fXEybs5Go2GuZN/o0jB/Jw/pEzFtXrjdoJCQqhcvgw3797nl9GTePbiFR6N2jBmaH8CAoPYd/gE7977sWzNJmq7O9G3a3umzF1E/doe5M+Tiwa1PXDwaoaFuRkr5injxZrNO1i2dhOPn77Ao1Ebdq5ZTLHCBSiQNzfO3i0wNDRg2Zwpf/u1/tE1retBxVrNOb1jFQBOdhVp138Eh0+eI42FBRm+qNDTumEd2vUbwarNu7SxUqJIQQoXyINL445KrJQtwdjBvXTWS0nFGNcalVm/Yx/OjTsQFR3DqP7KXdtdfxlDjqyZ8WjeFSNjI/avWcC88UmVxCrUbMqcsUplicZeHtSo1waNBurXdMEqjSWHfM4SHhFJfU8Xpi9axZY9h/gYEMTrdx/Y9Ps0Zi1dy9FTyh2VNZ2qU6Z4EQ6eOMu+Y6d498GfZeu3U8vVnr4dW37nq/xja1Lbhcr1O3Jyo5Kw7VilHB0Gj+PI6YtYWpiT4YuqBa3q16TD4HGs2r5PW8GpRKF8FM6fG9eWvZQYKV2MMf0766yX0ooxnu36cf/JCx4+96VNfU86NPFi7IAuNOymxMCEwd0BuPXgCUMmz+eZ7xs82/VjdN9OVCxVlHaDxnLh+h12Hz3NnYdPGdajLQC7j57iwMpZ2n5u3n/Muau36NayAWP6dab7yCnExsYzoGNzDA0N2b7vGEs27EStVmNjbcnSicNJY2mOk51yQXTc3OWULFLgp0qKAWhc0x67Zn3wWTUNAIdKpej46wyOnL2GpYUZGdJa67Rv6eVMx19nsHrXUUyMlZOjJQrmoXDenLh3GIJaraZiycL81qu1znoprRhTq8uvPHj2ikcv3tC6rguNa9ozYMoiKpYohEfHoWTPnIGl4/qzePM+9vlcJCFBQ76cWantUImnr97Rc8w8DBLvipz2i1L1cnSv1vQcM4/YuDj6t22AoaEBNx8+4/z1e3RtWptfu7WgYZ+xGBsakjmDLS5Vyn51X9o38CA2No5Ltx4wf2TP73/Rf1CNXatQtf0Iji9SvgM4lC9Kp7GLOHLxNmnMTfUqgLSsWZ1OYxexZt8pTIyU09PF8+ekcO5sePQcj1qlpmLx/Izuons+NaUVY+r0mcSDF2959PIdrWrVoH1dR04uVRI+1+4/TXBYOJWKFyBbhrR0HreYBZsPoUHD4l+VuGg7aj7+gSFkTmfDzIFtATj2u/LcXr7z55c562jv7cSHT0Es2naUkZ0bMrCVF/1nrMLQwABTYyNW/NadF+/86TV5OQbqxLjr1wqA6Wv2cOzSHUyMDJnYq/lffbl/eA0dy1GjxzSOzuoLgH3pAnSduo6jV+6TxtyU9F9UAWnuWokuU9ey9tDFpHjJm5XCuTLjOWguapWKikVyM7JdbZ31Uloxpu6QBTz0fc/j1360dKtEW087YuPiufzgBXP6Jp0Tc61QhIMX71J78DwszExY+ksrXr7/RO/Zm7Tv8ZTuyjShfRo50336eqZtOELZQjkpUzAnt56+5sLd53T2Um5o2XvuNrsnd9du/9bT1wz9fQcGBmpq25WkZD6lOk0Dh7K49puFRqOhbvVSWFn8dy4u/dMa1iiFfb/5HJmi/G3al8xLl1lbOXbtMZZmJmSw1r2Bp5lzWbrO3MK6o1eTYiV3ZgrlyEitYUtQq1RUKJyTka10p4pOacUY7xHLefjKj8evP9LCpSxt3SsydOk+7r54TxpzE6Z1UaanXrb/Ivsv3Vc+h7Kmw7OicrG684zNXHrgy94L97j74j2DmzrRcfomQiOiiY9PYFRrd9RqNbefveX8/Zd0rlWFES1d6TN/J3Hx8fSpXwNDAwNuP3vL0GX7MVCrqFW5KCXyZuXdpxCajluNhakJhgZqZnT7+aYObWhXBIdhqzk0RrnOUqNYLrot3M/xmy+wNDUmwxcVY5rZF6fbgv2sO3lHW9GlWM4MFMqWjjpjNqJWqyifPysjmupORZ+SijHrfO5w56Ufk7cqU1m3dipFw6pFmLvnEjvOP+RjaARvPoWyql9dOrmVofvCAyw6eBWNBhZ0q0lAWBTNp27HwtQYA7WK6R1cARix1oeHbz4Rn5BAG6dSZLC24ENQOEsPX2d4Y2XmgJ0XHjKqWVKlkgHelRngXRkAr7EbWZCY9DOiaXX6LT1MVEwcdSsVIpON/g1xqVX98jlxmXKU/f2Vm92rF8xIjzWXOH7/PZYmhqS31B1nm1TKRc81l9lw4YU2waBYNhsKZrbCe7YPKpWK8nnSMrxOCZ31UlIxZsOFF9x9HcTUA3fhALS0y0uD8jkZXqcEAzZeJSo2Hq/S2cloZYpzkcwcvvOOenNOYmFiyO9tlBtTbvgGkD+jJRYmSZf8B266xuuAcGLiEqhfPifpLE248zqIi88+0qFGfjZfesmac8946hdGw3mnWNulKgduvWXVmafKTbXmRsxtWQELE0PqlcuB54wTaNBQu1Q2nemafgbeJdPj/vst9nRU3t9qea3ps/0xPk+CsDQ2IP0XFWMal85A7+1P2HTdD2MDpX5M0cwWFMxgRoPld1CpVJTLkYahLjl11ktJxZhrr0OZevwVapUKE0MV0+oqCZzDXHPSdoMyndwIt1za9rvvfKRO8aRzhmktjKhdNB3ey+5ibqxmTv38WJoYcLibcj723PNgDj4IwKNIWu68C+eybwjtKmVh8O5nvAmOJiY+gXol0pPWwojxh1/yLiSGoXuVKb362menRj4bauSzAWD6iVcUy2zxn0qKAVB9mVWb4hVVqjoODg5rTpw4Yf3t1uJHV6BAgeAnT544azSab08K/hXp06e/smH9unIuLs7fbix+aKtXr6Ff/wE7AwIC6n3P+iqVqkSunDnPPH/84OdJUf6JWdqmj46IiMim0Wg+fc/66dOnO7JgzkyXhvV+vi97P5u5C37n19Fjl4SGhnX+dmt9KpWqesnixfZcO+cjxy0/gaz5ioT5+X8srdFovj2BdCKVStWqXh3PBZtXLvrjyb9FqlbFpXbwles3G2g0mmPfamtmahr+7NpJ8y+nARI/h1v3HuDs3cI3KDgk17faqlSqXh2bN5gyf8Lw/9aZAPH/pnbrHiFHTp1vr9Fotn2rrZmpSfhjn63mX5v+R6R+tx8+xbVlL9+gkNCUjC2t6jrbLVg/bagct/ykarTsH3z17uOUHbeYGIff3z7LPP13TEsmfnx3nvji0XOCb1BoeIqOW9p62k2Z1buxHLf8pOoP/z3k+NUHKTpusTI3/eAzs0fGvFnSfaupSIXO3n1Oq4nrbgeERJT82uMqlSqHjYXpg6dLen577hbxU0nXfBqAoUaj0ZbdsTE33jiybskmLe3y/Hs7Jv5zph+4x9SD98YlJGhGfO1xlUrVq2X5jFMm18knxy0/qear74WcfBqcouOWz9TfbvKHAj58+KD6djPxo9NoNAQEBBgBf2NCMM1HPz+//9k+if+uD35+REdHf/gbmwgIDAw0Skj4ecqC/qyioqKIjo42BEK/dxtxcXF+/n7+/8O9Ev9V79/7JURGRv2tseXjp08G35sQLH4c8fHxBIeEGvPXj1sC3n/4IB8+PymNRoOf/0c1KYwbY2OjUL+PAf/wXon/Kj//Txio1UEpbB7w9oO/fr128dN47/cRUji2GBkZhvp/CvpH90f8d/l9DPhLY8uHjwFy3PKT0mg0+AUEpfi4xcjQMPRjYMg/vFfiv8ovMAS1WhWUwuYB7z8Fy3HLT+xDQAikcGwxMFAH+weF/bM7JP6zEt/7P/tSHBgeFWP8M039Jb7tY0gERobqaEAnMKLj4t9/DIv6l/ZK/Fe9C46M1mj+9DMp4H3IV+bHEz8Nv7BY+IvXAP5OYswNX1/fkHHjxsXFfmV+YJE6REdH07Nnz+jY2NhnwMvv3U5ISOiKPn37Rd69e1dv7k+ROmg0Gs6fP8+4ceMjIyIiNv6NTb3VwIMu3XtGR0XJwVBqFR4eTsMmzSMtLSwOajSamO/dTnBwyJrho8dEXrl6XcaWVCohIYFjJ04yd+HvUfHx8bv+xqYehYSGvhv866iYmJjvDjnxHxcZGUnbzj2iTIyNr2g0mr+atXDh5p170fMWr0iIi5PvVD+TmJgYRoybEhsQGOQP3EvJOhoNa1p27Rfu5/9dBc/ED+yF72s69xsWERkVvSyFq5z0OXcpbvXW3Zr4eP356UXqFRsby/TfV8U9e/k6HLiSopU0rGndf3S436e/cU+K+CG9fP2OrsMnR0RGp3hsuXDr4fPohRv2JMTFydjyM4mJjWX0vDWxgcGhKT5uAc2atqMXhPtLcsxP5+U7f3pMXBoRFR2b4uOWkzcexa0/ckkTLxezfyqxcfHM3nIs7vm7jyk+bomJjVvRbdbWiDcfg//hvRP/JRqNhsev/Rm8aE9EeGTMH44tGo0mzNTY8EyneXsjI6Ll+qGAkIho2s7aHWFmbLRF88WJ/KjYhK1zjjyMvPDUX87xCxISNBy8/Zatl31jgQN/0vTk2efBcZuv+2niEyRufiax8QksOPMm7mVAVMrPtyT67qmUAFQqVVYrK6sj4eHhhQwMDORoORWKj49XWVpaXgkODq6p0WiC/s62TExMOqlVqplx8fGmarVK4iWViY9PUBsbG4dFRka20Wg0f+fiNSqVysra2mpfWFh4ZQO1Wj7RUhlN4mePhYXFweDg4IYajSb672xPrVY3NjExWRoXF2euVsnYktrEJySoTYyNgyMiIxunpEz4n1GpVOmsrNIcDg+PKKmWsSVV0mg0Kgtz81PBISFeGo0m/K+ur1Kp8qaxtDgcERmVW61Wy3jyk0hISFBbmJvdCQkNc9NoNCkqcahSqVRpLC1mR0VHd0GDGpVKxpSfgEajUanVqjgDA4OxERGRE1K6nkqlKmppbnYwMjo6q4wtP4+EhAS1uanpk9DwCFeNRvMqJeuoVCpVGgvz2VHRMV0ANSpkbPkJaDQalVqljjMwUI+NiIz6K2NLXktzs8ORUdFy3PITSUhIUJubmd4JDY/4S8ctluams6NjYpWxBRlbfgYaDcpxi1o9NiIq+i8dt1iYGh+MionLKudvfx4JCRq1mYnRk7DI6L903GJuYjQmNj5hkEajMVDJd6KfgkajURuo1dEajWZQdGzcgj9rq1KpzKzMTXZGRMU4SXz89FQa0JgZG24NjYxprdFo9O5IU6lUnmZGButi4hPSqFXI589PLEGD2sRQ/SkiJr6uRqO58GdtVSpVUQtj9cGo2AQ5bvmJJCRo1GZGBk/CYuJTfNzy2d9KjNFuRKUyAoz/9obEf1H01z6k/g6VSmUOyDRcqU+CRqOJ/F9uUKVSGQIm/8ttiv+MSI1G8z89UFGpVGb8vUpo4r8pXqPR/E/LR8nYkqpFJZ+j+HupVCpjwOh/sD/ixxCj0Wi+6xY2lUqlAmTO9J9LxJd3t6WUjC0/HRlbxF8hY4tIKRlbxF8hY4tIKRlbREppNBpNxF9ZQaVSGQCm/9D+iB9Hiq4HqFQqU8Dg/2F/xH9X3F+9mVqOW34633/cImWphBBCCCGEEEIIIYQQQgghhBBCCCFEaiR31gshhBBCCCGEEEIIIYQQQgghhBBCiFRJEmOEEEIIIYQQQgghhBBCCCGEEEIIIUSqJIkxQgghhBBCCCGEEEIIIYQQQgghhBAiVZLEGCGEEEIIIYQQQgghhBBCCCGEEEIIkSpJYowQQgghhBBCCCGEEEIIIYQQQgghhEiVJDFGCCGEEEIIIYQQQgghhBBCCCGEEEKkSpIYI4QQQgghhBBCCCGEEEIIIYQQQgghUiVJjBFCCCGEEEIIIYQQQgghhBBCCCGEEKmSJMYIIYQQQgghhBBCCCGEEEIIIYQQQohUSRJjhBBCCCGEEEIIIYQQQgghhBBCCCFEqiSJMUIIIYQQQgghhBBCCCGEEEIIIYQQIlWSxBghhBBCCCGEEEIIIYQQQgghhBBCCJEqSWKMEEIIIYQQQgghhBBCCCGEEEIIIYRIlSQxRgghhBBCCCGEEEIIIYQQQgghhBBCpEqSGCOEEEIIIYQQQgghhBBCCCGEEEIIIVIlSYwRQgghhBBCCCGEEEIIIYQQQgghhBCpkiTGCCGEEEIIIYQQQgghhBBCCCGEEEKIVEkSY4QQQgghhBBCCCGEEEIIIYQQQgghRKokiTFCCCGEEEIIIYQQQgghhBBCCCGEECJVksQYIYQQQgghhBBCCCGEEEIIIYQQQgiRKklijBBCCCGEEEIIIYQQQgghhBBCCCGESJUkMUYIIYQQQgghhBBCCCGEEEIIIYQQQqRKkhgjhBBCCCGEEEIIIYQQQgghhBBCCCFSJUmMEUIIIYQQQgghhBBCCCGEEEIIIYQQqZIkxgghhBBCCCGEEEIIIYQQQgghhBBCiFRJEmOEEEIIIYQQQgghhBBCCCGEEEIIIUSqJIkxQgghhBBCCCGEEEIIIYQQQgghhBAiVZLEGCGEEEIIIYQQQgghhBBCCCGEEEIIkSpJYowQQgghhBBCCCGEEEIIIYQQQgghhEiVJDFGCCGEEEIIIYQQQgghhBBCCCGEEEKkSpIYI4QQQgghhBBCCCGEEEIIIYQQQgghUiVJjBFCCCGEEEIIIYQQQgghhBBCCCGEEKmSJMYIIYQQQgghhBBCCCGEEEIIIYQQQohUSRJjhBBCCCGEEEIIIYQQQgghhBBCCCFEqiSJMUIIIYQQQgghhBBCCCGEEEIIIYQQIlWSxBghhBBCCCGEEEIIIYQQQgghhBBCCJEqSWKMEEIIIYQQQgghhBBCCCGEEEIIIYRIlSQxRgghhBBCCCGEEEIIIYQQQgghhBBCpEqSGCOEEEIIIYQQQgghhBBCCCGEEEIIIVIlSYwRQgghhBBCCCGEEEIIIYQQQgghhBCpkiTGCCGEEEIIIYQQQgghhBBCCCGEEEKIVEkSY4QQQgghhBBCCCGEEEIIIYQQQgghRKokiTFCCCGEEEIIIYQQQgghhBBCCCGEECJVksQYIYQQQgghhBBCCCGEEEIIIYQQQgiRKklijBBCCCGEEEIIIYQQQgghhBBCCCGESJUkMUYIIYQQQgghhBBCCCGEEEIIIYQQQqRKkhgjhBBCCCGEEEIIIYQQQgghhBBCCCFSJUmMEUIIIYQQQgghhBBCCCGEEEIIIYQQqZIkxgghhBBCCCGEEEIIIYQQQgghhBBCiFRJEmOEEEIIIYQQQgghhBBCCCGEEEIIIUSqJIkxQgghhBBCCCGEEEIIIYQQQgghhBAiVZLEGCGEEEIIIYQQQgghhBBCCCGEEEIIkSpJYowQQgghhBBCCCGEEEIIIYQQQgghhEiVJDFGCCGEEEIIIYQQQgghhBBCCCGEEEKkSpIYI4QQQgghhBBCCCGEEEIIIYQQQgghUiVJjBFCCCGEEEIIIYQQQgghhBBCCCGEEKmSJMYIIYQQQgghhBBCCCGEEEIIIYQQQohUSRJjhBBCCCGEEEIIIYQQQgghhBBCCCFEqiSJMUIIIYQQQgghhBBCCCGEEEIIIYQQIlWSxBghhBBCCCGEEEIIIYQQQgghhBBCCJEqSWKMEEIIIYQQQgghhBBCCCGEEEIIIYRIlSQxRgghhBBCCCGEEEIIIYQQQgghhBBCpEqSGCOEEEIIIYQQQgghhBBCCCGEEEIIIVIlSYwRQgghhBBCCCGEEEIIIYQQQgghhBCpkiTGCCGEEEIIIYQQQgghhBBCCCGEEEKIVEkSY4QQQgghhBBCCCGEEEIIIYT4v3btQAYAAABgkL/1Pb7iCABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYEmMAAAAAAAAAAFgSYwAAAAAAAAAAWBJjAAAAAAAAAABYCmj/VEniDQGOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2880x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_model.fit(X_train, Y_train)\n",
    "\n",
    "random_tree = random_forest_model.estimators_[np.random.randint(0, len(random_forest_model.estimators_))]\n",
    "\n",
    "features=['color', 'clarity', 'carat', 'cut', 'symmetry', 'polish', 'depth_percent', 'table_percent', 'length', 'width', 'depth']\n",
    "\n",
    "plt.figure(figsize=(40, 20))\n",
    "plot_tree(random_tree, feature_names=features, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is selected for branching at the root node? What can you infer about the importance of this feature as opposed to others? Do the important features correspond to what you got in part 3.3.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selected for branching at root node:  color\n"
     ]
    }
   ],
   "source": [
    "root_feature_index = random_tree.tree_.feature[0]\n",
    "\n",
    "root_node_feature = X.columns[root_feature_index+1]\n",
    "\n",
    "print(\"Feature selected for branching at root node: \", root_node_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4\n",
    "Measure Out-of-Bag Error (OOB). Explain what OOB error and R2 score means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Bag (OOB) Error: 0.9950822723496566\n"
     ]
    }
   ],
   "source": [
    "print(f'Out-of-Bag (OOB) Error: {random_forest_model.oob_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OOB error is the error that provides an estimate of the model's performance on unseen data based on out of bag samples. Out of bag samples are data points that were not used in the training of the individual trees. A low OOB error indicates better model performance.\n",
    "The R2 score is a metric that is used to evaluate the goodness of fit of a regression model. For the Random Forest Regressor, the R2 score measures the proportion of the variance in the target variable that is explained by the independent variables in the model. This measure how well the model fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1\n",
    "Read the documentation of LightGBM OR CatBoost and determine the important hyperparameters along with a search space for the tuning of these parameters (keep the search space small)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM is a boosting framework that utilizes tree-based learning algorithms. Some of the important hyperparameters are:\n",
    "* num_leaves\n",
    "    - Maximum number of leaves in one tree\n",
    "    - Search space: [8, 256] \n",
    "\n",
    "* metric \n",
    "    - objective function \n",
    "    \n",
    "* max_depth - use default value \n",
    "    - Maximum depth of each tree\n",
    "    - Search space: [3, 16] \n",
    "\n",
    "* min_data_in_leaf\n",
    "    - Min number of data points in one leaf\n",
    "    - Search space: [5, 300] \n",
    "\n",
    "* lambda_l2 \n",
    "    - L2 regularization term\n",
    "    - Search space: [0.01, 100] \n",
    "\n",
    "* learning_rate\n",
    "    - Controls the step size at each iteration during the boosting process\n",
    "    - Search space: [0.05, 0.1, 0.2]\n",
    "\n",
    "* n_estimators\n",
    "    - Number of boosting iterations to be used in the model\n",
    "    - Search space: [100, 200, 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2\n",
    "Apply Bayesian optimization using skopt.BayesSearchCV from scikit-optmize to find the ideal hyperparameter combination in your search space. Keep your search space small enough to finish running on a single Google Colab instance within 60 minutes. Report the best hyperparameter set found and the corresponding RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-optimize in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (0.10.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-optimize) (23.12.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-optimize) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-optimize) (1.2.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-optimize) (23.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dhakshina\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space for hyperparameters\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.0),\n",
    "    'metric': ('rmse', 'l2', 'l1'),\n",
    "    'lambda_l2':(0,1),\n",
    "    'min_data_in_leaf': (20,100),\n",
    "    'max_depth': (1, 10),\n",
    "    'n_estimators': (50, 100),\n",
    "    'num_leaves': (10, 20),\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=LGBMRegressor(objective='regression'),\n",
    "    search_spaces=param_space,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter = 100,\n",
    "    verbose=0,\n",
    "    random_state = 42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=89, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=89\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=67, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=67\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=26, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=26\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1519\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1508\n",
      "[LightGBM] [Info] Number of data points in the train set: 95916, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3308.401977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3286.829071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3305.208368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3309.798065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Number of data points in the train set: 95917, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 3299.437263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1528\n",
      "[LightGBM] [Info] Number of data points in the train set: 119896, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 3301.934935\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(objective=&#x27;regression&#x27;), n_iter=100,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;lambda_l2&#x27;: (0, 1), &#x27;learning_rate&#x27;: (0.01, 1.0),\n",
       "                             &#x27;max_depth&#x27;: (1, 10),\n",
       "                             &#x27;metric&#x27;: (&#x27;rmse&#x27;, &#x27;l2&#x27;, &#x27;l1&#x27;),\n",
       "                             &#x27;min_data_in_leaf&#x27;: (20, 100),\n",
       "                             &#x27;n_estimators&#x27;: (50, 100),\n",
       "                             &#x27;num_leaves&#x27;: (10, 20)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(objective=&#x27;regression&#x27;), n_iter=100,\n",
       "              random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;lambda_l2&#x27;: (0, 1), &#x27;learning_rate&#x27;: (0.01, 1.0),\n",
       "                             &#x27;max_depth&#x27;: (1, 10),\n",
       "                             &#x27;metric&#x27;: (&#x27;rmse&#x27;, &#x27;l2&#x27;, &#x27;l1&#x27;),\n",
       "                             &#x27;min_data_in_leaf&#x27;: (20, 100),\n",
       "                             &#x27;n_estimators&#x27;: (50, 100),\n",
       "                             &#x27;num_leaves&#x27;: (10, 20)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(objective=&#x27;regression&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(objective=&#x27;regression&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=LGBMRegressor(objective='regression'), n_iter=100,\n",
       "              random_state=42, scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'lambda_l2': (0, 1), 'learning_rate': (0.01, 1.0),\n",
       "                             'max_depth': (1, 10),\n",
       "                             'metric': ('rmse', 'l2', 'l1'),\n",
       "                             'min_data_in_leaf': (20, 100),\n",
       "                             'n_estimators': (50, 100),\n",
       "                             'num_leaves': (10, 20)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fit(X_train.values, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: OrderedDict([('lambda_l2', 0), ('learning_rate', 0.22651823566087775), ('max_depth', 10), ('metric', 'rmse'), ('min_data_in_leaf', 20), ('n_estimators', 100), ('num_leaves', 20)])\n"
     ]
    }
   ],
   "source": [
    "best_params = opt.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "RMSE on Test Set: 281.8305470615835\n"
     ]
    }
   ],
   "source": [
    "best_model = opt.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = mean_squared_error(Y_test, y_pred, squared=False)\n",
    "print(\"RMSE on Test Set:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3\n",
    "Qualitatively interpret the effect of the hyperparameters using the Bayesian optimization results: Which of them helps with performance? Which helps with regularization (shrinks the generalization gap)? Which affects the fitting efficiency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance \n",
    "\n",
    "* learning_rate : a smaller learning rate may lead to better performance by allowing it to find better minimum. \n",
    "\n",
    "* max_depth : Increasing max_depth may lead to an increase in performance by allowing the model to capture more complex relationships.\n",
    "\n",
    "* n_estimators : Increasing the number of trees may lead to an increase in performance, as the model will be allowed to learn from more diverse subsets of the data.\n",
    "\n",
    "Regularization\n",
    "\n",
    "* lambda_l1 : Lasso Regression adds a penalty term to the absolute weights of the features. \n",
    "\n",
    "* lambda_l2 : Ridge Regression adds a penalty term to the squared weights of the features. \n",
    "\n",
    "* max_depth : constraining max_depth may prevent overfitting by regularizing complexity of the trees. \n",
    "\n",
    "* min_data_in_leaf : setting higher values for this parameter ensures that every leaf contains a minimum number of training instances.\n",
    "\n",
    "Fitting Efficiency : refers to how quickly the model can be trained on the dataset\n",
    "\n",
    "* n_iter : number of iterations determines the total no of trees to be built during training. \n",
    "\n",
    "* learning_rate : controls the step size at each iteration and helps the model converge and generalize better. \n",
    "\n",
    "* max_depth : limiting max_depth of the trees can help control the complexity of the model and prevent overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1\n",
    "Report the following statistics for each hashtag, i.e. each file has:\n",
    "- Average number of tweets per hour\n",
    "- Average number of followers of users posting the tweets per tweet (to make it simple, we average over the number of tweets; if a users posted twice, we count the user and the user's followers twice as well)\n",
    "- Average number of retweets per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def tweet_statistics(tweet_file):\n",
    "    hours = []\n",
    "    followers = []\n",
    "    retweets = []\n",
    "    total_tweets = 0\n",
    "\n",
    "    data_path = './ECE219_tweet_data'\n",
    "\n",
    "    tweet_path = os.path.join(data_path, f'{tweet_file}')\n",
    "\n",
    "    with open(tweet_path, encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            total_tweets += 1\n",
    "            hours.append(tweet['citation_date'])\n",
    "            followers.append(tweet['author']['followers'])\n",
    "            retweets.append(tweet['metrics']['citations']['total'])\n",
    "\n",
    "    avg_tweets_per_hour = total_tweets / ((max(hours) - min(hours)) / 3600.0)\n",
    "    avg_followers_per_tweet = sum(followers) / float(total_tweets)\n",
    "    avg_retweets_per_tweet = sum(retweets) / float(total_tweets)\n",
    "\n",
    "    return {\n",
    "        'Average tweets per hour': avg_tweets_per_hour,\n",
    "        'Average followers per tweet': avg_followers_per_tweet,\n",
    "        'Average retweets per tweet': avg_retweets_per_tweet\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Statistics for: tweets_#gohawks.txt --------------------\n",
      "Average number of tweets per hour:  292.48785062173687\n",
      "Average number of followers of users posting the tweets per tweet:  2217.9237355281984\n",
      "Average number of retweets per tweet:  2.0132093991319877\n",
      "-------------------- Statistics for: tweets_#gopatriots.txt --------------------\n",
      "Average number of tweets per hour:  40.95469800606194\n",
      "Average number of followers of users posting the tweets per tweet:  1427.2526051635405\n",
      "Average number of retweets per tweet:  1.4081919101697078\n",
      "-------------------- Statistics for: tweets_#nfl.txt --------------------\n",
      "Average number of tweets per hour:  397.0213901819841\n",
      "Average number of followers of users posting the tweets per tweet:  4662.37544523693\n",
      "Average number of retweets per tweet:  1.5344602655543254\n",
      "-------------------- Statistics for: tweets_#patriots.txt --------------------\n",
      "Average number of tweets per hour:  750.89426460689\n",
      "Average number of followers of users posting the tweets per tweet:  3280.4635616550277\n",
      "Average number of retweets per tweet:  1.7852871288476946\n",
      "-------------------- Statistics for: tweets_#sb49.txt --------------------\n",
      "Average number of tweets per hour:  1276.8570598680474\n",
      "Average number of followers of users posting the tweets per tweet:  10374.160292019487\n",
      "Average number of retweets per tweet:  2.52713444111402\n",
      "-------------------- Statistics for: tweets_#superbowl.txt --------------------\n",
      "Average number of tweets per hour:  2072.11840170408\n",
      "Average number of followers of users posting the tweets per tweet:  8814.96799424623\n",
      "Average number of retweets per tweet:  2.3911895819207736\n"
     ]
    }
   ],
   "source": [
    "tweetfiles = ['tweets_#gohawks.txt', 'tweets_#gopatriots.txt', 'tweets_#nfl.txt', 'tweets_#patriots.txt', 'tweets_#sb49.txt', 'tweets_#superbowl.txt']\n",
    "\n",
    "for tweet in tweetfiles:\n",
    "    stats = tweet_statistics(tweet)\n",
    "\n",
    "    print(\"-\"*20 + f\" Statistics for: {tweet} \" + \"-\"*20)\n",
    "    print(\"Average number of tweets per hour: \", stats['Average tweets per hour'])\n",
    "    print(\"Average number of followers of users posting the tweets per tweet: \", stats['Average followers per tweet'])\n",
    "    print(\"Average number of retweets per tweet: \", stats['Average retweets per tweet'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2\n",
    "Plot \"number of tweets in hour\" over time for #SuperBowl and #NFL (a bar plot with 1-hour bins). The tweets are stored in separate files for different hashtags and files are named as tweet_[#hashtag].txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_in_hour(tweet_file):\n",
    "    hours = []\n",
    "\n",
    "    data_path = './ECE219_tweet_data'\n",
    "\n",
    "    tweet_path = os.path.join(data_path, f'{tweet_file}')\n",
    "\n",
    "    with open(tweet_path, encoding=\"utf8\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            hours.append(tweet['citation_date'])\n",
    "\n",
    "    return hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number_of_tweets_in_hour(hashtag, tweet_file):\n",
    "    num_hours = tweets_in_hour(tweet_file)\n",
    "\n",
    "    tweets_per_hour= [0] * int((max(num_hours) - min(num_hours)) / 3600 + 1)\n",
    "\n",
    "    for i in num_hours:\n",
    "        tweets_per_hour[int((i - min(num_hours)) / 3600)] += 1\n",
    "    \n",
    "    x_vals = [i for i in range(0, len(tweets_per_hour))]\n",
    "    \n",
    "    plt.bar(x_vals, tweets_per_hour, width = 1)\n",
    "    plt.xlabel(\"Hour\")\n",
    "    plt.ylabel(\"Number of tweets\")\n",
    "    plt.title(f\"Number of tweets in hour over time for {hashtag}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_file = \"tweets_#nfl.txt\"\n",
    "plot_number_of_tweets_in_hour(\"#NFL\", tweet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_file = \"tweets_#superbowl.txt\"\n",
    "plot_number_of_tweets_in_hour(\"#Superbowl\", tweet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "\n",
    "Library of Prediction Tasks given a tweet: \n",
    "\n",
    "- Predict the hashtags\n",
    "- Predict how likely it is that a tweet belongs to a specific team fan\n",
    "- Predict the number of retweets/likes/quotes\n",
    "- Predict the relative time at which a tweet was posted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction of Hashtag from Tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting 500 tweet data from each file to construct Dataframe (Subsampling from Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to extract the first 100 tweets from each hashtag\n",
    "# List to store tweet data\n",
    "tweet_data = []\n",
    "    \n",
    "# Directory containing tweet files\n",
    "directory = './ECE219_tweet_data'\n",
    "    \n",
    "# Loop through each file\n",
    "for filename in os.listdir(directory):\n",
    "     if filename.endswith(\".txt\"):\n",
    "        hashtag = filename.split('.')[0]  # Extract hashtag from file name\n",
    "        with open(os.path.join(directory, filename), 'r', encoding=\"utf8\") as file:\n",
    "            count = 0  # Counter to keep track of tweets for each hashtag\n",
    "                \n",
    "            # Iterate over each line (tweet)\n",
    "            for line in file:\n",
    "                if count < 500:  # Extract only the first 100 tweets\n",
    "                    tweet = json.loads(line)\n",
    "                    \n",
    "                    # Extract relevant information from the tweet\n",
    "                    tweet_info = {\n",
    "                        'tweet_text': tweet['tweet']['text'],  # Extract tweet text\n",
    "                        'citation_date': tweet['citation_date'],\n",
    "                        'total_retweets': tweet['metrics']['citations']['total'],\n",
    "                        'author_followers': tweet['author']['followers'],\n",
    "                        'hashtag': hashtag,\n",
    "                        }\n",
    "                    \n",
    "                    # Append the tweet information to the list\n",
    "                    tweet_data.append(tweet_info)\n",
    "                    count += 1  # Increment the counter\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>citation_date</th>\n",
       "      <th>total_retweets</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who do you have?!?! #nfl #NFLPlayoffs #Packers...</td>\n",
       "      <td>1421517546</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://t.co/H5JADypiEB #billbelichick #NFL #NF...</td>\n",
       "      <td>1421258906</td>\n",
       "      <td>2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One more week until the #Seahawks begin the #N...</td>\n",
       "      <td>1421518663</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have NFLSHOP on our site! 3% cash back and ...</td>\n",
       "      <td>1421380685</td>\n",
       "      <td>2</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most @SuperBowl wins: #Steelers (6), #49ers &amp;a...</td>\n",
       "      <td>1421257471</td>\n",
       "      <td>14</td>\n",
       "      <td>580.0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>@ehasselbeck a colts jersey? #GoPatriots</td>\n",
       "      <td>1421601818</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>#GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...</td>\n",
       "      <td>1421601839</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>GAME DAY !! #GoPatriots </td>\n",
       "      <td>1421601852</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Good luck, bro! #GoPatriots! RT @TheRealMikeEp...</td>\n",
       "      <td>1421601872</td>\n",
       "      <td>1</td>\n",
       "      <td>159534.0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>@NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...</td>\n",
       "      <td>1421601927</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  citation_date  \\\n",
       "0     Who do you have?!?! #nfl #NFLPlayoffs #Packers...     1421517546   \n",
       "1     http://t.co/H5JADypiEB #billbelichick #NFL #NF...     1421258906   \n",
       "2     One more week until the #Seahawks begin the #N...     1421518663   \n",
       "3     We have NFLSHOP on our site! 3% cash back and ...     1421380685   \n",
       "4     Most @SuperBowl wins: #Steelers (6), #49ers &a...     1421257471   \n",
       "...                                                 ...            ...   \n",
       "2995           @ehasselbeck a colts jersey? #GoPatriots     1421601818   \n",
       "2996  #GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...     1421601839   \n",
       "2997                        GAME DAY !! #GoPatriots      1421601852   \n",
       "2998  Good luck, bro! #GoPatriots! RT @TheRealMikeEp...     1421601872   \n",
       "2999  @NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...     1421601927   \n",
       "\n",
       "      total_retweets  author_followers             hashtag  \n",
       "0                  4              41.0         tweets_#nfl  \n",
       "1                  2             361.0         tweets_#nfl  \n",
       "2                  2               6.0         tweets_#nfl  \n",
       "3                  2            1364.0         tweets_#nfl  \n",
       "4                 14             580.0         tweets_#nfl  \n",
       "...              ...               ...                 ...  \n",
       "2995               1             164.0  tweets_#gopatriots  \n",
       "2996               1             200.0  tweets_#gopatriots  \n",
       "2997               1             233.0  tweets_#gopatriots  \n",
       "2998               1          159534.0  tweets_#gopatriots  \n",
       "2999               1             164.0  tweets_#gopatriots  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>citation_date</th>\n",
       "      <th>total_retweets</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who do you have?!?! #nfl #NFLPlayoffs #Packers...</td>\n",
       "      <td>1421517546</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://t.co/H5JADypiEB #billbelichick #NFL #NF...</td>\n",
       "      <td>1421258906</td>\n",
       "      <td>2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One more week until the #Seahawks begin the #N...</td>\n",
       "      <td>1421518663</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have NFLSHOP on our site! 3% cash back and ...</td>\n",
       "      <td>1421380685</td>\n",
       "      <td>2</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most @SuperBowl wins: #Steelers (6), #49ers &amp;a...</td>\n",
       "      <td>1421257471</td>\n",
       "      <td>14</td>\n",
       "      <td>580.0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>@ehasselbeck a colts jersey? #GoPatriots</td>\n",
       "      <td>1421601818</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>#GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...</td>\n",
       "      <td>1421601839</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>GAME DAY !! #GoPatriots </td>\n",
       "      <td>1421601852</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Good luck, bro! #GoPatriots! RT @TheRealMikeEp...</td>\n",
       "      <td>1421601872</td>\n",
       "      <td>1</td>\n",
       "      <td>159534.0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>@NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...</td>\n",
       "      <td>1421601927</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  citation_date  \\\n",
       "0     Who do you have?!?! #nfl #NFLPlayoffs #Packers...     1421517546   \n",
       "1     http://t.co/H5JADypiEB #billbelichick #NFL #NF...     1421258906   \n",
       "2     One more week until the #Seahawks begin the #N...     1421518663   \n",
       "3     We have NFLSHOP on our site! 3% cash back and ...     1421380685   \n",
       "4     Most @SuperBowl wins: #Steelers (6), #49ers &a...     1421257471   \n",
       "...                                                 ...            ...   \n",
       "2995           @ehasselbeck a colts jersey? #GoPatriots     1421601818   \n",
       "2996  #GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...     1421601839   \n",
       "2997                        GAME DAY !! #GoPatriots      1421601852   \n",
       "2998  Good luck, bro! #GoPatriots! RT @TheRealMikeEp...     1421601872   \n",
       "2999  @NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...     1421601927   \n",
       "\n",
       "      total_retweets  author_followers      hashtag  \n",
       "0                  4              41.0         #nfl  \n",
       "1                  2             361.0         #nfl  \n",
       "2                  2               6.0         #nfl  \n",
       "3                  2            1364.0         #nfl  \n",
       "4                 14             580.0         #nfl  \n",
       "...              ...               ...          ...  \n",
       "2995               1             164.0  #gopatriots  \n",
       "2996               1             200.0  #gopatriots  \n",
       "2997               1             233.0  #gopatriots  \n",
       "2998               1          159534.0  #gopatriots  \n",
       "2999               1             164.0  #gopatriots  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'tweets_' from df['hashtag']\n",
    "df['hashtag'] = df['hashtag'].apply(lambda x: x.split()[-1].replace('tweets_#', '#'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Train and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train,test = train_test_split(df[['tweet_text', 'hashtag']], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Hashtags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['hashtag'], bins=30, edgecolor='black')\n",
    "plt.title('Hashtags')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].map(clean)\n",
    "test['tweet_text'] = test['tweet_text'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642     .@DeSeanJackson11 talks #LegionOfBoom, #Redski...\n",
       "700     @chris_muther @Orbitz @Patriots @SuperBowl I l...\n",
       "226     Ohio State's Meyer: No desire to coach in the ...\n",
       "1697    Gallery: AFC Championship Game, Best and Worst...\n",
       "1010    Go H2H vs real NFL players in the #Duracell26h...\n",
       "                              ...                        \n",
       "1638    PC West cruises past Dell City 75-36 #GoPatz #...\n",
       "1095    Ponte en el Camino Al Superbowl! #SB49xESPN Co...\n",
       "1130    Ponte en el Camino Al Superbowl! #SB49xESPN Co...\n",
       "1294    Ponte en el Camino Al Superbowl! #SB49xESPN Co...\n",
       "860     I'm calling it now, Indy to win Superbowl. #Su...\n",
       "Name: tweet_text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclude Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    text_without_punctuation = text.translate(translator)\n",
    "\n",
    "    return text_without_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].apply(remove_punctuation) # Train Data\n",
    "test['tweet_text'] = test['tweet_text'].apply(remove_punctuation) # Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642     DeSeanJackson11 talks LegionOfBoom Redskins an...\n",
       "700     chrismuther Orbitz Patriots SuperBowl I like y...\n",
       "226     Ohio States Meyer No desire to coach in the NF...\n",
       "1697    Gallery AFC Championship Game Best and Worst i...\n",
       "1010    Go H2H vs real NFL players in the Duracell26hr...\n",
       "                              ...                        \n",
       "1638    PC West cruises past Dell City 7536 GoPatz tak...\n",
       "1095    Ponte en el Camino Al Superbowl SB49xESPN Con ...\n",
       "1130    Ponte en el Camino Al Superbowl SB49xESPN Con ...\n",
       "1294    Ponte en el Camino Al Superbowl SB49xESPN Con ...\n",
       "860     Im calling it now Indy to win Superbowl SuperB...\n",
       "Name: tweet_text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude terms that are numbers (e.g. 123, -45, 6.7 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nos(text):\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].apply(remove_nos)\n",
    "test['tweet_text'] = test['tweet_text'].apply(remove_nos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/vaniagrawal/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vaniagrawal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vaniagrawal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vaniagrawal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_wordnet_pos(word):\n",
    "  tag_nltk = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ,\n",
    "              \"N\": wordnet.NOUN,\n",
    "              \"V\": wordnet.VERB,\n",
    "              \"R\": wordnet.ADV}\n",
    "  return tag_dict.get(tag_nltk, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens = word_tokenize(text)\n",
    "  lemmatized_tokens = [lemmatizer.lemmatize(w,map_wordnet_pos(w)) for w in tokens]\n",
    "  return ' '.join(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].apply(lemmatize_text)\n",
    "test['tweet_text'] = test['tweet_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1081)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "X_train = count_vect.fit_transform(train['tweet_text'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1081)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = count_vect.transform(test['tweet_text'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Data to TF-IDF Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1081)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train = tfidf_transformer.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1081)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tfidf_transformer.transform(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = [1, 10, 50, 100, 200, 500]\n",
    "\n",
    "explained_variances = []\n",
    "\n",
    "for k in k_values:\n",
    "  svd = TruncatedSVD(n_components=k)\n",
    "  X_train_reduced = svd.fit_transform(X_train)\n",
    "  explained_variances.append(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "plt.plot(k_values, explained_variances, marker='o')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components (k)')\n",
    "plt.xlabel('Number of Components (k)')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=100)\n",
    "X_train_reduced = svd_model.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 100)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = svd_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 100)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of Models \n",
    "We choose to train 4 different Regression Models (Logistic Regression, Random Forest and Support Vector Machine). This is a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparmeter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to tune for each model\n",
    "rf_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}\n",
    "svm_params = {'C': [0.1, 1, 10]}\n",
    "logreg_params = {'C': [0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to store best accuracy and corresponding hyperparameters\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "model_accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#gopatriots', '#gopatriots', '#gohawks', ..., '#nfl', '#nfl',\n",
       "       '#gopatriots'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hashtag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Hyperparams for RF \n",
    "for n_estimators in rf_params['n_estimators']:\n",
    "    for max_depth in rf_params['max_depth']:\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        rf_model.fit(X_train_reduced,train['hashtag'].values)\n",
    "        rf_y_pred = rf_model.predict(X_test_reduced)\n",
    "        accuracy = accuracy_score(test['hashtag'].values, rf_y_pred)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            model_accuracy['RandomForest'] = {'rf_accuracy':best_accuracy}\n",
    "            best_hyperparameters['RandomForest'] = {'n_estimators': n_estimators, 'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'max_depth': 10}\n",
      "{'rf_accuracy': 0.8916666666666667}\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparameters['RandomForest'])\n",
    "print(model_accuracy['RandomForest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForest': {'rf_accuracy': 0.8916666666666667}}\n"
     ]
    }
   ],
   "source": [
    "print(model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cm = confusion_matrix(test['hashtag'].values, rf_y_pred)\n",
    "labels = ['#patriots', '#nfl', '#gohawks', '#superbowl', '#sb49', '#gopatriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,   1,   5,   0,   0,   0],\n",
       "       [  0,  95,   0,   4,   0,   0],\n",
       "       [  2,   0,  68,  20,   0,   6],\n",
       "       [  0,   1,  10,  89,   0,   1],\n",
       "       [  1,   0,   0,   0,  90,   0],\n",
       "       [  6,   0,   5,   3,   0,  81]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rf_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Hyperparams for SVM\n",
    "for C in svm_params['C']:\n",
    "    svm_model = SVC(C=C, kernel='rbf')\n",
    "    svm_model.fit(X_train_reduced, train['hashtag'].values)\n",
    "    svm_y_pred = svm_model.predict(X_test_reduced)\n",
    "    accuracy = accuracy_score(test['hashtag'].values, svm_y_pred)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        model_accuracy['SVM'] = {'svm_accuracy':best_accuracy}\n",
    "        best_hyperparameters['SVM'] = {'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm_accuracy': 0.9033333333333333}\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "print( model_accuracy['SVM'])\n",
    "print(best_hyperparameters['SVM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cm = confusion_matrix(test['hashtag'].values, svm_y_pred)\n",
    "labels = ['#patriots', '#nfl', '#gohawks', '#superbowl', '#sb49', '#gopatriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(svm_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Logistic Regression model\n",
    "for C in logreg_params['C']:\n",
    "    lr_model = LogisticRegression(C=C, multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    lr_model.fit(X_train_reduced, train['hashtag'].values)\n",
    "    lr_y_pred = lr_model.predict(X_test_reduced)\n",
    "    accuracy = accuracy_score(test['hashtag'].values, lr_y_pred)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        model_accuracy['Logistic Regression'] = {'lr_accuracy':best_accuracy}\n",
    "        best_hyperparameters['Logistic Regression'] = {'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_accuracy': 0.905}\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(model_accuracy['Logistic Regression'])\n",
    "print(best_hyperparameters['Logistic Regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm = confusion_matrix(test['hashtag'].values, lr_y_pred)\n",
    "labels = ['#patriots', '#nfl', '#gohawks', '#superbowl', '#sb49', '#gopatriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(lr_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: {'RandomForest': {'rf_accuracy': 0.8916666666666667}, 'SVM': {'svm_accuracy': 0.9033333333333333}, 'Logistic Regression': {'lr_accuracy': 0.905}}\n",
      "Best hyperparameters: {'RandomForest': {'n_estimators': 100, 'max_depth': 10}, 'SVM': {'C': 1}, 'Logistic Regression': {'C': 10}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy:\", model_accuracy)\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predict how likely it is that a tweet belongs to a specific team fan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting 1000 tweet data from each team fan file to construct Dataframe (Subsampling from Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to extract the first 100 tweets from each hashtag\n",
    "# List to store tweet data\n",
    "tweet_data = []\n",
    "    \n",
    "# Directory containing tweet files\n",
    "directory = './ECE219_tweet_data'\n",
    "\n",
    "team_hastags = ['tweets_#gopatriots.txt', 'tweets_#gohawks.txt']\n",
    "    \n",
    "# Loop through each file\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        hashtag = filename.split('.')[0]  # Extract hashtag from file name\n",
    "        if filename in team_hastags:\n",
    "            with open(os.path.join(directory, filename), 'r', encoding=\"utf8\") as file:\n",
    "                count = 0  # Counter to keep track of tweets for each hashtag\n",
    "                    \n",
    "                # Iterate over each line (tweet)\n",
    "                for line in file:\n",
    "                    if count < 1000:  # Extract only the first 100 tweets\n",
    "                        tweet = json.loads(line)\n",
    "                        \n",
    "                        # Extract relevant information from the tweet\n",
    "                        tweet_info = {\n",
    "                            'tweet_text': tweet['tweet']['text'],  # Extract tweet text\n",
    "                            'is_team_fan': 1 if hashtag == 'tweets_#gopatriots' else 0,\n",
    "                            'hashtag': hashtag,\n",
    "                        }\n",
    "                        \n",
    "                        # Append the tweet information to the list\n",
    "                        tweet_data.append(tweet_info)\n",
    "                        count += 1  # Increment the counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_team_fan</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I &amp;lt;3 our defense! #GoHawks http://t.co/U1pc...</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twelfth dogs are ready! #gohawks #dogslife htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Oh no big deal, just NFC West Champs and the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At http://t.co/Vd0RWOeAed -- #Seahawks #12thMA...</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good luck at Michigan, Jim Harbaugh. #GoHawks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>We know one team that is heading to Arizona......</td>\n",
       "      <td>1</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I think I just puked a little  #GBvsSEA #GoP...</td>\n",
       "      <td>1</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Fuck the hawks #GoPatriots</td>\n",
       "      <td>1</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Que jogo velho, VEM SEATTLE QUE NS VAMO DEBUL...</td>\n",
       "      <td>1</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>che partita.... e adesso tocca a noi ! \\n\\n#Go...</td>\n",
       "      <td>1</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  is_team_fan  \\\n",
       "0     I &lt;3 our defense! #GoHawks http://t.co/U1pc...            0   \n",
       "1     twelfth dogs are ready! #gohawks #dogslife htt...            0   \n",
       "2     \"Oh no big deal, just NFC West Champs and the ...            0   \n",
       "3     At http://t.co/Vd0RWOeAed -- #Seahawks #12thMA...            0   \n",
       "4     Good luck at Michigan, Jim Harbaugh. #GoHawks ...            0   \n",
       "...                                                 ...          ...   \n",
       "1995  We know one team that is heading to Arizona......            1   \n",
       "1996  I think I just puked a little  #GBvsSEA #GoP...            1   \n",
       "1997                         Fuck the hawks #GoPatriots            1   \n",
       "1998  Que jogo velho, VEM SEATTLE QUE NS VAMO DEBUL...            1   \n",
       "1999  che partita.... e adesso tocca a noi ! \\n\\n#Go...            1   \n",
       "\n",
       "                 hashtag  \n",
       "0        tweets_#gohawks  \n",
       "1        tweets_#gohawks  \n",
       "2        tweets_#gohawks  \n",
       "3        tweets_#gohawks  \n",
       "4        tweets_#gohawks  \n",
       "...                  ...  \n",
       "1995  tweets_#gopatriots  \n",
       "1996  tweets_#gopatriots  \n",
       "1997  tweets_#gopatriots  \n",
       "1998  tweets_#gopatriots  \n",
       "1999  tweets_#gopatriots  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_team_fan</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I &amp;lt;3 our defense! #GoHawks http://t.co/U1pc...</td>\n",
       "      <td>0</td>\n",
       "      <td>#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twelfth dogs are ready! #gohawks #dogslife htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Oh no big deal, just NFC West Champs and the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At http://t.co/Vd0RWOeAed -- #Seahawks #12thMA...</td>\n",
       "      <td>0</td>\n",
       "      <td>#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good luck at Michigan, Jim Harbaugh. #GoHawks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>#gohawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>We know one team that is heading to Arizona......</td>\n",
       "      <td>1</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I think I just puked a little  #GBvsSEA #GoP...</td>\n",
       "      <td>1</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Fuck the hawks #GoPatriots</td>\n",
       "      <td>1</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Que jogo velho, VEM SEATTLE QUE NS VAMO DEBUL...</td>\n",
       "      <td>1</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>che partita.... e adesso tocca a noi ! \\n\\n#Go...</td>\n",
       "      <td>1</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  is_team_fan  \\\n",
       "0     I &lt;3 our defense! #GoHawks http://t.co/U1pc...            0   \n",
       "1     twelfth dogs are ready! #gohawks #dogslife htt...            0   \n",
       "2     \"Oh no big deal, just NFC West Champs and the ...            0   \n",
       "3     At http://t.co/Vd0RWOeAed -- #Seahawks #12thMA...            0   \n",
       "4     Good luck at Michigan, Jim Harbaugh. #GoHawks ...            0   \n",
       "...                                                 ...          ...   \n",
       "1995  We know one team that is heading to Arizona......            1   \n",
       "1996  I think I just puked a little  #GBvsSEA #GoP...            1   \n",
       "1997                         Fuck the hawks #GoPatriots            1   \n",
       "1998  Que jogo velho, VEM SEATTLE QUE NS VAMO DEBUL...            1   \n",
       "1999  che partita.... e adesso tocca a noi ! \\n\\n#Go...            1   \n",
       "\n",
       "          hashtag  \n",
       "0        #gohawks  \n",
       "1        #gohawks  \n",
       "2        #gohawks  \n",
       "3        #gohawks  \n",
       "4        #gohawks  \n",
       "...           ...  \n",
       "1995  #gopatriots  \n",
       "1996  #gopatriots  \n",
       "1997  #gopatriots  \n",
       "1998  #gopatriots  \n",
       "1999  #gopatriots  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'tweets_' from df['hashtag']\n",
    "df['hashtag'] = df['hashtag'].apply(lambda x: x.split()[-1].replace('tweets_#', '#'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train,test = train_test_split(df[['tweet_text', 'is_team_fan']], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 2)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['hashtag'], bins=3, edgecolor='black')\n",
    "plt.title('Hashtags')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].map(clean)\n",
    "test['tweet_text'] = test['tweet_text'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968     @PRichJr10 #Faster and #Stronger than ever! #D...\n",
       "240     Cold in the UK today so it gives me an excuse ...\n",
       "819     \"@CenturyLinkSEA: @itsbrownbaby Did you enter ...\n",
       "692     Anyone know who's raising #12thMan flag at @Ce...\n",
       "420     Left a blessing on my English paper for my tea...\n",
       "                              ...                        \n",
       "1130                        @Cejudoo @kari_iv #GoPatriots\n",
       "1294    @gavin_danny hell yeah #amentothat #pats #GoPa...\n",
       "860     \"I don't like the Seahawks\" #FiveWordsToRuinAD...\n",
       "1459         so ready for the pats game today #GoPatriots\n",
       "1126    Hockey final from Orange Classic - @HockeyLibe...\n",
       "Name: tweet_text, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].apply(remove_punctuation) # Train Data\n",
    "test['tweet_text'] = test['tweet_text'].apply(remove_punctuation) # Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968     PRichJr10 Faster and Stronger than ever DontBl...\n",
       "240     Cold in the UK today so it gives me an excuse ...\n",
       "819     CenturyLinkSEA itsbrownbaby Did you enter the ...\n",
       "692     Anyone know whos raising 12thMan flag at Centu...\n",
       "420     Left a blessing on my English paper for my tea...\n",
       "                              ...                        \n",
       "1130                            Cejudoo kariiv GoPatriots\n",
       "1294    gavindanny hell yeah amentothat pats GoPatriot...\n",
       "860     I dont like the Seahawks FiveWordsToRuinADate ...\n",
       "1459          so ready for the pats game today GoPatriots\n",
       "1126    Hockey final from Orange Classic  HockeyLibert...\n",
       "Name: tweet_text, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude terms that are numbers (e.g. 123, -45, 6.7 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].apply(remove_nos)\n",
    "test['tweet_text'] = test['tweet_text'].apply(remove_nos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_text'] = train['tweet_text'].apply(lemmatize_text)\n",
    "test['tweet_text'] = test['tweet_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 635)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "X_train = count_vect.fit_transform(train['tweet_text'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 635)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = count_vect.transform(test['tweet_text'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data to TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 635)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train = tfidf_transformer.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 635)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tfidf_transformer.transform(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = [1, 10, 50, 100, 200, 500]\n",
    "\n",
    "explained_variances = []\n",
    "\n",
    "for k in k_values:\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    X_train_reduced = svd.fit_transform(X_train)\n",
    "    explained_variances.append(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "plt.plot(k_values, explained_variances, marker='o')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components (k)')\n",
    "plt.xlabel('Number of Components (k)')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=100)\n",
    "X_train_reduced = svd_model.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 100)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = svd_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_reduced, train['is_team_fan'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(test['is_team_fan'].values, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       199\n",
      "           1       1.00      0.98      0.99       201\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       0.99      0.99      0.99       400\n",
      "weighted avg       0.99      0.99      0.99       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['is_team_fan'].values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr_cm = confusion_matrix(test['is_team_fan'].values, y_pred)\n",
    "labels = ['#gohawks', '#gopatriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199,   0],\n",
       "       [  4, 197]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(lr_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_reduced, train['is_team_fan'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(test['is_team_fan'].values, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       199\n",
      "           1       0.99      0.98      0.99       201\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       0.99      0.99      0.99       400\n",
      "weighted avg       0.99      0.99      0.99       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['is_team_fan'].values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rf_cm = confusion_matrix(test['is_team_fan'].values, y_pred)\n",
    "labels = ['#gohawks', '#gopatriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[198,   1],\n",
       "       [  4, 197]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rf_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-14 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-14 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-14 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-14 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-14 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-14 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-14 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-14 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-14 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_reduced, train['is_team_fan'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(test['is_team_fan'].values, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       199\n",
      "           1       1.00      0.98      0.99       201\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       0.99      0.99      0.99       400\n",
      "weighted avg       0.99      0.99      0.99       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['is_team_fan'].values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_cm = confusion_matrix(test['is_team_fan'].values, y_pred)\n",
    "labels = ['#gohawks', '#gopatriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199,   0],\n",
       "       [  5, 196]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(svm_cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict the number of retweets & likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting 500 tweet data from each file to construct Dataframe (Subsampling from Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to extract the first 100 tweets from each hashtag\n",
    "# List to store tweet data\n",
    "tweet_data = []\n",
    "    \n",
    "# Directory containing tweet files\n",
    "directory = './ECE219_tweet_data'\n",
    "    \n",
    "# Loop through each file\n",
    "for filename in os.listdir(directory):\n",
    "     if filename.endswith(\".txt\"):\n",
    "        hashtag = filename.split('.')[0]  # Extract hashtag from file name\n",
    "        with open(os.path.join(directory, filename), 'r', encoding=\"utf8\") as file:\n",
    "            count = 0  # Counter to keep track of tweets for each hashtag\n",
    "                \n",
    "            # Iterate over each line (tweet)\n",
    "            for line in file:\n",
    "                if count < 500:  # Extract only the first 100 tweets\n",
    "                    tweet = json.loads(line)\n",
    "                    \n",
    "                    # Extract relevant information from the tweet\n",
    "                    tweet_info = {\n",
    "                        'tweet_text': tweet['tweet']['text'],  # Extract tweet text\n",
    "                        'retweets': tweet['metrics']['citations']['total'],\n",
    "                        'likes': tweet['tweet']['favorite_count'],\n",
    "                        'hashtag': hashtag,\n",
    "                        }\n",
    "                    \n",
    "                    # Append the tweet information to the list\n",
    "                    tweet_data.append(tweet_info)\n",
    "                    count += 1  # Increment the counter\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who do you have?!?! #nfl #NFLPlayoffs #Packers...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://t.co/H5JADypiEB #billbelichick #NFL #NF...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One more week until the #Seahawks begin the #N...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have NFLSHOP on our site! 3% cash back and ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most @SuperBowl wins: #Steelers (6), #49ers &amp;a...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>@ehasselbeck a colts jersey? #GoPatriots</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>#GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>GAME DAY !! #GoPatriots </td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Good luck, bro! #GoPatriots! RT @TheRealMikeEp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>@NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tweets_#gopatriots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  retweets  likes  \\\n",
       "0     Who do you have?!?! #nfl #NFLPlayoffs #Packers...         4      0   \n",
       "1     http://t.co/H5JADypiEB #billbelichick #NFL #NF...         2      0   \n",
       "2     One more week until the #Seahawks begin the #N...         2      0   \n",
       "3     We have NFLSHOP on our site! 3% cash back and ...         2      2   \n",
       "4     Most @SuperBowl wins: #Steelers (6), #49ers &a...        14      0   \n",
       "...                                                 ...       ...    ...   \n",
       "2995           @ehasselbeck a colts jersey? #GoPatriots         1      0   \n",
       "2996  #GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...         1      0   \n",
       "2997                        GAME DAY !! #GoPatriots          1      0   \n",
       "2998  Good luck, bro! #GoPatriots! RT @TheRealMikeEp...         1      0   \n",
       "2999  @NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...         1      0   \n",
       "\n",
       "                 hashtag  \n",
       "0            tweets_#nfl  \n",
       "1            tweets_#nfl  \n",
       "2            tweets_#nfl  \n",
       "3            tweets_#nfl  \n",
       "4            tweets_#nfl  \n",
       "...                  ...  \n",
       "2995  tweets_#gopatriots  \n",
       "2996  tweets_#gopatriots  \n",
       "2997  tweets_#gopatriots  \n",
       "2998  tweets_#gopatriots  \n",
       "2999  tweets_#gopatriots  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who do you have?!?! #nfl #NFLPlayoffs #Packers...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://t.co/H5JADypiEB #billbelichick #NFL #NF...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One more week until the #Seahawks begin the #N...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have NFLSHOP on our site! 3% cash back and ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most @SuperBowl wins: #Steelers (6), #49ers &amp;a...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>#nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>@ehasselbeck a colts jersey? #GoPatriots</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>#GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>GAME DAY !! #GoPatriots </td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Good luck, bro! #GoPatriots! RT @TheRealMikeEp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>@NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#gopatriots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  retweets  likes  \\\n",
       "0     Who do you have?!?! #nfl #NFLPlayoffs #Packers...         4      0   \n",
       "1     http://t.co/H5JADypiEB #billbelichick #NFL #NF...         2      0   \n",
       "2     One more week until the #Seahawks begin the #N...         2      0   \n",
       "3     We have NFLSHOP on our site! 3% cash back and ...         2      2   \n",
       "4     Most @SuperBowl wins: #Steelers (6), #49ers &a...        14      0   \n",
       "...                                                 ...       ...    ...   \n",
       "2995           @ehasselbeck a colts jersey? #GoPatriots         1      0   \n",
       "2996  #GoPatriots #AmeliaRoe #Chruch #GodBless #MyBa...         1      0   \n",
       "2997                        GAME DAY !! #GoPatriots          1      0   \n",
       "2998  Good luck, bro! #GoPatriots! RT @TheRealMikeEp...         1      0   \n",
       "2999  @NoDigMaine @VerdantWater @MaineWEA @Dustin_Pr...         1      0   \n",
       "\n",
       "          hashtag  \n",
       "0            #nfl  \n",
       "1            #nfl  \n",
       "2            #nfl  \n",
       "3            #nfl  \n",
       "4            #nfl  \n",
       "...           ...  \n",
       "2995  #gopatriots  \n",
       "2996  #gopatriots  \n",
       "2997  #gopatriots  \n",
       "2998  #gopatriots  \n",
       "2999  #gopatriots  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'tweets_' from df['hashtag']\n",
    "df['hashtag'] = df['hashtag'].apply(lambda x: x.split()[-1].replace('tweets_#', '#'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "r_train,r_test = train_test_split(df[['tweet_text', 'retweets']], test_size=0.2)\n",
    "l_train,l_test = train_test_split(df[['tweet_text', 'likes']], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 2)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_train.shape\n",
    "l_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_test.shape\n",
    "l_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['hashtag'], bins=20, edgecolor='black')\n",
    "plt.title('Hashtags')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train['tweet_text'] = r_train['tweet_text'].map(clean)\n",
    "r_test['tweet_text'] = r_test['tweet_text'].map(clean)\n",
    "\n",
    "l_train['tweet_text'] = l_train['tweet_text'].map(clean)\n",
    "l_test['tweet_text'] = l_test['tweet_text'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642     .@DeSeanJackson11 talks #LegionOfBoom, #Redski...\n",
       "700     @chris_muther @Orbitz @Patriots @SuperBowl I l...\n",
       "226     Ohio State's Meyer: No desire to coach in the ...\n",
       "1697    Gallery: AFC Championship Game, Best and Worst...\n",
       "1010    Go H2H vs real NFL players in the #Duracell26h...\n",
       "                              ...                        \n",
       "1638    PC West cruises past Dell City 75-36 #GoPatz #...\n",
       "1095    Ponte en el Camino Al Superbowl! #SB49xESPN Co...\n",
       "1130    Ponte en el Camino Al Superbowl! #SB49xESPN Co...\n",
       "1294    Ponte en el Camino Al Superbowl! #SB49xESPN Co...\n",
       "860     I'm calling it now, Indy to win Superbowl. #Su...\n",
       "Name: tweet_text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_train['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2445    #GoHawks @DangeRussWilson @bwalt19 cheering up...\n",
       "473     Patriots vs. Colts through stats-based lens: A...\n",
       "1814    RT @PP_Rich_Hill: Testament to trusting the DB...\n",
       "1488    Did you say the #SuperBowlXLIX was coming to A...\n",
       "297     NFL News: AFC Championship Game 2015: Early Fa...\n",
       "                              ...                        \n",
       "500     At http://t.co/Vd0RWOeAed -- #Seahawks #12thMA...\n",
       "2659    @ms_pats thanks for the follow! Let's go Patri...\n",
       "141     #Healthcare #Fitspo Private Label Caralluma Fi...\n",
       "2597    @DBUPatriots Hello! We here at @911cellular wa...\n",
       "2605    #Patriots vs #Colts domingo 18 de enero en el ...\n",
       "Name: tweet_text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train['tweet_text'] = r_train['tweet_text'].apply(remove_punctuation) # Train Data\n",
    "r_test['tweet_text'] = r_test['tweet_text'].apply(remove_punctuation) # Train Data\n",
    "\n",
    "l_train['tweet_text'] = l_train['tweet_text'].apply(remove_punctuation) # Train Data\n",
    "l_test['tweet_text'] = l_test['tweet_text'].apply(remove_punctuation) # Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642     DeSeanJackson11 talks LegionOfBoom Redskins an...\n",
       "700     chrismuther Orbitz Patriots SuperBowl I like y...\n",
       "226     Ohio States Meyer No desire to coach in the NF...\n",
       "1697    Gallery AFC Championship Game Best and Worst i...\n",
       "1010    Go H2H vs real NFL players in the Duracell26hr...\n",
       "                              ...                        \n",
       "1638    PC West cruises past Dell City 7536 GoPatz tak...\n",
       "1095    Ponte en el Camino Al Superbowl SB49xESPN Con ...\n",
       "1130    Ponte en el Camino Al Superbowl SB49xESPN Con ...\n",
       "1294    Ponte en el Camino Al Superbowl SB49xESPN Con ...\n",
       "860     Im calling it now Indy to win Superbowl SuperB...\n",
       "Name: tweet_text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_train['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2445    GoHawks DangeRussWilson bwalt19 cheering up Ja...\n",
       "473     Patriots vs Colts through statsbased lens A lo...\n",
       "1814    RT PPRichHill Testament to trusting the DBs pe...\n",
       "1488    Did you say the SuperBowlXLIX was coming to AZ...\n",
       "297     NFL News AFC Championship Game 2015 Early Fant...\n",
       "                              ...                        \n",
       "500     At httptcoVd0RWOeAed  Seahawks 12thMAN 12 Seah...\n",
       "2659    mspats thanks for the follow Lets go Patriots ...\n",
       "141     Healthcare Fitspo Private Label Caralluma Fimb...\n",
       "2597    DBUPatriots Hello We here at 911cellular want ...\n",
       "2605    Patriots vs Colts domingo 18 de enero en el Gi...\n",
       "Name: tweet_text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude terms that are numbers (e.g. 123, -45, 6.7 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train['tweet_text'] = r_train['tweet_text'].apply(remove_nos)\n",
    "r_test['tweet_text'] = r_test['tweet_text'].apply(remove_nos)\n",
    "\n",
    "l_train['tweet_text'] = l_train['tweet_text'].apply(remove_nos)\n",
    "l_test['tweet_text'] = l_test['tweet_text'].apply(remove_nos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train['tweet_text'] = r_train['tweet_text'].apply(lemmatize_text)\n",
    "r_test['tweet_text'] = r_test['tweet_text'].apply(lemmatize_text)\n",
    "\n",
    "l_train['tweet_text'] = l_train['tweet_text'].apply(lemmatize_text)\n",
    "l_test['tweet_text'] = l_test['tweet_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1081)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "r_X_train = count_vect.fit_transform(r_train['tweet_text'])\n",
    "r_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1088)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "l_X_train = count_vect.fit_transform(l_train['tweet_text'])\n",
    "l_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1088)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_X_test = count_vect.transform(r_test['tweet_text'])\n",
    "r_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1088)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_X_test = count_vect.transform(l_test['tweet_text'])\n",
    "l_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data to TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1081)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "r_X_train = tfidf_transformer.fit_transform(r_X_train)\n",
    "r_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1088)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "l_X_train = tfidf_transformer.fit_transform(l_X_train)\n",
    "l_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1088)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_X_test = tfidf_transformer.transform(r_X_test)\n",
    "r_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1088)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_X_test = tfidf_transformer.transform(l_X_test)\n",
    "l_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40460503, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = [1, 10, 50, 100, 200, 500]\n",
    "\n",
    "explained_variances = []\n",
    "\n",
    "for k in k_values:\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    r_X_train_reduced = svd.fit_transform(r_X_train)\n",
    "    explained_variances.append(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "plt.plot(k_values, explained_variances, marker='o')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components (k)')\n",
    "plt.xlabel('Number of Components (k)')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_values = [1, 10, 50, 100, 200, 500]\n",
    "\n",
    "explained_variances = []\n",
    "\n",
    "for k in k_values:\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    l_X_train_reduced = svd.fit_transform(l_X_train)\n",
    "    explained_variances.append(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "plt.plot(k_values, explained_variances, marker='o')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components (k)')\n",
    "plt.xlabel('Number of Components (k)')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=100)\n",
    "r_X_train_reduced = svd_model.fit_transform(r_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=100)\n",
    "l_X_train_reduced = svd_model.fit_transform(l_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 100)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 100)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_X_test_reduced = svd_model.transform(r_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_X_test_reduced = svd_model.transform(l_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 100)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 100)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model on # of Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(r_X_train_reduced, r_train['retweets'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(r_X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweets - Mean Squared Error: 2851.5914566778747\n",
      "Retweets - Mean Absolute Error: 21.23602653646607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse_retweets = mean_squared_error(r_test['retweets'].values, y_pred)\n",
    "mae_retweets = mean_absolute_error(r_test['retweets'].values, y_pred)\n",
    "print(\"Retweets - Mean Squared Error:\", mse_retweets)\n",
    "print(\"Retweets - Mean Absolute Error:\", mae_retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2843\n"
     ]
    }
   ],
   "source": [
    "largest_retweet = df['retweets'].max()\n",
    "print(largest_retweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model on # of Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(l_X_train_reduced, l_train['likes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(l_X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - Mean Squared Error: 5.668133012246949\n",
      "Likes - Mean Absolute Error: 1.4212903005314839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse_likes = mean_squared_error(l_test['likes'].values, y_pred)\n",
    "mae_likes = mean_absolute_error(l_test['likes'].values, y_pred)\n",
    "print(\"Likes - Mean Squared Error:\", mse_likes)\n",
    "print(\"Likes - Mean Absolute Error:\", mae_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n"
     ]
    }
   ],
   "source": [
    "largest_likes = df['likes'].max()\n",
    "print(largest_likes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
